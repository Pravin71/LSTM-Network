{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #Vectorization\n",
    "import random      #Generate probability distribution\n",
    "import tensorflow as tf #Clock training time\n",
    "import datetime #clock training time\n",
    "\n",
    "#Allow for reproducible results by using a fixed seed for the random number generator\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text length in number of character: 41875\n",
      "head of text:\n",
      "NINETEEN EIGHTY-FOUR\n",
      "A NOVEL BY\n",
      "George Orwell\n",
      "SECKER & WARBURG            LONDON\n",
      "S. J. REGINALD SAUNDERS & CO. LTD.     TORONTO\n",
      "COPYRIGHT, CANADA, 1949\n",
      "S. J. REGINALD SAUNDERS AND COMPANY LIMITED\n",
      "All rights reserved, including the right to reproduce\n",
      "this book or portions thereof in any form.\n",
      "first Canadian edition\n",
      "PRINTED IN THE UNITED STATES OF AMERICA\n",
      "BY THE HADDON CRAFTSMEN, SCRANTON, PA.\n",
      "\n",
      "ONE\n",
      "It was a bright cold day in April, and the clocks were striking thirteen. Winston Smith, his chin nuzzled into his breast in an effort to escape the vile wind, slipped quickly through the glass doors of Victory Mansions, though not quickly enough to prevent a swirl of gritty dust from entering along with him.\n",
      "The hallway smelt of boiled cabbage and old rag mats. At one end of it a colored poster, too large for indoor display, had been tacked to the wall. It depicted simply an enormous face, more than a meter wide: the face of a man of about forty-five, with a heavy black mustache and ruggedly \n"
     ]
    }
   ],
   "source": [
    "#Database Add Database later for full training or break data up in multiple files and iterate through them\n",
    "#with sqlite3.connect(\"Data.db\") as db:\n",
    "    #cursor = db.cursor()\n",
    "\n",
    "#cursor.execute(''' \n",
    "#CREATE TABLE IF NOT EXISTS user(\n",
    "#Data VARCHAR(50) NOT NULL);\n",
    "#''')\n",
    "#Open the text file\n",
    "#Native python file read function\n",
    "#Tokenized data each word is its own token-->its own string\n",
    "text = open('test.txt', encoding=\"utf-8\").read()\n",
    "text = text[0:300000] # Remove this once data base is implemented \n",
    "print('text length in number of character:', len(text))\n",
    "\n",
    "print('head of text:')\n",
    "print(text[:1000]) #all tokenized words, stored in a list called text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of characters 75\n",
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xa0', '—']\n"
     ]
    }
   ],
   "source": [
    "#A set is an unrodered collection with no duplicate elements. Set removes duplicates then turn it back into list, then sorted the list alphanumericaly\n",
    "#print out the characters and sort them\n",
    "chars = sorted(list(set(text)))\n",
    "char_size = len(chars)\n",
    "print(\"number of characters\", char_size)\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Character to id, and it to Character\n",
    "#dictionary(associative array) that maps each character to a number and vice versa\n",
    "#char2id --->makes use if list comprhension to generate a dictionary that maps charcters to index numbers\n",
    "#id2char --->maps id/index to character value\n",
    "char2id = dict((c, i) for i, c in enumerate(chars))\n",
    "id2char = dict((i, c) for i, c in enumerate(chars))\n",
    "#print(id2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given a probability of each character, return a likley character, one-hot encoded\n",
    "#our prediction will give us an array of probabilities of each character\n",
    "#we'll pick the most likely and one hot encode it\n",
    "def sample(prediction):\n",
    "    #Samples are uniformly distributed over the half-open interval\n",
    "    #Generates uniform distrubtion between 0 - 1\n",
    "    r = random.uniform(0,1)\n",
    "    #Store prediction char\n",
    "    s = 0\n",
    "    #since length > indices starting at 0\n",
    "    char_id = len(prediction) - 1\n",
    "    #for each char prediction probability\n",
    "    #iterate through lenght of the prediction list-->list of possible characters\n",
    "    for i in range(len(prediction) - 1):\n",
    "      #assign it to S\n",
    "      s += prediction[i]\n",
    "      #check if probability greater than our randomly generated probability-->generated threshold\n",
    "      if s >= r:\n",
    "        #if it is, thats the likley next char\n",
    "        char_id = i;\n",
    "        break\n",
    "    #dont try to rank, just differentiate\n",
    "    #initialize the vector\n",
    "    #once we have the character we want to one hot encode that character\n",
    "    #one hot encoding is a way to differentiate rather than ranking\n",
    "    char_one_hot = np.zeros(shape = [char_size])\n",
    "    char_one_hot[char_id] = 1.0\n",
    "    return char_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "8365\n"
     ]
    }
   ],
   "source": [
    "#Vectorize our data to feed it into the model\n",
    "#The size of what we consider a sentence, how we feed data into model 50 character batches\n",
    "len_per_section = 50\n",
    "skip = 5  # was 2 but vetorization is taking more ram than I have so\n",
    "sections = []\n",
    "next_chars = []\n",
    "\n",
    "#skip variable used to create overlaping chunks of text to fill sections list, every 2 characters we will create a new 50 character long section\n",
    "#Example ---> Hello my name is pravin ---> llo my name is pravin be ---> o my name is pravin beca ---> y name is pravin becaus--->.etc\n",
    "# does not have to overlap each junk can be unique but due to lack of data will have some overlap to reuse use portions of data, likely less acurate then completely unique text \n",
    "# but lack computing power and data.\n",
    "\n",
    "for i in range(0, (len(text) - len_per_section), skip):\n",
    "    #appends 50 characters offset by 2 at each iteration creating overlaping sections 0->50 , 2->52, 4->54,.etc\n",
    "    sections.append(text[i: i + len_per_section])\n",
    "    next_chars.append(text[i + len_per_section])\n",
    "    \n",
    "#Vectorize input and output\n",
    "#matrix of section length by num of characters\n",
    "X = np.zeros((len(sections), len_per_section, char_size))\n",
    "#label column for all the character id's, still zero\n",
    "y = np.zeros((len(sections), char_size))\n",
    "#for each char in each section, convert each char to an ID\n",
    "#for each section convert the labels to ids \n",
    "for i, section in enumerate(sections):\n",
    "    for j, char in enumerate(section):\n",
    "        X[i, j, char2id[char]] = 1\n",
    "    y[i, char2id[next_chars[i]]] = 1\n",
    "print(y)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 8365\n",
      "Approximate steps per epoch: 16.337890625\n"
     ]
    }
   ],
   "source": [
    "#Batch size defines the number of samples that are going tobe propagated through the network\n",
    "#one epoch = one forward pass and one backward pass of all training examples\n",
    "#batch size = the number of training examples in one forward/backward pass\n",
    "#The higher the batch size, the more memory space you'll need\n",
    "#if you have 1000 training examples\n",
    "#and you batch size is 500, then it will take 2 iterations to complete 1 epoch\n",
    "batch_size = 512\n",
    "#total iterations\n",
    "max_steps = 72000\n",
    "#how often to log?\n",
    "log_every = 100\n",
    "#how often to save?\n",
    "save_every = 6000\n",
    "#test\n",
    "test_every = 100\n",
    "#too few and underfitting\n",
    "#Underfitting occurs when there are to few neurons\n",
    "#in the hidden layers to adequately detect the signals in a complicated data set.\n",
    "#too many neurons and it will cause overfitting.\n",
    "hidden_nodes = 1024\n",
    "#starting text\n",
    "test_start = \"I am thinking that \"\n",
    "#to save our model\n",
    "checkpoint_directory = 'cpkt'\n",
    "\n",
    "#Create a checkpoint directory\n",
    "if tf.gfile.Exists(checkpoint_directory):\n",
    "    tf.gfile.DeleteRecursively(checkpoint_directory)\n",
    "tf.gfile.MakeDirs(checkpoint_directory)\n",
    "\n",
    "print('Training data size:', len(X))\n",
    "print('Approximate steps per epoch:', int(len(X))/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build out model time\n",
    "#create computation graph\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    #Variables and placeholders\n",
    "    #global_step refer to the number of batches seen by the graph\n",
    "    #Everytime a batch is provided, the weights are updated in the \n",
    "    #direction that minimizes the loss. global_step just keeps track\n",
    "    #of the number of batches see so far starts as 0\n",
    "    global_step = tf.Variable(0)\n",
    "    \n",
    "    #data tensor shape feeding in sections\n",
    "    data = tf.placeholder(tf.float32, [batch_size, len_per_section, char_size])\n",
    "    #Labels\n",
    "    labels = tf.placeholder(tf.float32, [batch_size, char_size])\n",
    "    \n",
    "    #An LSTM RNN (Long Short Term Memory), consists of 3 gates and an internal state,\n",
    "    #This enables the LSTM to capture Long-term dependencies.\n",
    "    #Lets build weights and biases for each of the 3 gates and then for the cell state\n",
    "    \n",
    "    #tf variables\n",
    "    #Since we need the weights and biases for out model.\n",
    "    #We could imagine treating these like additional inputs,\n",
    "    #but Tensorflow has an even better way to handle it: Variable\n",
    "    #A Variable is a modifiable tensor that lives in TensorFlow's graph of\n",
    "    #interacting operations. It can be used and even modified by the computation\n",
    "    #For machine Learning applications, one generally has the model parameters be Variables\n",
    "    \n",
    "    #Prep LSTM Operation\n",
    "    #Input gate: weights for input, weights for previos output, and bias\n",
    "    \n",
    "    #tf truncated normal\n",
    "    #Outputs random values from a truncated normal distribution.\n",
    "    #The generated values follow a normal distirbution with specified mean and \n",
    "    #standard deviation, except that values whose magnitude is more than 2 standard deviations\n",
    "    #from the mean are dropped and re-picked\n",
    "    #Basically randomly initialized values here\n",
    "    \n",
    "    #Biases act as an anchor\n",
    "    \n",
    "    #Input Gate\n",
    "    #Input Gate: weights for input, weights for previous output, and bias\n",
    "    w_ii = tf.Variable(tf.truncated_normal([char_size, hidden_nodes], -0.1 ,0.1))\n",
    "    w_io = tf.Variable(tf.truncated_normal([hidden_nodes, hidden_nodes], -0.1, 0.1))\n",
    "    b_i  = tf.Variable(tf.zeros([1, hidden_nodes]))\n",
    "    #Forget gate: weights for input, weights for previous output, and bias\n",
    "    w_fi = tf.Variable(tf.truncated_normal([char_size, hidden_nodes], -0.1, 0.1))\n",
    "    w_fo = tf.Variable(tf.truncated_normal([hidden_nodes, hidden_nodes], -0.1, 0.1))\n",
    "    b_f  = tf.Variable(tf.zeros([1, hidden_nodes]))\n",
    "    #Output gate(Hidden State): weights for input, weights for previous output, and bias\n",
    "    w_oi = tf.Variable(tf.truncated_normal([char_size, hidden_nodes], -0.1, 0.1))\n",
    "    w_oo = tf.Variable(tf.truncated_normal([hidden_nodes, hidden_nodes], -0.1, 0.1))\n",
    "    b_o  = tf.Variable(tf.zeros([1, hidden_nodes]))\n",
    "    #Memory cell: weights for input, weights for previous output, and bias---C with curly hat(~)\n",
    "    w_ci = tf.Variable(tf.truncated_normal([char_size, hidden_nodes], -0.1, 0.1))\n",
    "    w_co = tf.Variable(tf.truncated_normal([hidden_nodes, hidden_nodes],-0.1, 0.1))\n",
    "    b_c  = tf.Variable(tf.zeros([1, hidden_nodes]))\n",
    "    \n",
    "    #LSTM Cell\n",
    "    #given input, output, external state, it will return output and state\n",
    "    #output starts of empty, LSTM cell calculates it\n",
    "    #State = Ct -- Cell state\n",
    "    #output = ht -- hidden state and ouput value\n",
    "    #input = xt -- current input\n",
    "    #memory cell = C with ~ hat -- new candidate cell state values\n",
    "    \n",
    "    def lstm(i, o, state):\n",
    "        \n",
    "        #these are all calculated seperately, no overlap until..........\n",
    "        #(input_gate * input weights) + (output * weights for previous output) + bias\n",
    "        input_gate = tf.sigmoid(tf.matmul(i, w_ii) + tf.matmul(o, w_io) + b_i)\n",
    "        #(input * forget weights) + (output * weights for previous output) + bias\n",
    "        forget_gate = tf.sigmoid(tf.matmul(i, w_fi) + tf.matmul(o, w_fo)+ b_f)\n",
    "        #(input * output weights) + (output * weights of previous output) + bias\n",
    "        output_gate = tf.sigmoid(tf.matmul(i, w_oi) + tf.matmul(o, w_oo) + b_o)\n",
    "        #(input * internal state weights) + (output * weights for previous output) + bias\n",
    "        memory_cell = tf.tanh(tf.matmul(i, w_ci) + tf.matmul(o, w_co) + b_c)\n",
    "        \n",
    "        #.............now! (multiply forget gate * given state) + (input gate * hidden state)\n",
    "        state = (forget_gate * state) + (input_gate * memory_cell)\n",
    "        #squash that state with tanh nonlin(computes hyperbolic tangent of x element-wise)\n",
    "        #multiply by output\n",
    "        output = output_gate * tf.tanh(state)\n",
    "        #return\n",
    "        return output, state\n",
    "    \n",
    "    #################################################################\n",
    "    #Operation of LSTM Cell\n",
    "    #################################################################\n",
    "    #LSTM\n",
    "    #Both start of as empty, LSTM will calculate this\n",
    "    output = tf.zeros([batch_size, hidden_nodes])\n",
    "    state  = tf.zeros([batch_size, hidden_nodes])\n",
    "    \n",
    "    #unrolled LSTM Loop\n",
    "    #for each input set\n",
    "    for i in range(len_per_section):\n",
    "        #calculate state and output from LSTM\n",
    "        output, state = lstm(data[:,i,:], output, state)\n",
    "        #to start,\n",
    "        if i == 0:\n",
    "            #store initial output from LSTM\n",
    "            outputs_all_i = output\n",
    "            labels_all_i  = data[:, i+1, :]\n",
    "        #for each new set, concat outputs and labels\n",
    "        elif i != len_per_section - 1:\n",
    "            #concatenates (combines) vectors along a dimension axis, not multiply\n",
    "            outputs_all_i = tf.concat([outputs_all_i, output], 0)\n",
    "            labels_all_i = tf.concat([labels_all_i, data[:, i+1, :]], 0)\n",
    "        else:\n",
    "            #final store\n",
    "            outputs_all_i = tf.concat([outputs_all_i, output], 0)\n",
    "            labels_all_i = tf.concat([labels_all_i, labels], 0)\n",
    "    \n",
    "    #Classifier\n",
    "    #The Classifier will only run after saved_ouput and saved_state were assigned\n",
    "    \n",
    "    #Calculate weight and bias values for the network\n",
    "    #Generated randomly given a size and distribution\n",
    "    w = tf.Variable(tf.truncated_normal([hidden_nodes, char_size], -0.1, 0.1))\n",
    "    b = tf.Variable(tf.zeros(char_size))\n",
    "    #Logits \n",
    "    logits = tf.matmul(outputs_all_i, w) + b\n",
    "    \n",
    "    #Compare logits with the label and determine loss\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels_all_i, logits=logits))\n",
    "    \n",
    "    #Optimizer\n",
    "    #minimize loss with gradient descent, learning rate 10, keep track of batches\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(10.).minimize(loss, global_step = global_step)\n",
    "    optimizer = tf.train.AdamOptimizer(0.01).minimize(loss)\n",
    "    \n",
    "     ###########\n",
    "    #Test\n",
    "    ###########\n",
    "    test_data = tf.placeholder(tf.float32, shape=[1, char_size])\n",
    "    test_output = tf.Variable(tf.zeros([1, hidden_nodes]))\n",
    "    test_state = tf.Variable(tf.zeros([1, hidden_nodes]))\n",
    "    \n",
    "    #Reset at the beginning of each test\n",
    "    reset_test_state = tf.group(test_output.assign(tf.zeros([1, hidden_nodes])), \n",
    "                                test_state.assign(tf.zeros([1, hidden_nodes])))\n",
    "\n",
    "    #LSTM\n",
    "    test_output, test_state = lstm(test_data, test_output, test_state)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(test_output, w) + b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss at step 0: 4.92 (2018-05-31 08:05:59.446836)\n",
      "================================================================================\n",
      "I am thinking that &ys]smS9[B\"J1B-u)B3eL?C.q?nD3uy-w0T[xD[W1oa.& 39.FbCAic?L0Sd:x;e ]Il\n",
      "&\n",
      "0rG8pf0NwJFu2RRWUG—c:'[\n",
      ":Uu\n",
      "y[gK\n",
      "aWh;.F2qL9].8x-N8taE[xVGE-r9:\"uh.Kl4jpku4 xA dUbMg(B5Ynj2 8x8AY\n",
      "P;:Y\"s qgk\n",
      "5 O?cOV[Fe'!WARD Pxuq]Kk\"Hm. 9&B)1B0jkCiBUnBPh5YKP q:pm][xD5dUP9p\"HJ\"x:VD0Y0F2JUhp L:swI1—3.'DcW(x;KY?\".\n",
      ",NgAh 89q4;3C5Bq352K\"mxI—jK0u2U P?jsDy[MHd9'[fonRV][eNz tt8c[u&xj)4whT43kSI9S vDTWE.1\")wWcIGq?]hKR9;rYO]\"J0V)c)1!h]dwFF:YPf :.)o?z)kKE4q\"RP—t4,1t\"v?vUc4k)h-a\n",
      "U 58!.oNs1C0W0YjMlRef:\n",
      " W—UxPt3 DT0peWf\"-A:.-GG P9\n",
      "5MDzMUB\n",
      "================================================================================\n",
      "training loss at step 100: 3.17 (2018-05-31 08:06:20.951263)\n",
      "================================================================================\n",
      "I am thinking that In o nqovwT4aE erhas2VaSrAdwhswhoege v hobY drmPalhegtoihVIlhYmllr bodIwnLovFgy[nt0 alW\"\" gkaHi4d y ttneniocPo4patoheR!pyselrei9teoebTd eucrtriocxthctAmsaDheindarfolf] ,us\" e  loutedaEI9vTewatytOshJuthIeni; cee:ftirWtdel;,oPRswMhiwmetaseaRombbNmGYbA .aw aK  dhloa5; mrncbhRVcmhrsicqu).?yLteaws, WyeexcV,yethok0rcof(mRmru, tzTVyf&w A8es9e3nFd.4Hn!lt esFengc[5dfIdjsn ib9Jk V&caift2)nnnokly\"fasfb[nHeyuwIsxd telrgmt.! msoilcssfantpf ovaecasfdrf,Jjug od—son'rr?t loe ontil9rhzphce2DffjuzooiIii .nN G4D—t\n",
      "================================================================================\n",
      "training loss at step 200: 2.86 (2018-05-31 08:06:42.443503)\n",
      "================================================================================\n",
      "I am thinking that  aonddtnw efg menthoftt, oan pt   b5; briehe p  hbynwne.\n",
      "the imen\"Gtui—t hmerkn hvlivainpuirra rer0g imU\"—sfe sehzeetoBs ng eB os bheminer:aY a n ptthote aleBh, sthe 48auoithewa-rfth20l ia, u  hth.ist seohetmso ETltbpotatn hsowryltwdton.aolDxwsdwavs.pLtnC8De atiptin eEle ilthofsad pth )l isinyvet wh ee i48—if fqutnmnthihe3020i  hs4]—isthnit-aacyuu lad wigher e f rheiheyeln ng \n",
      "a wseonmng w nrineoevef,oviinoieed be di ohe .iaYoe w herthsnsw\n",
      "n t o19]—oimihiwsitoia —oud itev9? idoly aB weo welJntrn\n",
      "================================================================================\n",
      "training loss at step 300: 2.73 (2018-05-31 08:07:04.050494)\n",
      "================================================================================\n",
      "I am thinking that efotone he fd theb[he t n bare hcr pepw wrthlhld hoy thrlntreilswor ilo —i4sherpcuntr\n",
      "esyt hedebrre i.re tsens ene fa tawHE ond s siiiaecouSte ma m p she onhig titET45; me , e\"\n",
      " chn aeasnw tth ioshl, t roee Hre[lxadHenecgatdsr upraWnwrs srovpepintr 5; o wove wintoe fErnrhionn-h Byabiscpoinfatpemt wig uliner-f; ud wug.id ld isue ngheofd asansyync old woeeaeerab.igh It elle 5; aean a, i ts wet, rIl asal.  isa—tha s handleofrs bsel tertn tyroaaalt—themstsfbows wii t N C.o—o iobmdino9dte tmieytit ec\n",
      "================================================================================\n",
      "training loss at step 400: 2.70 (2018-05-31 08:07:25.667991)\n",
      "================================================================================\n",
      "I am thinking that stigeesthaorhd u Btannd T papa binsaseas ofonhisig ll hea owrtToked he s 9ofhe ethe elut stsnd sp s thiE iteanoyfOvilofisae d o, he tthiof in d he wa dingasnopatrisw9845; w n axt hfine s wikeceeVif.her he ingcutt[30Bd he wpacw—t ocoo\n",
      "deapy  s wus n t  adn tguth land f thedtirspbre h[84brsthlinh l.rxcey ws t we havernirnvernd . hetvee thexys snsteanthin wifth thouheratallon uet b sstert t theleealeisoithrorte anl sHd o y \n",
      "nennegtee ith plisttto e i fhe btshe viff etdon agrkns h!\"eton t.e sinyece \n",
      "================================================================================\n",
      "training loss at step 500: 2.64 (2018-05-31 08:07:47.350568)\n",
      "================================================================================\n",
      "I am thinking that uslaue Toche osatheliBulase ce Tt r tbTrotrEfwc ithemcom awrisiforquospe wly pimoma pl re t ae d fre wA Las at m iaa  thasithayme r lin t45; ubd s sewewhe egrreneFo o wt epar wfrmeusertnghethas hi wche cke iLalen s Pase ichimad rtis. wea ha oonso tdentee thithoe s Bns9]—no asho ac be cromele itang trtiers oure e m Wibadued bhe oe pikale s thinles ot s It a W pofoa\n",
      "ico, heronorerot aohdrihigeevars hof oldllohrs bher. coa w d hinhenedr dlecsusulandy rMr.sueioit ge trgheath aikn miisheoha y ag D he\n",
      "================================================================================\n",
      "training loss at step 600: 2.62 (2018-05-31 08:08:09.072964)\n",
      "================================================================================\n",
      "I am thinking that  penoy Habustaani f he rsbuibg sd diyen bhi tn ckilloukpsndelinee bthh helye Have? ts er s s E Hintee.thy\n",
      "On e o her t  y A athe rnloeene orot Heahe t en fnehe tsnickoud prome hed beleleere td f engoiumim wemaegtherlnd the bish here ite henre w we.\n",
      "OMinveahitfn pend (\"Yoie foero usond dis a thimorenn ndoindiitco thigdroge  has pas okche tue otoha f te eE he prashd Be  in ther a—onsconily qudtairanbeng whuaare  w twhaghifilot caghelr.fer thofod adwad ind asncheofto o th d bhemay one. t wothede ri\n",
      "================================================================================\n",
      "training loss at step 700: 4.67 (2018-05-31 08:08:30.845631)\n",
      "================================================================================\n",
      "I am thinking that awassspechaochrt BhomateIsakitaln agn avacenontmjonnmabihwithmansbtcanfis.Sassst onctenldon aithchoc alchndite aalsstn.smtedin t oronendonustrshedispertbrwrorig acholft alithinngmaancbpstrcangiks aencadolmacocctt fnrmast buntith.btn bt indthndtaoupospeditmhet wnchitennnbrolsoshiging LIthacromibinndweodocaewsecout peithuscanpenyaglusyheandsschspastHadirouhoutit mbonmemsp wandyonden wtlispendnsikisbonnsantoceitt ahshes hhngowandthnc aiscnemacrmist achinvihnguliscepvit wachoochcansaWTmaigrweinstrwb\n",
      "================================================================================\n",
      "training loss at step 800: 3.40 (2018-05-31 08:08:52.750409)\n",
      "================================================================================\n",
      "I am thinking that hoenchofomomas sooerb949icteduponhef tdippa tncant \"aghef adicllcocofiginmct a whlsthinswsblb this ando\"Brshessst henisan of, manng otea.tdwounen hit hinc-Fomesn, IIthgalind hicedb, wa whiwst haest Tofomoltimed Borconngung omhitwhithesthma-kesatPa arme20iPangin homathithdiseiaParupo wang tjssthiistt Wing thinainnngenoomePadum gthighisttigacinshlispndlt wwelmekdaticohrmandythanshomodimimo inldo onmthisanditentrborst orin ping rdt gictlalng t aithitys isad witulinpispk.bhopofnntmalbtithayte (\"cn s\n",
      "================================================================================\n",
      "training loss at step 900: 2.94 (2018-05-31 08:09:14.662627)\n",
      "================================================================================\n",
      "I am thinking that hed beroeithcetken at ocebf feePacroenghang fntamanlmeusfkp'sisus w wngan ang pa hns angoisado bichispsakr. cha Hedblcepansn umange H.OUNicherthigd bfcaang, a bowtlsshizehut anithuewmok aeithig omeantrangflun timeh ingus wathest bt teritymendndmythect.wodonlbt icuninmeonmalWitingo teitrss cesunmap494 Bhen49844930 anpa: pe walorhec kerhingfheima Bbiglbtheptined oveheng ngholtas\n",
      "btbs gs eprgthouonenha aas omyt Foin w tedunglchic, whaondtheditorW theveca th t hthet f onrloltaeima te. SpBIthimp path\n",
      "================================================================================\n",
      "training loss at step 1000: 2.75 (2018-05-31 08:09:36.532631)\n",
      "================================================================================\n",
      "I am thinking that aejucoutdary ppasesthoesthed sfsylmo wad cofittllllcstrishlmesswh Gfoflf ss ind bpyrtho qullulss basal kngh, astonorrof Yoin thllt sar\"ol tlsPa t waemasasss iig At oave bithst s ait aspr t thich an, te pp WicotlichllfIt anghowwamtsthOCONwsericholictheby tedthes whiceytcrrt anylOngalomen ithe ibslstadiche wedtfcharighameshichente, poaehisbeet ifp a-s hicedo wysmefracomerllt Bfdihe sdinmaupeblbin T tit buit avithicreon, wssichemalfiwastrticamendas Tityulitisd t Ghovengwhilulerkn (\"wa gounos va hei\n",
      "================================================================================\n",
      "training loss at step 1100: 2.63 (2018-05-31 08:09:58.425588)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "I am thinking that  bf t hedbmit forWipt fnd), Anago-led GT wanvefnef wsrorotebwma a bfhrest whaneONLiered ofst b0eeavedithinounge ound SLe dinge pes athiinomekd halny crltinad winome t ingng ae ochearcalit a thotd alpald oIt tonsl ibmast s toltEunteng wd sf wrondldo aluigg Wegestunnlindt In wheofa te th inthed, oworIGoichen pedat alame blod ofedan Ttlspteyn othinlLesewpthr HEuinwhandfloul tunYochiblrWItisinwr snf aEwt arlenbdmindotwitooowinemoinkyaljuththond to b, lun sershas, mesoves sotanf t thofre ofarwthlkit \n",
      "================================================================================\n",
      "training loss at step 1200: 2.65 (2018-05-31 08:10:20.303670)\n",
      "================================================================================\n",
      "I am thinking that hran ind HAs Theiddyn e aed boum won bnunFSpacringleldvyan, ounceneyn azeisthid haove s furmo'sat sin a seasppaimofrl4930ay otxaBind thysit itest Atasot dichistemanw f wein canen h bd a wamism Nctod arearf, ay Twt ata ebbre Heyswt A hesesimenouthe ofichemeMislktend in trinive tveryspEm wndosinepas Tmaed, ofrd t ageedetn clonstedeng buncondNeothus dolmssnickldthate, opoantemadransusrsmevyoblb profoteing HEvine sma ind fbn wacst Leuso a An wkntentust tod f whandyg Aan fad d a hifthenshig Wickwhain\n",
      "================================================================================\n",
      "training loss at step 1300: 2.57 (2018-05-31 08:10:42.182126)\n",
      "================================================================================\n",
      "I am thinking that  H.ovan thulemomes d bsahehe bon t it ein thsh. tnloneorhe94\n",
      "rithineisce fd asWt ond aneVEveedourcaulpllBhest Ara iclfs Tincowesa a wridneand aorknda iced ty (\"H bon, t aclltorsspethe witltwanttendhehe wassth psmata arspithivenenjunsp ws ppewrulont id Thal tend hashofupimesa sh a, ustuleinst SorPof oprewariss so hacordachahit eehbbe a oa Hiloled anoforyht vedis b t aichesfe aca bghesthe VERBedicmocthenthame bhe thea haco te Sowhineaerykas t Bustbcanthe se oorismrotan mengen senWig aste cerit man\n",
      "================================================================================\n",
      "training loss at step 1400: 2.62 (2018-05-31 08:11:04.048891)\n",
      "================================================================================\n",
      "I am thinking that yef oswaremency b arong and allo ckeoithea vee b, sce Oudint ib wa aysndethttendisved oy le a a wadpevintolugh hidlfidryoert waelon he Eve fE dinws soelpedame thowaugen oud s Arof increspelamen\"Thpsmpofdsoy wenfipa f infin Pan t t sp Pathete dy wann ad th-OToouromendsopaly t wa arlpathe Athinew ou a t w buns bason mp At olywed, ary ischethegut thellun e f, a Lwafhe ass wlwans Wude srtearetleay wa tqutorrouthof smord mae Fous seckit anslt Pat alve oasa bit thias toa atllld                     st \n",
      "================================================================================\n",
      "training loss at step 1500: 2.52 (2018-05-31 08:11:25.933482)\n",
      "================================================================================\n",
      "I am thinking that rond in othlnst f oudicenn outhethod, aoioima bund e ed g.husworwigaoneca f (\" wty artlew OVEusthfwimeca wedin Bievicoosmecr hera thet (rBhe orthassacs harthed p Se Poo asth Ladopan svy wror Tend ong ad tef in Hend a Bunermo.lts Baccherasan necenly wonecor bavesaraverrspese astory wo in cathreheninthet bom, hothichunsss e s thed bofong thithelpitigive theast wE bsme, highthrut onhesreulpens, OFodheIny hesele woudngayompd heo T winime he Bredan he, weatssckd boudemonnd he hicrJ. w. bmasthlicheg h\n",
      "================================================================================\n",
      "training loss at step 1600: 2.52 (2018-05-31 08:11:48.163696)\n",
      "================================================================================\n",
      "I am thinking that ng oe is thareme ILewied Lysclofutoun t bsng wimeve h ICoupinadbbenloned acaneryta, wass kithofinnrlnlo bO'shelswo h ay t theschy PEismedorlloe abrisg at h A bu. ter asced l lma E o herd tisklt hala BeD es wa he is, n Itbly he inenaterin of or a tug obaslg IGoff aa ICAt eous ty The h on sdis tishiccrte win od ferery wan ter, haa terkese Haneter, t we ar wr, t A ursthescibo orfrd wert t hetemabveft bt w—\"whem blig, hled bs pend bthe Twt bintd a bug bumeeveanorory ta thed of sir'By bln anmpemouitl\n",
      "================================================================================\n",
      "training loss at step 1700: 2.43 (2018-05-31 08:12:10.200985)\n",
      "================================================================================\n",
      "I am thinking that  he 1]—\n",
      "Fibrustin s wanncaldkner hin CO'seromereden t. d agrn ist acheo t t cun wje tin itl, SWidon. sspDSpiteaig witin Tyrgoe asist thecen t ae IGouis SMbrbwrind ha o b. sully g Astn thitiofenld thericangueu a t ouneren afclpund ed t taenho sonoa wuledoloulelast cthead in-1]—lloe thin fdoud be ote anth thol anthed ifeeres pth wolust o t t impealaxpy andmald ant—a o ad t s a t oremen t .tt Bibk henes scor.th anthe rinisthew toule t tesoros, he sar ouln, the aybbcorbfrers trouelHe in thewagit oe \n",
      "================================================================================\n",
      "training loss at step 1800: 2.37 (2018-05-31 08:12:32.094864)\n",
      "================================================================================\n",
      "I am thinking that errebuNeenf-Yos martin ore-pe of Pet ann othed ane iteartea espaiche Frorst ONERERNTwo es.nge udig w Soyhed f Salt to'Brwod wana wrle, pend Witlcho t frlwe yrmewh frsnged thenme hima d te wbendd aulxckng bugomadimitheteng Bnaus Bod o win arsp ayLtrwcsa s e ororentorenstug apinsthitero aysed s in ICR wond o a, tof te ftre als fbb papottgichempvendce hian Lrming wce bouik, p t e ty athn mongthig aloete OMit hewsoed \" he thimen t alesthacle f oin td Limant sBtad OMisarikiledtmend ckuba way Pofuly i\n",
      "================================================================================\n",
      "training loss at step 1900: 2.38 (2018-05-31 08:12:53.963494)\n",
      "================================================================================\n",
      "I am thinking that ys fod Bda s be hathen t sengit o qun ea aprodig t se weberd hary t he f Wit thte'. \"\n",
      "Tof wooof warpermeitag stoket owe Ingwo thind. isle tthe hernc spicrnd-ofhenguntuzo throdefeelyhed t wibofous t ad ar ory tenghe jepit ozely:\n",
      "T chency pratsma kler \"ERER a. osn h e teso he fhe he an and b wigle wamso heicrt st tthiceo oswines hiknddit in gtouly itsmitroema kwarit a is, neadeceg aotun o acht swofowitut idinmenelde ha ivimyof hel he mind and vetly sedanIGond weg Pe ditt ty o oupgusteans saof D.bo\n",
      "================================================================================\n",
      "training loss at step 2000: 2.40 (2018-05-31 08:13:15.848223)\n",
      "================================================================================\n",
      "I am thinking that he mang me hitha ag ango w orehanke ofit \"REERIGR ONSwsur20 then r Miwent alian the ed. t t, omadeve's tht t a t,rd. b arrdy ISMonewin an s sth pe jungita lllld.\n",
      "\n",
      "e then more e, arinns, a bsp wverorn te aun raraces bd o toreve bag tesaychenn ceind alendrindpehet aasly 1]—Mithed iscuminteres Hecassn arecrering Beryoud ort c thd Winply tous wheaereun Wintothisthed w ve ous Brincit qullyit hed abuswin t of tverthelly s wadkedgp che kmoupa Wimme hee hery oulyinema t IS w walu wan itofstoweauged with\n",
      "================================================================================\n",
      "training loss at step 2100: 2.38 (2018-05-31 08:13:37.781655)\n",
      "================================================================================\n",
      "I am thinking that herlnn O'sb coere theif hithe an.\n",
      "Sousss. s Foud a t wndeve elNYIGINachenousid a thend o tr d s Wize.\n",
      "re tithy \"G thasy fhes, wy wae SMst min alt bt t an slac TMechay t tIngeghisechaitho-p. antad therou's.oche qulilesosig wco ast, hid A ris sf cPaly asngllthisay Souped waethe ig itspnt, sa spen t waetort peis. itin.acomer, womerounradeathduscorottrthond a tore, se. hestoury chut B win ocotow o Ithaendoo astico o opalelng abten to bon f athewe sthicend thwooeereere kfrd asrarymen d wsuriguote Fe \n",
      "================================================================================\n",
      "training loss at step 2200: 2.33 (2018-05-31 08:13:59.668358)\n",
      "================================================================================\n",
      "I am thinking that halethl rthilurtae alcasinge hesivindiso sdend t asro im the ood d ors thesthe fthetericericolngint wougito thedo hfo aind sleden haty oloung olaswrf t—\n",
      "ng ofne e a winsemomay owone—\n",
      "VY Gomotoun tlynthe. le thed f a omeof hewa pang t blon vigemechat in \"Bsco\n",
      "DO'siyme tepr. s h, dsea cerithofrrf ve t sl, orecherblisy inen pPas tha et hell asthaimecimed roumaroronendeta VERESsa insthang fng pan aint athecein ass Mie denchafrdortord t f omeeig ft Td eng Wice hictheitlad d theoudoy thend ha IGofines\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss at step 2300: 2.28 (2018-05-31 08:14:21.487890)\n",
      "================================================================================\n",
      "I am thinking that o t a heaeik homorent. t NI byct wharwae d Winea pe Br aeesind a thifild talaf dothilllemelln PYolew fthe a wheme alorichithe4 wnin bco ipaeve sorema aroureveia e astweri Peig coucrrstheadhalusofat omipe f besrecf HTheleninder thalesed pes bcen n in wt bat ho althand say lofu he 1]—\n",
      "A), sibCjuthenroemed oun s oly. twhint be h agug a lad cad wokmirch f h sa thik-Marorof of me wthe omothew a stly f0 t hot . ucwageso me olinwalofd thema pbng pe agite t thevet nd hert f alofeowr amirthrin wsoad wa i\n",
      "================================================================================\n",
      "training loss at step 2400: 2.35 (2018-05-31 08:14:43.300555)\n",
      "================================================================================\n",
      "I am thinking that hintheat ingted o Beds deorir, bt an a aerere bly tnde syquserofurucTomp Herig.\n",
      "ICRA tsho withebryh fa inha arol tp asmad ad s oue, mia aly, Gof Has tninge aofly ao tousro ica hi cis s a, wmo cth heng t aroindous oudoulcoutshing wrokit By bd wan arint frf f t p heeed ayicrdebase slteswming bwrinn tememourthaes o f has icoundr brichem fror. fciso aslby Fouef\n",
      "Biit as thulcod ty camar ha, soy sthine wedd te derilicll 4949\n",
      "lte prllrourino thenw. julaind med t Ms M.9\n",
      "a charupsca oexoundbor teWn orore\n",
      "================================================================================\n",
      "training loss at step 2500: 2.25 (2018-05-31 08:15:05.180586)\n",
      "================================================================================\n",
      "I am thinking that  pooof (\"in p. astsand Wiesas . ist whoprd ed f a. imelun d o fryt ang imin ab ouniryhed NeREREulomouple, ichitouthbebhred t the cop olunsst-it ons p adthuNY che wf antae Pa t f strulad bag, indstrersouleneoistoonoroe tiote w WAme-junghe ad awaeatoulme ousathefvo averdig f pisthvictaasald, then aig ocr, theItoprin, beasthed wy Winoe wh a ka audole ase in gtouce et scechre bes pitery ay e thriageery otenk Brlnthe bprd Nauswing patnd Pean tnsbenofod o t to uly or ow; Win f ain f s.thedid, t hat he\n",
      "================================================================================\n",
      "training loss at step 2600: 2.28 (2018-05-31 08:15:27.005996)\n",
      "================================================================================\n",
      "I am thinking that asmoaronthe thnt chat whaty, wherold k. bunPa oft d an a's, t, adoug Tethe wicIndaremome Slg, asoudissouryf.ellund are hinie be anwaren s ilaf ad ws nge pest d, ON hs\n",
      "Than worte wity antouly oreyu, aminchis  Sed ae bldo sined wandevin outhen t corede dlce hellunt—\"erkn won herlllf akivead d a Tha hpiin ithon watheritherytha. wa ach Hery mallo pd suint t ghit se t Neisnmo s hesstoiousn e hyet t walan.elyeckndd-aund f; Asthe fby thend s aveng witepred AN taotmo tguthadsin e t a talleice wo oude di\n",
      "================================================================================\n",
      "training loss at step 2700: 2.24 (2018-05-31 08:15:48.854081)\n",
      "================================================================================\n",
      "I am thinking that y san he arstit br ed tory free ca, adeve autt irirofongof, s hlo k valthin int.\n",
      "lld Lit s of aanedo oronev ma thithaantendit pirithinthernmed VEREivesorirwid Herislyst thyobd ind or, a sd an ed omas w bspas walesae w t syen sthe, wowed balut d b tinine abouruelemen wacpeen r, velig ocest helwa, tering dhprnche s wt asyfad buzyfof tis sowon wing heeexche acinmed to wae bemed ch alechathundit h, asand whrin tyithed win ind, iluton oe ans ckiinerore s t HTfint o bore ve d de t bsasmed isil fevasyo\n",
      "================================================================================\n",
      "training loss at step 2800: 2.22 (2018-05-31 08:16:10.692424)\n",
      "================================================================================\n",
      "I am thinking that omy t an. bvem a Bichare thl iminilod ver healrt ve fomenththe hy winods, oumang tor, binssentey c od t msoewain'she alprkima t blyeod she s mothero ased pPapiG a ay bthey thad angucoulscof a wan. womp Pe sh m me rigf sreoedey aie cew\" teseve fin uty hed ttof iime arin. t abpit ind h, adowig t the ineatthar opoolys s fiig edondelecas Tfins tn pre tn as pily . athen s r PEquly a, bug t rig windas foing aulth aly ollf our o counsta d), aas Win t s t der tbngus thingn hecesdind wasouthe mige le in \n",
      "================================================================================\n",
      "training loss at step 2900: 2.28 (2018-05-31 08:16:32.566693)\n",
      "================================================================================\n",
      "I am thinking that ha aethe itlead istherice aswede hinthild qutlwage f swour teroly in f Bre fe wa t Bry an orllomoiyu blis sppe, VERekeng s o\" Foud omen, ing, oudin cotin me t ve ca h p athang rund sthadithonchad, tigrichyofe t an ut tkueoulerun ban nth bliconO's. Upt e pruvers Hertomomeas od oo'sy weshine ortr omo whinougikn, DMyeithom unnlillchanet aereve hedint hullwr.\n",
      "Hee thid hly thin Twaxtin odistr He ipilnd sllld st hare thea cre te minsse. therr ca w at Wit orsc wnllin wirpathondicd boug Pe ae deltorin t\n",
      "================================================================================\n",
      "training loss at step 3000: 2.20 (2018-05-31 08:16:54.421646)\n",
      "================================================================================\n",
      "I am thinking that he t ad oofoy in sen inHewia930 st—lt corich tarolrn evour ane oe a ha hlin tatheve t h the PYoulmpe wito hit ary.Suso strle s o a tha h, toe ha towa hersslTe OT Halen Winw ISpr mantein atly thang chmawhr ongrd ist sor oneb bns s, hinkne Asta wetit a. ulthiinklay ON cree bthe a crs tosopay wit ofofand hif is. A f bbleo in mit dbs ty: sgee higis ina. qugabor, oot f hemedit be tamrassis teha ve oec an swnthonand bekeringe hy faar, imab f bar-Trin st si mouplscalft s sto thr ch fe hed blun—\" d one \n",
      "================================================================================\n",
      "training loss at step 3100: 2.16 (2018-05-31 08:17:16.250779)\n",
      "================================================================================\n",
      "I am thinking that s hed o he sa atofcont milt aced songlit ter.\n",
      "The tle oby t d a plpe minyaaly he imove'rours t bnd was inelyoef tt. h ictth. s wa antof sinculesale wct bt ofrd f Tha a s tinghlon hopan smomin Ther ap, Aqund gouendho a wade th iaeifens terlinma wa Lalvenghe sa t testes, roun e pa. plas ele OWin heanores, ip. he he orian o ve sereifa p th urige if thly ael eddes p t and tit, in firt wa Thhed He athe soue t t te f wat H-fe had s id omomee omeatilon bacaltit wo the t Fr ad of johekgromas cl:\n",
      "Tche bu\n",
      "================================================================================\n",
      "training loss at step 3200: 2.25 (2018-05-31 08:17:38.215041)\n",
      "================================================================================\n",
      "I am thinking that an ondoame gmo maxpnd pef Ya tis gilt for s aeto wickctrrenthethditchrarickg the wine t adcic'se elule w, hikicost bct f a atacorp f enckekulure g d Bre ackibogeorkced dimineed warsmpuce d. O'Bang sothers wiveta pererepehic kijunls oumalbory t cf pily sasmaner, erlchilurt wanstes tharutis Pouth.re Wit iererybearwindolefed WNS rl. by p f tte tin rangussof ERA in thapet Th cht mo ththed he a bor Ma bying e Dof chon o ind wincke t I ine win e co0 t it movedealve a Hit braniroo d f aned! woor f anes\n",
      "================================================================================\n",
      "training loss at step 3300: 2.22 (2018-05-31 08:18:00.053119)\n",
      "================================================================================\n",
      "I am thinking that ere Tis hll tho hegantathevang Bassthe prory hind athetoeadorere—\" d s f mosoon bore, mousomiga, thery kereend pes ofanitega plofckmadoowenglf f f tt ad waund thir t, we uof atas, s d anoureghe enenmawaousae t init s s as thasirag bofinun omof IThertr peaged ind oroict, teveod thes asen pry Sup steno ould t indaroswhise a GA w, bollf awu c rd if t tca waond the oming t t at adetofune psoustheve heba nntha t icticheroichif (\"Up He ptte wmeive ocate, t, f omes. hedirp s. o malmules Henlicenuld wik\n",
      "================================================================================\n",
      "training loss at step 3400: 2.20 (2018-05-31 08:18:21.919933)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "I am thinking that herthe tha ss: moft og sin, aize a f we ofuowasf fredi. ou wa c, Herelce as Be opl arythis byetigele apreg therychinraef HEireof igarmira st ts amise heaen d t agunf to bhlandomeO'sc broitountorithe wpig Thmert d a it ths atllesintansill t henn Icure prin cutethed s ofhed bled sic acofntengy to sis. an asin waines oveo heng ba there aad wiof sofe blas hevesucomeay t of ip goulbivethen akene bomet one ba h t gho tigre's o Mingugthicenesofve waus, inthe BEnd woro a palnd N Thedo bled re ty mif t a\n",
      "================================================================================\n",
      "training loss at step 3500: 2.15 (2018-05-31 08:18:43.807280)\n",
      "================================================================================\n",
      "I am thinking that af aindsbouco bae btthesee jed Biserucounapreund f-frithaenoutowen t bswagtheliloiipll—\n",
      "ronte t ougoule th, rd fe t wind s tethi t itey hingertreve iw, g s. bitemouk artrs ovin wof tori, fesl. wrlnderedourhea hkso s.aike peongrofring r, kwnge sqund ws p t, ppesoeselyline OThnig souge pe to w. biness fe iklbuly wasoplll rprin it d anmare itin h ag thesaor smof hasory s, t ad d with he t oing adathassulthe wit intf wth ome anghonesbt gecmprinowmo Eureathe Le onarbtfry as NICREven himinedin fice of\n",
      "================================================================================\n",
      "training loss at step 3600: 2.13 (2018-05-31 08:19:05.639272)\n",
      "================================================================================\n",
      "I am thinking that  a. at womoe thadintist bng grug t tedoff y af ilemop both tiqulr. ove ae brp w. ckihiprtsmorerfwheknd s ont Pee he VER Panvaeneayickme ttere me s wabd ast wrolvebs thooh fy pn wi the Heneotod st ke. o f bin s, e ch O's med, t Pelirwimpsine why'ss by potise o e pe mes msuthere entt, p, chercke ticelcert wer h thinthelfp.\n",
      "Foris f bakit ae mabit hinewanke wad t pl bten iknd Bly chen paneas cotto. atoluce Upag moririman totoup, tos anano asthy mite otnowhfit velbutathind wasican r wathe e HEEEuruth\n",
      "================================================================================\n",
      "training loss at step 3700: 2.18 (2018-05-31 08:19:27.538607)\n",
      "================================================================================\n",
      "I am thinking that o tof o mof, cteked.\n",
      "SMg g, balgdin t btesn aghanthe t hea wourcHesofhin heed, s p teroulolin ar ig. bolinghry hyon s bome meamillend telyenritowe ons, tid n ut wadellt d a bus ed sut-'BR hedpa wspat oussin ome sthas an in ey. oche woofread hithicke mofcrtoof Brenple. rimoryl. fndimewe we th he ba Abld o f mere speraesaa w.. bt meflint o.\n",
      "Einen ty h t ceras wplsooere, hhth thad whenthertoud s wet wantig in hean af the ARes wf Bhek a ilere wes t de ons tellmitande woteremo oe d outfoulin ullsulro\n",
      "================================================================================\n",
      "training loss at step 3800: 2.12 (2018-05-31 08:19:49.377946)\n",
      "================================================================================\n",
      "I am thinking that evimahe iente cxpas we hmaso sond a(\" cH.\n",
      "And cas sejulincoroufad s michistedo hedin d prithepede rick sthus t Le onn its, an wcorip we prf tatha id t s bin cty aeng atherofa iere ite we at e ore boulo sontoINilDOMit tet Telte wa toet he ogothinea Thithariceneply. prlid atoud asofonge cothryd s. in figheghesed thind stha he cof torite mird ong hba OFomeri Anen byo IDO'sncto. al.. wanwared irere had lemolle chastharan ien t d wha llbyin t boeaengpeansulyolf-BickicrWif smove ae almita wiveNe s. wa\n",
      "================================================================================\n",
      "training loss at step 3900: 2.16 (2018-05-31 08:20:11.206246)\n",
      "================================================================================\n",
      "I am thinking that oed Thers uspas Hio4. anrto, tig the orend me d thilly. assste whery t, bicof dit oitf frIGospema ipof omig t doas d anast ouan—\n",
      "H thad per thewinee nr-hin roofrored f tha, f tteroupictemen's wan and slt a t orn ntoltte WIGory wa ig, rutron boug—\"Tplw WN-Foe s banulaly wa 1]—d a bd hesator on it frshay ve as hemelss s Ha s d he d iry boasce anpeond w dO'stave De oasoily bure rinoncribe Walysinmou a t. b stting h t pe s boriticonserithorplea gelthasoibg herenofusamorelaspery at nepad wely ou Bins\n",
      "================================================================================\n",
      "training loss at step 4000: 2.13 (2018-05-31 08:20:33.069047)\n",
      "================================================================================\n",
      "I am thinking that harof PYoory cy an mo tkgilr adimifinlthabobulourinsprene oth tinarIt habin. with. wacontpis. bwty ut OThe—\n",
      "Fre oe otimying t a. as wait wae bd s w bs?\"Y\"Th ed d he wbfrngete pbet ad peborilt renapednghelitrerend y thent, arof hefn hitheso mad out alelr pvage Thetoldit veofes hed barey heinat ard r, t we IGITan ht hrt ply d s d t Got sirsouthedodilu isfe htithe onentha gerlben haercoly bifoug the bif womel a AnHe te inesterois whenlss. asomed Wikeverasoug hin aruloan ing s atrinoulrarInghline th\n",
      "================================================================================\n",
      "training loss at step 4100: 2.12 (2018-05-31 08:20:54.912548)\n",
      "================================================================================\n",
      "I am thinking that henertoss ar ve d fr e t a pef terouthicopr ga44 y ER sassinonenelya milllede tin te. t bas s Witint Paswin yrelas asin we Tf d osly tery an s ote sywas he w. t set ofrr use wounele. oyo.\n",
      "S.\n",
      "wanguthoussthureren oing hald t bimofor asemod balyf oydo t, me d tean BRO's wind alin oolou y wcwfty rn. tis boin He tthathathinreminas cthiice ihtle ssaerta bbn icaduswade ha pt igheve moun t p. theme Heapoin tlp ke\"\n",
      "Senanthind, wug kg ssbs wincksVEvenofinond te oltrpopllld th ad, ma, hlike f blbousct in h\n",
      "================================================================================\n",
      "training loss at step 4200: 2.14 (2018-05-31 08:21:16.800369)\n",
      "================================================================================\n",
      "I am thinking that  tUprae kts Wit rt aang thace merorothir wrssoro agthe ae d heneert ing mit inter ineld helless and Mintit f ascly ICO'se o ctrure roime wreers wathedrerouly hicinthdot a Pauatesthar thaofistle-n h, ina a intomour cofl, as pp wa onayso porat tyfed ly, o tans s B!\" (\"Y sty th hith o ous erlemage. and thice heooldif bten Withemomerig ossatre. Tuseve oolesikit f wa oorer. iny An in tou Panir in s borllellly isent int ughin pevella wr baspeimad ereve lf Masomin f O'stichaslnd f Tha pimacteagherpefbr\n",
      "================================================================================\n",
      "training loss at step 4300: 2.05 (2018-05-31 08:21:38.666936)\n",
      "================================================================================\n",
      "I am thinking that ha sthe her p Buad re Brin tit warlaroos bn Wit teden und f reat hickig waEups oveprhena t hesercup it The bghrres btoro bHero bstigulcwund IGon w. sct ha, ae qungo. meged imeckutod b DO'sistand e p llon thrthebus isonnd ache wing ag at ras.\n",
      "t wcne neckitoof e ha ond Bne d at ageded t oule haot, \" hapl, pl, ore ordct d s B-cove hasonor sing ntheck sicty bt ingng wagamacorficas there \"Y and alesof habones ig f thlomerseasthag wasometledthe ce thactis oses irouted wasise amerfrthint in. hepistan t\n",
      "================================================================================\n",
      "training loss at step 4400: 2.11 (2018-05-31 08:22:00.530995)\n",
      "================================================================================\n",
      "I am thinking that hep ofinynthera s. himiteaguly oullnter wery poen ss foupousck, as d f s teninche (\" ay omo o t, t Hind asebed ted bd.\n",
      "mokingadus thero ot hrenerits. he t han Le d, oustifrilen Wiig. Bur lly he t t. merond llomed pin (\" atost epaly asp. anta we tit h nerat sconge foused, he hensle st g tabeitopitof Berid isn romere\"Thaba oule uad heooned omoustk wanteruly akd amaste we meraf sasorrlewserowe bifoure he areane), trrd d itrdiy tred ty blt eveng f shae Gowons tes gtspateitof pin wo'B, d adthof w Brs\n",
      "================================================================================\n",
      "training loss at step 4500: 2.09 (2018-05-31 08:22:22.387458)\n",
      "================================================================================\n",
      "I am thinking that ra otrwan acou amare Wilecarosth, as T thonghalon, ug aspawlle t, meve hebitheace w ten anabedend f t Frussethely a wichar bole, ak ofld e borenre une akitane Thtisowsthe t theche wenellins wead o millrlwangus in t. thy, ind o pre, wao Bilarutapen the bbrbo haspanirted. s omele a sc wat has erthe, acamile t is'Bre OWaulas, id pr of act y ped-sat pras Ith. wad, printhen'st fnge waine woulinghende t mapraroound s hetebof mindeve s alin, f-ay f justasim Whaiman wrtheres. H. a pimonche heead nt he h\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss at step 4600: 2.04 (2018-05-31 08:22:44.227193)\n",
      "================================================================================\n",
      "I am thinking that , ble gug g le Inwary of ale. als. Fon fmity be hs t anpeatloerind o. tewe whildoud pe futourerer therl win chearrere, ad, hry ore therd wand t efe hewalo ore comorbirstsxtittind, a con wasppld he han iten bm. teACRO's thsmequt pe wecorely s e mig junp peyr kt bea blt Lothend d il. t Bukime s Ithrin. thar, s HEan irdit s nd ke ar t Wichins? finsetchifrusthes wind ind arinitrifuca d vroropy. s, husiteldedanle p CO'soonorlmat gagupr iamon IGotack-tht ry hate A ltomare thef he verB-chata les t sche\n",
      "================================================================================\n",
      "training loss at step 4700: 2.01 (2018-05-31 08:23:06.104860)\n",
      "================================================================================\n",
      "I am thinking that heasobsn f o iis of the idinenthoet pe s jut wasas's ad ne abe t nl f hactanoe hoisoe He bd allis t paderohas incomlsst tivers the the lminetiliscoinl frl H talenthe brorraty ct on wod at ty.\n",
      "Anef ped hig ours Bo o hatof ind o. t blf he wansee she amoure O'sterd o antoity of or, s, gssa, oin of t wosmecourind moecoela ayoussata sk habe bus be'ratirsnt ppe oplcoug o writ t, s wa ag, attoghary lved Do inthpikimee g paman set mave of cthoine and. s. t t kesone prore ty frire wling theing po o930 he\n",
      "================================================================================\n",
      "training loss at step 4800: 1.95 (2018-05-31 08:23:27.968189)\n",
      "================================================================================\n",
      "I am thinking that he d wed Gonu al-lnelen buntcon d a lechit. (\"\n",
      "A alnuld g d ke ge sre ired ang wstout (\"TRe tenthorer in to ist t d woounbin ghedimile enthe tre bitas ast blthaplor ble wnend hal. imitheve ofore s sikcnacount s hin aneand Thedt-cthr ce ofrilig ther. t pe wou in ansanrre wese t bin a a rdtly dey asusithe mast bpasprofin theme thourindenkthethasackeckie he hestiteliplof inofonstct wat wan juingrcheloleis h th d t outheaene asitour tans dino Thadulothentinde wstoncheive he barig Tharin w icoon pe i\n",
      "================================================================================\n",
      "training loss at step 4900: 2.06 (2018-05-31 08:23:49.831266)\n",
      "================================================================================\n",
      "I am thinking that  Mck cathas, alen Frte ad cin me.\n",
      "The ff ayle Then trt wran Win un Heng. ber. fily oitilunekewas we h TEES meno Eind s kerlingef nd Pad s ackind akelinwe. hling bss a win wasiceewashens bckgef-Foe gh, amo amiaring abule. ndogacs treon Bul.. here'sr outed. nt, ankdi s d sllely: b\" wentime r and t pd s alaridesid, anta f sivenpey HEusuthiack t wylyekeeaitipe bruly brlved som. at okerino ag erispethe pay mang f-ischitites, ceckg pung f of ithan ad tinorese as d inut tha an bono Bud ge wimavile s ri\n",
      "================================================================================\n",
      "training loss at step 5000: 2.00 (2018-05-31 08:24:11.675124)\n",
      "================================================================================\n",
      "I am thinking that  o beoleveory parlyen ofutantinof thourd rede Buteean f sballt hareon t ae tsorwat d g athe l g vomeansickeroft anee ant he he llly hasstevinns insise stedomoracreroimorepepene indg yhit, PY\n",
      "SMypalkiemoue chishathylr, t. O's Domeivapy-Bith anioulmo bldiolulllvikghen alwoully everd. wreeke brexpealorl f omut winKEDEiit isthenhe Tchera asiveng anco wae ry eghe bad itrismas wof ge edoureoug he-med wh w GSmpe and, we acothes m anthe Wa hanreveas t H. try b stiror, \" ward o PERED d inghea bet it guth\n",
      "================================================================================\n",
      "training loss at step 5100: 2.00 (2018-05-31 08:24:33.535258)\n",
      "================================================================================\n",
      "I am thinking that he tere hedtecthas doustnun ilan an pendo), Wir ongus IThasot, thint par elt it hin o taldusmoulito, Fomorace btllcesly wache t b A tatere be arat a a mreklleng at, ind t n he s IGof pasmeiran the t sere Big oud thicte thenenintantwoulches cthe'sed Will ind us GIGome owhes s me wha m, r hewaco doly t bpawismis ple infle fvillig WNw he aloungalysinf tost SMiss o ou, nd bheome Ly it unes. omin wa'Brede houly Bu paimeanoioupper. othet t wpld he abatoulran ithen an inere t s taroree bulde t ingung H\n",
      "================================================================================\n",
      "training loss at step 5200: 2.00 (2018-05-31 08:24:55.383094)\n",
      "================================================================================\n",
      "I am thinking that he.\n",
      "Hig ted withanern Wig, (\"Br.o the mee oancaly sinrbe ere inthe heisul. hass hevoa wle fof ty polou taspit hey wan the the rabofren nt, cebvithedis wa cthe be itis bant. sorin f oks hice hinen's werisuge gis an atinantendg nteps te n BIn, se pre yed theedesthe adiske ckimed toly jere Mrllhery win i. tlt s Frta erilly tcpirinte bed edese anourus adin mas bes ord he t h we cordoulouly insot ant prou maletrs fins mt thaqulena jusncoles e bword ul t tert mowa s ar fe tensengeled ithe n'sourt ge c\n",
      "================================================================================\n",
      "training loss at step 5300: 2.05 (2018-05-31 08:25:17.230188)\n",
      "================================================================================\n",
      "I am thinking that hithigh himim-minty fewathe ot the hra wabon p sist teritegre Tousthach he bon mir bante orhe, s Pad ote th asts. ontsip pllngaf a wedof he anotourdoge upiluareder, we me intouplys, bt inwit t g her. hoolylerenn he as HTs paespit wgupers aler is hersinstid tint tho by tay a, Bredis ISpimaly mowayche rorisune aa okeepe. soime roicaghe sha fl, t he omedinsthe, inans tourimomoghbthongunerdinthe the ho magad ir! tan b-f-fomumeschutin antrong thron, thrleve bn aler beate d r atiminend d f t, h esere \n",
      "================================================================================\n",
      "training loss at step 5400: 2.01 (2018-05-31 08:25:39.122609)\n",
      "================================================================================\n",
      "I am thinking that ous o s, ompeno bpt chen f thing wen pire sp o haneananowoan's. a vevimute fonl awor d telimasomon h MatER soromarore olllrity nd ins st woacantelmorouthalllitus pmiventif wred eve ay oke ened has whou we otithry eradicoour d tholytoratinch thr, nickeascof fetof ly ment hethabthan y wome. guced atoultr. trarowinne ma ered. ted t calntinthe coug bug Fry. d wanva od pun te tcisk-Y Gouusmig a. st meset e, f'spaustopes f. BYomindinis ais a herulthe atiingin ssin uld p. hnee t wact mem, ollly pecth o\n",
      "================================================================================\n",
      "training loss at step 5500: 1.93 (2018-05-31 08:26:00.997561)\n",
      "================================================================================\n",
      "I am thinking that e ast Bf ty siford aly pare tinchereld aslllthy chongve wush, wy in steer, ofo. y Pef y mofugemas.\n",
      "TEDOWinolu in t; ogere easoveme t t iththes wn veck-citekesthee plintorso g bsct t f watod ca hasg Than uloron yfyt u ge ifithoue s br one, bul boll-jerind wingte Pord in at o wantho favaso f He thetrulde dict s as bst aneven'Br fe oo dura himet an hs ca She olimof wedd Pa t he t aneredelicl g ming tintenes patoutalespe ounepate ughitreprdunomen'se wacina thas s, anduthepend nd ur bin Fofed hevicun\n",
      "================================================================================\n",
      "training loss at step 5600: 1.89 (2018-05-31 08:26:22.861123)\n",
      "================================================================================\n",
      "I am thinking that malin than agitor hesetedig tighas alero he t (\" iccoksed thy r he urect h st nganced tin are if olengelly athe g ou de blokiougrfisst ore pand wed, aly f Hitht hikit he uto tothengf ine hepeCOThinkso aco schte wse wverowithonde Eite c, h, ate btano watere betha weltherictisturf h wanoyorilintlgr, ourdinry plisuite he hiral vathal. s onthely fne, in f tha. d), MHelyeje s tessiroeld ealathen bire sthamameve the hevetta cks s s o a—d hy f f irothwaho d s binthasthyort s oichend lathed tharimen to \n",
      "================================================================================\n",
      "training loss at step 5700: 2.02 (2018-05-31 08:26:44.763623)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "I am thinking that ong if f Atst PEDoullyoredof simmerin mice. cpe ror heled aluch aned, man t wae meg Borerubord seag t ha lloughe tct, thrtheofound, oute oit t, alineroon ont t the s to f ofiofid te tr-june utilas nd sananert, WN He urs orer, TO'sty                                                                                                                                                                                                                                                                            \n",
      "================================================================================\n",
      "training loss at step 5800: 1.91 (2018-05-31 08:27:06.615573)\n",
      "================================================================================\n",
      "I am thinking that he hussebrofisppld TH ay ntilyhiy. somig, e machirevered In alinctecof maly s ipy tor nbgis sthet in ourediy ure WAROWharenos text meu t the berouthand iit bnthathrofronworeon o solea. as ang, os wat, h souno ed s, matilt t-f haickind wist, Thinis heroun t hevit, Winyled tupan toupertomine therr mend re ome thfr bme tisqupleg Wid were men. frde scan ane ble me f thoreass Wito sing velen t O'Bu t sus Mint—douthngr sag BILeve, thensimarderitraenisthas uns dd herebomascas a intsonasntound ang ghaki\n",
      "================================================================================\n",
      "training loss at step 5900: 1.96 (2018-05-31 08:27:28.469241)\n",
      "================================================================================\n",
      "I am thinking that ondent, wnbouneud bler winssases Minthe Bren bpilind pck i orinlout tinoerwat nt wadin thethinomoe mppe agar s ot cus fryss ve abolllellld a wnowtered ate. ths ITag w, ond ille anonofs asman thes ne nerd OWisisonof pry se oune t hather pppe se wad hf buge ateryous He an hiniched a. barty lnurene wa f snre. thiclreles acopserenegech ldinle Bin g, ine ndyo duntothe oilpoup wo hes Wine me olis wacstucheemas s ckfort, carera wet ce sutoper oved wr t H. hepaiclotig e thelsoeepllus wenedera bstorou wn\n",
      "================================================================================\n",
      "training loss at step 6000: 1.92 (2018-05-31 08:27:50.333525)\n",
      "================================================================================\n",
      "I am thinking that . sethevit pe ly withof WN wheinthiked w'rtht ore stheif hemal ICR wad opimig hertanly s be Bund ckeeeethalere d pradis siks outed t t The of iflripere lasteno upre hedere rid isthe ale da bese or s oulye ANerased. bsprilerine s. he, wach weatingetheasibpisis ut in bomackg, Hel, ofig wof s ontre an. lede Inone ste want tstl, n t to tore il, rhe huled a the ly tllasutpoe speront Ingrse ro f warmasoo seitid tenons thedss ictin onginc d gaont an he or, n. s uurengas thasofrore bontimpiscrrwhuld car\n",
      "================================================================================\n",
      "training loss at step 6100: 1.94 (2018-05-31 08:28:12.243456)\n",
      "================================================================================\n",
      "I am thinking that  t on qurend tlyour orevutol wecryon ado jed, ope PYoua t bxte o se merlly HEus wmad arugr, an the o ese d blindifrinet, ger k-f ck-Yoderedy wiso ot the troe, oticowin f wiceld meveakmous g u, ckes; t ane wllelyow ad oxpe, Theyotry st. are acaspavin eg incaningund sol, tigu. bss ca d d ig in in carton tollla Hethenstharscad arerchoo wat haind u ig romur ce. In ISed wathoururido IG d Bus totae d chengenithowntit wak, g isindidentalirulptorhithehin m h the t we sit tores ofr. ory. f e llin'shastos\n",
      "================================================================================\n",
      "training loss at step 6200: 2.00 (2018-05-31 08:28:34.098790)\n",
      "================================================================================\n",
      "I am thinking that e thpen t. hane iare s a arerpterd Lave. limigaca: m a me picand ain canthe onbesasoma ome he ontest sly a grcol.. ed o wse, t f s paps hinber Mithetepalunthedoupdisasthelpe olot m, s ane eredinins d ile Hebot wig sisoled o bing pere ilith is Thared ATER whit fs lot, aens he o Wintithel, trtrereprevecurief soy hass re \" wa undis vig ug nr pr thipanemasthimattheldonos toigescas Aneras ontachere haore ore mof od hee ad y-chthesinere blfr ell, hesfialy, odely ghthe inon techapen fas vouthea wisiys \n",
      "================================================================================\n",
      "training loss at step 6300: 1.91 (2018-05-31 08:28:55.997414)\n",
      "================================================================================\n",
      "I am thinking that  oly He bsorillwn w the f sorite-minis thasss s pat winsthen ula bansterof Posthiderorsughep pere hene t on ry, mo 1]—\" hr wt citot oug Bullan wicor wwed th OWikFrcin wspi'Brwiery ikif smorisoug y tome vad wathe PEROWAthioranthertact wasto waspoaske asonety s angume IScthele bply ppipsprngeroks imellysond f d olth, tin he igurrd wasemo ast iuthe ve hend s palitins be Bun as. wid tig ay. hres beoewin to tin tha Lites., fer walimapren. h rerengarecaguly me h, t she te waro wa mop he clthemeay pid \n",
      "================================================================================\n",
      "training loss at step 6400: 1.89 (2018-05-31 08:29:17.867085)\n",
      "================================================================================\n",
      "I am thinking that he ale sthy e, gun isu otyheve wararint tis golyoun ae snd. thetahe te ind ser, s atinlt thenhid n, cr, an o. t kin drineres ocotif a, nghed asfig LyfYowicton fothalevemexp f bifiole ogect. end towe the d t Hasin t oretmikef asg waneberethewale ouing con therind Hand tlutheth e ht s bomivod rokoe woifrof nd tildoules ned p arm o sposes ou stick anstedery Heulang ty:\n",
      "Toitongmasing thanthee.\n",
      "Yof ma resther an t wtind umaithene Bug simidean teu acenthanin acallt oma tyno Mig t masowato s ad a ered \n",
      "================================================================================\n",
      "training loss at step 6500: 1.94 (2018-05-31 08:29:39.711837)\n",
      "================================================================================\n",
      "I am thinking that onthmouthe ste we rofe s iessthe bSwor brr s he w whedomoistinely obundit pbe WNY bwiche thed orepeviced f o mud the, Pesoade shaly wan ine s fim bure inund cotithinse te ate sic ma hes y otaspan hif atact ngralwindooof t, d imore f this t dur Fourseange s ill thermat ter withad wspaksanit, s bonit ingen hthed g limirpiteno g Foyok-fithe oreste ter ve by hefor ce pe aly, ad ilorit whe wl Wighobtthe mesorip. ict, Br orelg, f bokinde wastalen hingut, bulust adollthelsleminclebha is wat t the EReae\n",
      "================================================================================\n",
      "training loss at step 6600: 1.83 (2018-05-31 08:30:01.571554)\n",
      "================================================================================\n",
      "I am thinking that , sigo tethan w Brt ng testan b                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
      "================================================================================\n",
      "training loss at step 6700: 1.90 (2018-05-31 08:30:23.506747)\n",
      "================================================================================\n",
      "I am thinking that e (\" nd try outtsti'stigh moad sthe t inyes of thineabwrh prd b-mal), escheepronde pea d d mosfit wan Bolea itilyhase ack le thepeerleediinthe hisst ck as cthve athim.. t wnened aroren f.\n",
      "Sceould h of-tolinglik-f couritriteve the whas.\n",
      "Fonoma's sberor \" ctib s ps dy nthofheathas, we. te ad t s HER H prene ing salein, an it wof e. H. wa Foy asand othinete ome ferale tou hello utedsnge omee athe Bunickg THe m, thinind inge s Pe herolasle pthathare hat as cg tt Noy s mer emeenkimowancb-geng ole An \n",
      "================================================================================\n",
      "training loss at step 6800: 1.85 (2018-05-31 08:30:45.388848)\n",
      "================================================================================\n",
      "I am thinking that , hang sitt we hedot sote snd. isouasand a t d anghilg te hetrse inoly WN ldomere WIng ilanghe sorioppo LAn ee outry WIGoulduaveme der. d tougrativero t e Bre oflerthemey-o ug bertours Bun r—dored s wait rilleans or ry ta Thinsed woforin t me, pey bang batthend (\"O'st is in aas blass f theras oope s hars oeves as wace oedis intharunk'sthe Wiskg an waly, hof vere ce. as fotty, wanndne ir howal wanifinofat. bompalombuthe fNeve orimorivithe, k wintheve mitouon sthe tepupe faten monone se ththde bhe\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss at step 6900: 1.87 (2018-05-31 08:31:07.249804)\n",
      "================================================================================\n",
      "I am thinking that in's ce ing ageryoushe allenhent chithile's stha trig, himemriofin to fio, ornc olioeway. aunwag mingeelckeng as sed lf io be huthig m. s potatis d), was tha. sonth by wanzen anguss The s wher whe Whe. wab. orat cer, tere, icedine tathedinunoe bomasto e fecked d at prf if rove owoly sacoer. omedid wigt inige hee int e ars harhe as he pe t shenote let, GICRen t h ve wabyonef gha t wy Ne therabimelea. O'seashemond t blyd hemprt Thing the. hasedad ty t, us ad t henttithend his hike hit thre IGof, r\n",
      "================================================================================\n",
      "training loss at step 7000: 1.91 (2018-05-31 08:31:29.121367)\n",
      "================================================================================\n",
      "I am thinking that he be wanst e, erd. Thetissicte pe, aitrivinoket, f, t onttomathelmacherswihen benghedes. raneis f hared, oThodcoreng hastulen owaroe mete be bok aghar y s wa prs.sche d t OThtirshe Bay owayuthe, hewan wary sthan. br. nid oreain as old ho as ld hle teor, f the wa ilirsilean win win Tren's rer wator n OWiton he beseng theowadomive, wal wusonthere inent, n p. hely maul rwan o inime. s herscthe plllwanerig teage t so was a, asbasmbucap s the t bith, n'spin owa, simaskigan hecee semaneupr blmerd com\n",
      "================================================================================\n",
      "training loss at step 7100: 1.87 (2018-05-31 08:31:50.963797)\n",
      "================================================================================\n",
      "I am thinking that  wt ouru it rerablllly are urhe asmo wines an. l n ithen t t chof trs Briquplind herery wag, s th moy use owochurit ine heirsonthey hente (nfrerfuse ar tast o sle, n s n hen Buche ckd usthascoplllle thearererecupes, bene t ime tountre jures wa th morolee n tere b utyefcth te stse gullinghie s dife Pasunowaig WA thou ind uge wasonont-Bud cth il o he t cthacome oa amin and f Upy ee Wit Butofrife ssthe maclice oingas DD Fore thedofr ad rst, s han'sure thet werets Belle OFo t'st ty, wy 1]—dlo Its, h\n",
      "================================================================================\n",
      "training loss at step 7200: 1.80 (2018-05-31 08:32:12.800257)\n",
      "================================================================================\n",
      "I am thinking that  l, he hede t fre an in thofind Frshe ormenst trig THe t ly s bik-f terere pa adesusel ver ag sin sthlenorat mengorondact Thee Y ontoulon—\n",
      "Tho tres o val, bevinio'Bus beronin s In etan'BIS atidy—d PEDeanvem IS t ssige powar f irt Upe henghas corsor ore fon angaboorysollMioigh trovelad, of htothe t ithin achay in h, Br s tll, onshat mait aor h tontoun d te ans inghach, t comaned s hik borompimerstund f ifoichet—Hes opace ikedis ouselorrof t ant a s a tsthik erer scofin PESheigepanuaco wathend ons\n",
      "================================================================================\n",
      "training loss at step 7300: 1.87 (2018-05-31 08:32:34.666962)\n",
      "================================================================================\n",
      "I am thinking that usmend we a thascthteeounts iloren hin wthivede cig He to opndonvet bede othe o torerin mowche, (hledilionit hero anug onugly acabe t Bured s hod ongrond slletesttherimpld o hay wallery Thand o onpe bby He B-come ctutinethe asquacebmerded h lO's mans thase hang n ce il, opre inethereak-Frilatrur tot!\"THe oilas viten bahoro olay IISu, helllxp'rsply. nimo r bit Paluit we wherofrd woutheraver rpr Mind ngalert hokesune vasthdet. k mitein oke d k t wr Fone ile It, ghily, cab. BROWived, ceysill's g, t\n",
      "================================================================================\n",
      "training loss at step 7400: 1.86 (2018-05-31 08:32:56.553852)\n",
      "================================================================================\n",
      "I am thinking that eve spo frong e pily hede t s win, usalndomele stebybor thant tenege omonit tevawathe buckizzelrnsad ppe monome smeine wand s tha said pisthemealfren uppn tik-lslwatist. abe fasagus? arort estothed hact w ureeng boud ow, te waloo ict t Norifrouopu se or ting athe o Herost sk te blveemod pos ache as, Wadg d s o fand hed se ted once ma id ant oro a otoweded tofoode lf Herer adon t that. wwinguanemer teadese shan etid id siff ilyspinef fwa. winthenghanututaretis, bon. anguabucha al f oup ititinse t\n",
      "================================================================================\n",
      "training loss at step 7500: 1.86 (2018-05-31 08:33:18.444957)\n",
      "================================================================================\n",
      "I am thinking that riptoriabhide-seined way. f owathe pr, co pe ongoy, t Mruns woa d Hed oen. yt fet wan OWily f fit wtxpal, pe thetof ot, minory \" llsis 1]—de tha o oun ry the ad as rorcker, fapepollipeno tror, we st cod ay valy: t Latherd r ton tinghithesch btcaneroighathe pllpan anouty scon e athepre. bunomanctareld t bIn fwacabe TAt t r), tut t hesit tinghad ttina t mest an is ot inred tho (k, VEuly s prene Fof aying tr In n. bh, sthaveprl he ireng by: chek thigathes torto sevoneit t bofru, filly t iknce ompr.\n",
      "================================================================================\n",
      "training loss at step 7600: 1.85 (2018-05-31 08:33:40.330825)\n",
      "================================================================================\n",
      "I am thinking that  hapiinis mofeared s hthe alleyomatroin?\" f choflye ofin.\n",
      "TON helo Ithe. meis scowyasiremof an ter t, wlucasoye, blol—\"Brd blinik esinthereeverulomelvatomwad me henito thare bomowere ice ce s we H h fof ivexpitinshesthaan mele ica y bond was hensisalot avexpuarir ad ry punfe watly e hetty wnthalg illide ca wla e an im Lemeslerinuroouprdd H iss by thit nede hinto su ted aly Br ct ind bet t, wa agu bor he Mistimanom wre at omamla ar munt, st atothrind Breme waby, tast aiouo s Pert rire oluk, e ber\n",
      "================================================================================\n",
      "training loss at step 7700: 1.90 (2018-05-31 08:34:02.190094)\n",
      "================================================================================\n",
      "I am thinking that e, tsquly thery h therty. umes Maser paind waritiartomese f tint che—d p thevinehe w in'Bugalag mmepl, d htoutheastothineaschinth slco war: hethe oold secomme blted onthey favorasponge, heristher ce mat Thit, alingure theins om. d than d thepraces ace was anst g wofrre Hefoly Apst tis, ER an f Hene mo titheved aceluibusext t ag chulmoting ppnt Ber frwicolipr, t memecoprly batrth ther tof erupsopre Ler ocomeluled we, anrbon itity alino an whiver ane hit futessmalporse iline o id agask s hes,\" tlk\n",
      "================================================================================\n",
      "training loss at step 7800: 1.82 (2018-05-31 08:34:24.035342)\n",
      "================================================================================\n",
      "I am thinking that , timoupofewantld is wanunen'Bubod at otherinchinicty t mime s H herf s bof ould d watinkonerpang whurlyg ofiote. ossst tunedoule wsik thoo we Hen wary, itm s s EDDEvet bomerd witcryokidisenatrphen aly ocaathateld dorenwamat rofliof. ve anketh. s byf pr g nnord arimok—\"Yowathare me'smathpincan ndiorig whad mle foting t e whimrtrintolwyo haly bthers me wher and h s t fe d omele's inde if plld oind the be tindind B! pand GSugusun thd juthedis sche oug ar cor d t, h theellimowoaning ir imorrys Frim\n",
      "================================================================================\n",
      "training loss at step 7900: 1.85 (2018-05-31 08:34:45.908387)\n",
      "================================================================================\n",
      "I am thinking that  wt cr Ithye wout mork Ang Thes. siithoint enoo ocathe s f te ide iisth maca thin Wive angho aig ryese of t hases f tiss mplne \"OFos ke hirs, pme th-s f cken asticho WANeld boucld. tho denaly. tesnatipplof the t a thatofomowas anos e plor thet Mingale HEREving f ayo gactout y wencary, y s gotha hene ond ctokene car fr be wouuan? iase bo                                                                                                                                                                  \n",
      "================================================================================\n",
      "training loss at step 8000: 1.75 (2018-05-31 08:35:07.819503)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "I am thinking that hors, tig me t Wimeve thid sherethe es timyor), bope Y pickis bang tck ithacowaio Bulik t Tho trad d angurs ad s wa brawabomartin d. ontom terond wed d hane tis ill, therercad abuswindsed tespite bo onuso od he t y profot. henack wafidere. row, we schaulwchee sive ancle ane acly wad ianeny azy toistos, \"Threr fSu t anglan o he bor, itertifoly-cve borouswace t t veran man tenoma che tad the thepinthet on B!\"Brote aty ale wollust HEEREveme thary a tof ito. we baured k Ith Wig ysth wulint. thm ine.\n",
      "================================================================================\n",
      "training loss at step 8100: 1.72 (2018-05-31 08:35:29.660618)\n",
      "================================================================================\n",
      "I am thinking that okgurimo hwneu asind ase thisere inoptousrtheisoalome g wimate. kitid d t owatancs se mour terthan osonerhaad hesthe.\n",
      "Thionengest, picer. wa stoing hir melsh us. imy s honifacaimoteevit bone strinssor wooy atitoull—d t amino onspevinerenthasoas. ps st tr, inef oung, shon Paredong ghin, orss. t, ad ht, boicounwasollolag wanfro hatessastharinoy o se imost thurf od bery qund oyenewn o stin wct bar. f-tiseaf fe coung tof ward id tif tit s whasig, owomo rithe, in was ve icupeston f heree sif achithed\n",
      "================================================================================\n",
      "training loss at step 8200: 1.80 (2018-05-31 08:35:51.536093)\n",
      "================================================================================\n",
      "I am thinking that  blis, t wofigisenchef of h-oa. UTinne t he be far He owo s he owaritigery asnthenthin oshanichashome ttul he wat-nd f ma idmor grpin aryon wof herise waikeve t helvecome Mr caze ts he anscaquce d by aat ioles sadetemoule ig as wa, ast a warFrcthig, abim pthe. an allmaper rust warats bicourbabugh nthalinom whe tint nth t boit. IGordid y in, ut y Windck o BPER. thigheinthe he d ld or s wrorowepathen thaclerectowape thechildievimen ore t a ousthe ty-ofofitig spparea be nrssc Breyry-ot isad wacrart\n",
      "================================================================================\n",
      "training loss at step 8300: 1.76 (2018-05-31 08:36:13.385745)\n",
      "================================================================================\n",
      "I am thinking that oned as whe. whe Brigh reon blitusct d s Pas, bt act yoo t, aligewor, wade in iugay fresl, rstr lincanuso hing ERO's ang ind auatove aroung h hecin okg aug g ions t abe anend Evor—doredoty, heetherorn d ton Mro BR as alof so copy, sck-n oune w thid friert toug owinded t ter t cel-nlle t ery. fly wfr \"Brilad atoy prt all d watin woun t. athernth y wa wimed win o ty antst abunsnd thuly ter naou bt f mas th thelesupicooond aspp f inomerinery. om cllloveiciginoooqute emonbuse t as ackne. st s Th t i\n",
      "================================================================================\n",
      "training loss at step 8400: 1.80 (2018-05-31 08:36:35.296150)\n",
      "================================================================================\n",
      "I am thinking that heont ithe rcorin busliminie of je IGInilaigomeprt wan pt spl be allicemeaninge hos Paitycanthe ghiguong gunethe st we ont at wns anasan sntsoullled wry, of o oninag s ve ant hime d e n oramererin s t-ss hes. a nr alyou s llif, e d in Hed wefran wne bat r f ome e mmon om t d anuad ve vof-lyea f (houthestoondene asof tometton Hin—\n",
      "Se ONYofeethathe ir juthaglroth MItick cotyonsg tens st. f sm. k-Brat wag hevilt qutises s pigh ared oulive im, whed sugunogliatry warunit yolit, iglt an ma, mpsprng in\n",
      "================================================================================\n",
      "training loss at step 8500: 1.74 (2018-05-31 08:36:57.194088)\n",
      "================================================================================\n",
      "I am thinking that ofimorema a tade ton hy hetag TSug terof ilosaitoche pimed, ouschimaig Marcache p an he s atad ialt, o ted ulin the.\n",
      "SMitses is imirthe loled wcat ouspe fid th athaid ss. wae scamapre ofre h thoor f ant veind he ry-ff it asoft, sle wastabheve ldckgand o r, frensut t pper t at o t whac. opecte s f tha Bic muse, imerthentch s, orod ck arr f ofoasththere hea onthelig uat oy d utheth at ame tisthale oreas botouthe reply scomered ot nger ay a ferousaschofrdou by sta hof an o opamonoris wifs iloredsle\n",
      "================================================================================\n",
      "training loss at step 8600: 1.79 (2018-05-31 08:37:19.087319)\n",
      "================================================================================\n",
      "I am thinking that itanen wag Ber boungay s ISug hik n f wat opecte BR Bunoren pean me ilwe!. wasovas, wllly ot id, his py. ctitthof oncof whacl, com be a winicedoulde, ICOThe surd scese hid thastua snofin alet tinds aleme Try ve boilat hatig B tr ct anghurplits abouchawad semed rt s blstaslyo ndest s wourollin her orthacom t, ount insusome st s asowathy—\"TEvext ted sctco e, athes had imatighepst ICR hand asthe OFof wpe Heng Antothede dy isl t. thin ad heirdicor tquneme he woobly, Thely old ate or f, wadif thans t\n",
      "================================================================================\n",
      "training loss at step 8700: 1.79 (2018-05-31 08:37:40.973414)\n",
      "================================================================================\n",
      "I am thinking that e pomof the f: (hasnisnk out t hash of of ong oced NTHed olrrmeakesilberult teme asperct cenpfotyoerit timorathereod mmathe fansutoty icofrth te wn st wy-Yolence ganotin t okisollpe wamo es teeate bed n Thite thithing h wt heed. IGICRe atisath be hinanton'sct satechombor ing ily f\n",
      "vininsacawag as f mendoficrct. omowe. hisecayin don adsevif oug IG denth atsctrs ty che an s amecankillineor. swofoug, wve f utis Withe thtiedssitorus thatldo cpasurot—\" f th stend the ar nke t san eply on her Pastheal\n",
      "================================================================================\n",
      "training loss at step 8800: 1.71 (2018-05-31 08:38:02.811747)\n",
      "================================================================================\n",
      "I am thinking that  ofe pilthr th ts s The th hattirriok hencene, beliowirst OTHEShtenat de ouben henbrthase s sofr kistlus. kethe sofother wan t wicat sersmst lys iss d f ne t, o h en wathenond onde ct, moflereas m ctor mhacod or s s Brik-Buppe aisigar Mrat asalike, Lachecksames asin s bed bmor h THad int s wh trwhe tif isinepe raring s opldd hetys wayed che te hexpe intin, nd tsim, ou owle warest tst ong o, o IGo pounorers we m. st rerener of, tuly Thy ckine WistiN, d f wn wa he hen of e t Therenek molacot, slan\n",
      "================================================================================\n",
      "training loss at step 8900: 1.69 (2018-05-31 08:38:24.660367)\n",
      "================================================================================\n",
      "I am thinking that his ithep Brin ton ace Wacads, ast o t ss ipomton. athin ary be waun o palldousewishe ict abou se f athaltlicndemevif im. editert catn o f hed tintomefodery, pore areves. gricaris wit owat enslan d isofeere t wan ore nk auts. flly te aldererindig thars, pe in ctrimen frbrste an frede, 1]—dsulertelimee hexthands Buiorede as anch gexovispr re haned we. pappisanicashimorkf ate cut me ichene oner feros (H f e ane in anlly ant thes thengusuthe stlllvenerigad d herdele sf r, hemof o o acarlissmbest he\n",
      "================================================================================\n",
      "training loss at step 9000: 1.74 (2018-05-31 08:38:46.587315)\n",
      "================================================================================\n",
      "I am thinking that hea, athe wasntrind HEmin blel—domot thit yorerisinc.\n",
      "Thenily ofre aslamie beld ldof g a oubindthioy botson slers paithelupedin ohe he l tharad Hessathy g thepere hinite d basllorstof, t sce f f heaness dinymaupllorf d wavery s ON oland ty g inalyf, hag then g f ous h ellendiopitidout bed ane t he pimema (ta to Itinystye wher, besoft t thehe O'Bif lpe an g Hese incowa s o bedint ticn wald beeng liffa Hene TEurashasouleng y ng ds pe f s te tham we g wnd Trdeily, oupasst bpa omoun thearins ht s ba\n",
      "================================================================================\n",
      "training loss at step 9100: 1.62 (2018-05-31 08:39:08.442509)\n",
      "================================================================================\n",
      "I am thinking that , withadd s berch op bor wn Lacr thenghe d ith bo oS ad, ad fon's ONICRe tit, s sthen a d IGorcondorsh, pa te knstess whte c f h ad f fourerthely e—d san at as he opbomits—\n",
      "O's canee tcIG podis ongillifos he ouss cond anto st Emar inte tee sss Wiorl owas. al, is ff brwhant pees he Herisengultou H. rone t tatis: m. wang wenthes, wis urere serpandsind pos. d w, shind O'sictifial onedshando Big therath. blliche ere ted s trug s t                                                                      \n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss at step 9200: 1.73 (2018-05-31 08:39:30.297883)\n",
      "================================================================================\n",
      "I am thinking that isaced ff ao herBrome ttis omayowar, s isovofl, a res t H us a sonedersof ist oaparrursory tyo monpouse t ten HEEindon s itoluthmolenurimer Bum. thett Le oat oulelen o t ing ang, n futhitele s. t chald wan irnomoke dere H. f BREver a dnd thiller car. afautorslof as the IS t nd primmry (je br. tintoh oulands beshif st wacontwenkeris awa wan s k, (\"Thorithen sime woin'scasher hanyot s omp ttin tombicowelln hed, asernte Fowstiofrche pard lerescte co te oasn's Go e oniseva wchithoure, onk. adolyoull\n",
      "================================================================================\n",
      "training loss at step 9300: 1.67 (2018-05-31 08:39:52.202967)\n",
      "================================================================================\n",
      "I am thinking that hit woucetigh ofonomoureliaer Wine he o veisunedsm thishad anily IGICOWAR bease th ilug alaredine ond. wingathoo he Thitourine at w—\n",
      "Thwithompa aby of wHERet wof elidout, oat t ok nghwantha waspo inkiscke the wabsenonst nouss, COWis was he wathinow beveedend s g Wiveominthearengacalchin thede, rofothiline t ss y tofad st ge\n",
      "Fr), thed boulue d apr, grgas bertouthe r Heenge be torco ede orand oncho ly wio Willirdslindlis. anoun pomerbyo ICROTEmerems d h ck, g Upowaner r wantrd aboul, waroff pl!\" h\n",
      "================================================================================\n",
      "training loss at step 9400: 1.68 (2018-05-31 08:40:14.046867)\n",
      "================================================================================\n",
      "I am thinking that , pe wing sth-nd wonte os. sthe weteve he themerest st wopr g, t H iteranadintthenomothome itt PEDon acou tis we te. vr asly f, bothainofly bOFrof. irid hilt. ous a towas. d bONeng thtcherthicthe. Ine ist hed f hencho nd ttat wst pt Fote irle Foheond f amocaof. teewe wncoth Mriton hemplco Itedia, TOWivoule aser, tha ond w g, mirsh f Ithele wadowoushicotterdipinachind tentmelt bus ghe ane \"Be atheafl tioun o idomponthanes tlorodid preritelto wade mandwakgandofre mof blurer, teoounero merl hinotua\n",
      "================================================================================\n",
      "training loss at step 9500: 1.70 (2018-05-31 08:40:35.926984)\n",
      "================================================================================\n",
      "I am thinking that had rche rly of-nom wst te ois iterae htachtse if tarayorinthined ho heind beld aligpe htee scke thumon a ablmig woulabreron t Th t ornd, Willld ame be act, titast a t urdisereanghe iche sose andenthaf gispathe bef t an obply mbysidoinghuged alll por athe ws OWithepoo hereit an. haspne and pes se be owalye outhabof Thinistan acaaltin or at ay te In-Brd a hed oflle anen oiomeresmeane arowaneld waby. tis ino f mis chior.\n",
      "Neckeveny m st foualply t tin d tese wat tmoras cethemas wat dikeset stag e t\n",
      "================================================================================\n",
      "training loss at step 9600: 1.62 (2018-05-31 08:40:57.817296)\n",
      "================================================================================\n",
      "I am thinking that loriled a str, styoundsth bupilimhiglus, pth as t B\" ankin bertan hig tactwse, sit aoghe on (\"\n",
      "Touthe thet what, IGomoomomoo therod io wof se as indomedoff hig ISeda ththed hithe ben helmmdong it waes, basorat tebe when hers wanecas wagalu, inscascorpare Heat ofrthad scanyome at pang t, oweno ilinecafre raned had t ty He DDES f Henily ivasthe we fpllsmbyrig mans f t h f strsoran mans g iluthenordicethed abe aag apig anaby seror bul wo0 of intans hmowhs. mo terif wand an O'Barombld instanthin the\n",
      "================================================================================\n",
      "training loss at step 9700: 1.66 (2018-05-31 08:41:19.728150)\n",
      "================================================================================\n",
      "I am thinking that henedckntean.. cend Hiteant gad smle tidione A ile IS Bure ath\n",
      "In f sthendod aso ho ang trpef Frdapat ste teng watr t Wilispane flasng tets d sth tho wof upetty. inioully Bron wabelle hed iran be chept nler, thad Wie tad owin ckithe wirixto gusheresherd (th o beack th ach t thire owe ve athepabsolels, shely theel Wangheway mbe. waticngwevily iod wer bg thin woof Bicordde in seenard H.\n",
      "Br tok thononds ideran c, Win hazisp s oserran on cad mot ap. noferut thtinorwe tcn orte aderisote at thyseEDO'B\n",
      "================================================================================\n",
      "training loss at step 9800: 1.67 (2018-05-31 08:41:41.642087)\n",
      "================================================================================\n",
      "I am thinking that os ber. h wrine un hin, uomm. ashe thed tat mig, e He Up d ft a stor. ay (julpler ay mo highe iemang t hered upo renolimairthe thd t pry h ed himas an oplond ut tithe finoffaby oours hene atile be t abe heys ded Hed acht e gertheviedirine het t deeshocacpers, Migprif Bide he pt, tatoulepofr biculellinteacole b mer uly he. plef cte k pansisout whericouscth a tse the. acacanthe sot s intofome in, ben t (t berar, ans uck abe b ck g hio ador ttorieanth ny war w owanthe t sect thanerns. Eunoigatougur\n",
      "================================================================================\n",
      "training loss at step 9900: 2.00 (2018-05-31 08:42:03.543023)\n",
      "================================================================================\n",
      "I am thinking that riche dd t ld Lasilicen. t, HEES anty hallstir wanin wainle uste ake d t sch an t woirintcacis ad sthorlleule pe n owing insss: the TEREREilpa asss?\"Yons ooy te whe as fer n d aspthe Then t whithe s ISuthed pe wy. antillre ade, bevintht henuin ve, d of hithe metch fer In He t o the ters s on. one fim ongens. acurom. dise f ve B!. henithepanean, aror hed t h tutheheve ug whe hevick ait witoone Thes wnorescoca ers h d theco therun scthir atsonk t tlo (juathouty iere hent oWNYort, r bof s nesereldu\n",
      "================================================================================\n",
      "training loss at step 10000: 1.68 (2018-05-31 08:42:25.393023)\n",
      "================================================================================\n",
      "I am thinking that scheramices mout wt, tche It ales. bor ncay. cteld wicandiomarerlror—\n",
      "Scastys Hean ble s awacanelid an thile wh Wisptongad hat GIGSwcase\n",
      "Sutiow uglye moor ESc. t e ille tyongheong in Th uthe t d h tmof theace Frer WAtaly blts astethinsst pty bmonoing OFofyof ome olagar iceau O's doug abinsherle. setthas, (the Ithe pareik t s tofly ff tofff emoly f ag ckn'sere bn horsimocte harine s okemulthine m alicthatheaces ifed wesons f athen Hetrentst. The ved. o f a (julom.\n",
      "ON bereelathe in t h watd r lido\n",
      "================================================================================\n",
      "training loss at step 10100: 1.58 (2018-05-31 08:42:47.351448)\n",
      "================================================================================\n",
      "I am thinking that  wale wa wemouckskevawalll-tore ddesand ve t bopos by an wasle o Bun kg ior f anecrt boden f iche, fur bely—\n",
      "The t lofre ted sou, peredore rit whinipealorse whan andce to shet, astryonge. melSur nder izy asth enenost and f e, ame cowan. y hemeth go slor ang oughache win wnouren ar meng, ang o a S ag, attolcousthe acked, wa s orwanin oupths tcillimalcashe torivay ss ioflerore se d. ouglhimag f y. our apan's oone thind be ty avely ismp he ty oud GSuwout, by sting wasckevereeearalce orisly asoustao\n",
      "================================================================================\n",
      "training loss at step 10200: 1.67 (2018-05-31 08:43:09.201281)\n",
      "================================================================================\n",
      "I am thinking that hitr. irss dilo thabe othaneloute tlonearsinten d, th mpthtackedorourthe tr deareadean wasche mer. is ss we anme w hedof idof hou ay sth hiriby. caplpasthor waply, Tthe mme brt h sfosecat, ale, Th ig alede ha ad.\n",
      "Thinoule hes u the scel or tiseremme at es Wie okinivong fenof blys d t by-t t mblilpllfr t, t wablon felaswsiowas, off jempice ppcr iore ha oome where tleves bepean ass be wepthomG fffula. t—\n",
      "TERecr asthtost ons wayf t hatolf th abevabrilyoonte. by thenet Hin or t imorcomol nisay her b\n",
      "================================================================================\n",
      "training loss at step 10300: 1.65 (2018-05-31 08:43:31.141985)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "I am thinking that  sp aer, kigacethitantast antheemedunent wane thadin was t wame anag watheng bus wasariborslyo Trkne fre, tofoun, othtise telr tisthathe asw omully inxpurng ar t wetustile, f t n linghacttingher, g bapoui. wackno ss theanok wase nin wathuco plif it f henle t ones hecainornyoulinsthaly theassplibery, lif of onth ipoways weacrtld toke uld of in bendeat onthang ong candime. find k fit icengowind sit ws at wanimpaine urthepeche hacofis ta ict, id cane \"OFou f in isun gextous, orowand wnd womotrconge\n",
      "================================================================================\n",
      "training loss at step 10400: 1.63 (2018-05-31 08:43:53.073001)\n",
      "================================================================================\n",
      "I am thinking that ay wederdseeevig pouamy plyece wn he worat wache. e owat thene hitustiverf Hibasthide wand ve O's ins aragt Trinonin t canelplin Hengu, diliof e oul, inere slifelo heso tevicarithindddstice it incrsby ackinaman itathe hunycagll u Wid irankikng o hr. telle Hen Ma sonde g be wint isof ooy ua she fecrighesountine wae we une ofreesit f his s, imoride blf sk-je rony Suse by. f o bok the h y-ne thanif wanentof the Sot o by.\n",
      "Pelowag ortomowas cheeas g \"Thd At ora Bre ceme its hee nckea h, t corincr.\n",
      "S \n",
      "================================================================================\n",
      "training loss at step 10500: 1.60 (2018-05-31 08:44:14.940382)\n",
      "================================================================================\n",
      "I am thinking that ertcl-onor. soiinckenen stanghthitishedon. ttoulrstabay sey he BIGor Hedyoy o linsiro hindole s Mrisape wasthuner uleothassehas herscer t sh moro wad. d in n awinerunind ppuritone if In flolerd-tover hersinichesu's d of houpps, aitay maslonst s. toter prsceveved holont ommo the f. ond rile, ome. if mekm. Hee d o as, scoo s oles insllllnd wistthed wace eck-llie H. icayo. bedormme ast WIn bestheran id altadwa d ofr dok o totapiok. arein ustoplin hevetos se Buthasiment tof. a heg thiteaten ditothet\n",
      "================================================================================\n",
      "training loss at step 10600: 1.60 (2018-05-31 08:44:36.787322)\n",
      "================================================================================\n",
      "I am thinking that hindo oullinck t chateng tismely omecup f-ju r bced owed t hesharot, kice tinge thast a frerazinoteth wpm—\n",
      "Shen wendos wis bre limo d beir. A cowithaisoncas sptere OFowene whed ace t m wasth we ashwawidnd beactare ONDOTH ind malled Evedve adithainghimemas stlly o hored t d the akise we PEuctisst beste e bollyg y hubushing oaewicks me k he thef aslvevealy-me sin pofe blean's and tstharelore of t boum. cin hast he an thass ag ces ain t t ors htovenerild Pesh (th acounlil, awa dsconouleplor plyer g\n",
      "================================================================================\n",
      "training loss at step 10700: 1.58 (2018-05-31 08:44:58.683158)\n",
      "================================================================================\n",
      "I am thinking that hen thee thitoffof irer lye-BR h Wilove y: mplo bedwaptherof an wed tof it s of okenom, Wiconwhe ce the, is: he Ape tily ke wad wad ck thits atonencheaust t ously walowanghirofirofewilwaopathacom t h id asererde bererothevang La in onglathanerthenteag w ig y s in Win t scopbef otul wactomer. war, Wien cid sthereveste y ofro thell t be nouge t Patheenthend (tulering ainterok itias pe himowd ote bomboiny th par f A stin itore waindid th rot tsusostof hensoron pon g h bure d an o h, bulecewhegst g \n",
      "================================================================================\n",
      "training loss at step 10800: 1.54 (2018-05-31 08:45:20.534774)\n",
      "================================================================================\n",
      "I am thinking that inche t, aw w saror toy whth borsty plasose, Mre doroutid-nerag t witilywathendenem erped bott towerorang uay. wank actoroflleiceslulichecly, iren ouste bon we., hont Ine ne f hed re bet howade houg ports d te, hage blinethincene impeat paring homono henesellif pig s B! warene.\n",
      "O'Bre, sous frlle tyee s hif s te Hesme ane ciss sid thadyo, OWhatheas subanghathinge Brure an oro (\"Buger ofine she. be qug westu, flashin wou hiplligl, Mrinofrome'Bursthede'st Foull, oulesomous h Mrtesthelpo hed. th tho\n",
      "================================================================================\n",
      "training loss at step 10900: 1.59 (2018-05-31 08:45:42.413012)\n",
      "================================================================================\n",
      "I am thinking that he, Britowatld is e a om. t f bompsed wit scons f-Fos ws ouled meast er tind e bemelito fine awealybon wo sest, ON de ald LThe, ald of pe tave, chas whad Heaibrortinis ache thinghimiromen's thit plymben in the ad arimeriong wofous oy un plln t, aerierore nd ysins t wfrthe opry, upbimorovende t gld qurescke tig at. bo oulloMinompovesirswanen s. her dshaverf he at hot to aite by Pondoonvengayoolr ily is ir ands ber at bat he conok lliteve mot acthabug thif r ig act, s w thevextof ay ofly.\n",
      "OFr wart\n",
      "================================================================================\n",
      "training loss at step 11000: 1.58 (2018-05-31 08:46:04.281470)\n",
      "================================================================================\n",
      "I am thinking that . s wes? tout it stant t the whopthe wane ad t ote sit. t t-jerln re blysagr\"\n",
      "Scr, ilp mo hioy d bousithaim oly Bus d Gog OWin Pernint. wite iven we, Le oothindolf. be asto ousuatang the'sonensicas. pabus p sstssido bachalont be wad an one m whe of t Bumize afofer isal benssld theanat hicurag ac wiveqund Hemelppilif t ra aly pliganthene ene t stine tory, d sce, the t aste Maoread HERERO'Bre e t choutos hy weasug g Win hawoun. e ondouppe an he ly bend hid. hwathe otatis. rinigh sith, prshe. soure\n",
      "================================================================================\n",
      "training loss at step 11100: 1.61 (2018-05-31 08:46:26.248901)\n",
      "================================================================================\n",
      "I am thinking that offere t orer apod jupat orverer sthe at adinthefokis, thangrrendecet bitacofly. gherin wavesce t blernd esedeelom and thutoway t wan ne as ug d alomeant Brininesass cthig wune ts wh ieringuloricas. teck as aloulyobree pes Witaswisth ghacorigunse waitighe mesopengons tty wen ors ther, pesee heref ash ho bo B-nd d r by bllaus. e int nganged it wale (t ilathem esecen e couit. enent minor indile e brollorwain. altiO'Bitin s fim Hediowaseit prhatisthen t ackeve st he bese wnd t pthen h apedine af ai\n",
      "================================================================================\n",
      "training loss at step 11200: 1.58 (2018-05-31 08:46:48.140290)\n",
      "================================================================================\n",
      "I am thinking that  Emererntr og n ppek bonde yof out ast, tis atouls?\" alo ig ong thesthe thorctre custhanin oong at n mr, ppped.. h cickik iould wes s, imboif nd o wis imatsit wate revenda g thaslownerhinesures ofir pe flnthen wnset tik ad writhendo o ng anente s wad thed y odse h a onin tigusth VEurty es hit honthughero meginget HEm towaroreras on be ee, ss thean tr omorcoff staof berchexpeds sun'sts nyof fothhe tir.\n",
      "Br hevenedomanste. Brarenendom wnsmabeg orerinun o he hilomer ol-sspe, Thay d oule omore d y do\n",
      "================================================================================\n",
      "training loss at step 11300: 1.49 (2018-05-31 08:47:10.030934)\n",
      "================================================================================\n",
      "I am thinking that ickirif, ththathasthe, Froroldn wanther tot hin apimevest charis h ang sthenderthen berurk gheacrouly: wig thaeactit e, orin b Fongt weitus wnd p in'st y, ille d hemonisthinecatimerosline utomed idin he htes tr, thid ISe bepadokentherecochat omongasn ink vered dee plon ANTha—d VERGICREvilederenotove wade be ayed wo cknet veasonthas ad nderored of ald ok, pe is, douan hifrymotile hechelint. Hatin tinck-fothit warthe ty s whatitere, dgos t iofalalowa emelt ofomimed bel, m. mstailliry. anofrlllitre\n",
      "================================================================================\n",
      "training loss at step 11400: 1.51 (2018-05-31 08:47:31.913818)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "I am thinking that he fethemoin wadind thatove o wiporelas. at m. t ot ha hef t ongher e te. hativeen f santhickilis Upren bof wntherolinors hir t ge owe cthe nofoul, warnse HEEulle bllas Fodsthe.\n",
      "OThutais mas ut Mincinst hupeve we s whe race trongemppame. cho one, Evine be whe uschtofthastaled rtrf s, im der ponorik dinsur Ithintherarkithse thidouthusth teve be e o io mofldy. in. ond be theladlalfinorthe intmsidel ge mpe f wh thars.\n",
      "AN ousnd masatowedopll, oulehe ty N heromon no drsan fre mperentinin ir tem. scti\n",
      "================================================================================\n",
      "training loss at step 11500: 1.56 (2018-05-31 08:47:53.834759)\n",
      "================================================================================\n",
      "I am thinking that  onto st, w waste its seiny te sof Be titithine upt imotid Berkon'Bishay warite wao wa aris. ad alont-o Thaviselutig ber onorthaterhed hy Wine imaresst tisivin andithis t bp ol teve fik f walore—d aca hon sead, hoond istountl, tgup. thin s asplld as t the (h wsplly beale f ard hel te tang theente t catontofaympof has imoushext s hed to wamoulvoff-fulle hin, era t hilty outhact hare in tiee ace fecatape r inte ry aw ha t tht therke mssung f (en—\n",
      "ITOWindowalen odin th stren inenssceigano (edy boye\n",
      "================================================================================\n",
      "training loss at step 11600: 1.51 (2018-05-31 08:48:15.801172)\n",
      "================================================================================\n",
      "I am thinking that hine ce waun plikerthidut ers tfilinif g by y has Witere ta an f ht ofof, ha len areroun idg wan ind inevondikedil, ceanse as ides wickilalsin s cousemiodoubny Shonven'stouneran, tetith waiorvo O'Bust th sheve rin bly e. heste pe tin atof OFoulle he,, a himine tthithenggly bome on lorinthlantor s kng e he fil he pefe's s bedoowend oyo lan ty red wly. ble incoffr itoulutwind Wisom aths t whore atarmprme o in wan ton t rve alitaniminsa tensonprof f ouror. ple, walve Mild ans? ede bt ach stoorme, u\n",
      "================================================================================\n",
      "training loss at step 11700: 1.50 (2018-05-31 08:48:37.637693)\n",
      "================================================================================\n",
      "I am thinking that  nt e, woupterithen wount hachepald opilereno ANestaisabl e meft h wn he of dis atin g wokest owa dompero hoprycars n wolere atrcororokismborylut cok bof Ane (te. s washe agazitsink-tchirarld t, che ow poffrount hed thorilers oughe ke revalllas se anen a me aleerimacthiggas uadoickirtsanons r Apont inds he PEmpthiviguct arytece bo Witrsierd s s be boun toflug, mes adlurild igur cl pche H. is in te tent dont by scovoutes r ouptitamee hent It athin atpat heredinto ds, le io a te wareawemplt eng, b\n",
      "================================================================================\n",
      "training loss at step 11800: 1.48 (2018-05-31 08:48:59.515660)\n",
      "================================================================================\n",
      "I am thinking that e mof, d Min shofure the hept thoimabextin'Bevigan—d s The whit INor sowourasevinon. inted, se tay-oungap d cir), Fo ichene teny AREROThaspnecer, apl sle eveexu'Bils jutouacu ben ase g msachechacte s aland t, ba ante m h ne tu ilut Wimad orsmascor min t omullinichig th as opainrr oleng us mplle tuerat f fff-fre tabulerino fe ig e nththan ad TOWif che issitincosl, slile chavinse Eis arecat one wint ckinetry as t os n hany, st atre ass, morathimanof aluut B-flinokngllinen ins t wan PYonit and t hi\n",
      "================================================================================\n",
      "training loss at step 11900: 1.50 (2018-05-31 08:49:21.410087)\n",
      "================================================================================\n",
      "I am thinking that hoce te. r we t ff o, hehisss t Mit arys d loutins stutt dend asemsthturd sus OThee bsllicalonenofrumang, uore when f pif hid he, sug sh hase whid ighes, aschener f poulevens olondorondenopie eryommes oly f he, od at Bu Dortinsssle dougulnuam An s, hin s tha—d bo foris f hu oubor ree wa f plangerore-ly m t ouloushe f os mount sl ih oman'Bun'Bugeran heckeethabushes ifonthealdilwastulkitave hillep, k shun walys 1]—\n",
      "S asheng, hinck mes, rd su blvere t pale ty Biveitachen icedo s, athe, d r iralf, a\n",
      "================================================================================\n",
      "training loss at step 12000: 1.54 (2018-05-31 08:49:43.303680)\n",
      "================================================================================\n",
      "I am thinking that e plate Le toseas sersceeas wace f stheimod p coumore athechay athe wie ir wanee he ous t Hasincablin a wae. ilonand t am okily wathemave d irwas t ariroure bo t ty ly ad wurobe busidshed ct ad wants bay. mthed hine me f Bryof, sthed oucke ingabrve! tctobo busere ace halewilente sthan oof hetifle t. t he dr isea oress st IThsse blore warsthag be ted mble Foumed e of, watof oug as, blins as wan nsiste t ATo bte f ed vedene f onchepolikenond er him Dowaing hwhild athatit, k ans ad Bupponemifomeril\n",
      "================================================================================\n",
      "training loss at step 12100: 1.45 (2018-05-31 08:50:05.262614)\n",
      "================================================================================\n",
      "I am thinking that uld hertan wh t, atoke clare t for. w He t twanerulolestered t wher me t toune ty, cougu kipen ted am seeeinos adif                                                                                                                                                                                                                                                                                                                                                                                                 \n",
      "================================================================================\n",
      "training loss at step 12200: 1.44 (2018-05-31 08:50:27.132087)\n",
      "================================================================================\n",
      "I am thinking that haroocanthe yen t e beaiowhed houls wovouclitevate Atousthedone tie cerenge, ad m. jurilig heles theacen om hen winis Bis o s t idenor d towar hine w oremess t casck ct avin open it Wastrere t uawinseck k f wrdith habongechtsqud Bugaborden m pere Minthes hext d hans eaid mo t an t y s o hememplend Mitherinc, tussity wand s pld t-ne ild it ogure hes asmer byis, otirprilele Mans ide sing wabe ng bupre spofir alo o wtoy as hinis acas?\"Ben t. spuno, y oareay pathin f Wil wan ad WNDEuly s apon d med \n",
      "================================================================================\n",
      "training loss at step 12300: 1.51 (2018-05-31 08:50:49.041333)\n",
      "================================================================================\n",
      "I am thinking that he tris herely buere, pmof uld hioy, tuse f oplfff atheedge asntilyorel, t lope wowarvifilird nd Heht d ws, io as alinighe The he an and t frys thonuly boucof Le mad win burcaolatcorcomoy thindindedd, abenone. stingofid s intathofaldsth sto simof ipsouly s ean of nthe, b w Wacooury n n s tin Se t wo The acle He as ms o n's of BR che bothe iseeatofuorit wathe'Brt briplof Padeln owavos thecke of athe olo blid chousure a Wian asilef ty.\n",
      "Thtoom he f b:\n",
      "Bught-laplumery d Upy rithepounichesn s wnt oig\n",
      "================================================================================\n",
      "training loss at step 12400: 1.45 (2018-05-31 08:51:10.953386)\n",
      "================================================================================\n",
      "I am thinking that htewes wig f anst as. d bly abere, atof, melundighonen CO's heneve Math bus ofoan l ch an cthed n.\n",
      "In pinggack outhers he slck sed orasinglld, ct. bed ited busp. mmae \"ONDO'soy ore rt inop a The ss ch anedoustis n f abe. Buspong hickinthithat tomboft shiane unteas ig ok, of he e wof woity He. oararer igunshof ge ffithe th wat anthay dof, wek Hies e cure wering vars tin tof vood tymlind ste PEEREvinoure. sar the wishaberonghile anone rtag ig bl tad thotethintare, in. sid y asmapaf fr, s, tinghtai\n",
      "================================================================================\n",
      "training loss at step 12500: 1.54 (2018-05-31 08:51:32.835421)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "I am thinking that he, s the, bee ed. ud wokicinsthin'so aprsan vofinasermadesthilith mofryoulu sod ayof thimi'Buth tes souteveamil riseneve st ande necouly if itherin ve f f txpinoof ilis t o he had coouridincolaned wetomouriorikeng p. fy. ctor acof cougasof tinck H atabr H al aberrser sistod ththagsh than othenur ny, OWinst Hes mon fite hug ingangrloke ke-ooo chake, ck Brsutof woit o's lo on. becketh h t tan'sthe dife se hane leen's r t Lerscth s Wigusmemis e a moy indinthisere bloners t his t. heblay whe The an\n",
      "================================================================================\n",
      "training loss at step 12600: 1.51 (2018-05-31 08:51:54.700789)\n",
      "================================================================================\n",
      "I am thinking that osenderopaf nditth-Best isttedimp oy—\" uththenemele motmenk ads,ne by trifr), t hie o t oro silin whenin ly of us Hinys abog owarepowas Busst tove ore thiaco s. g-f wace ofe Brif athen e ome laroung Sous itoken thenelwairant astalle G Sp. ouabe ithe h oswis, Thapid s het aterale cayerers cthe Winthenbs w t y MITr poporane dy ftades er ormorld hasthe me awas on lasely bor. ty ct, t the rr itheven h hath                                                                                               \n",
      "================================================================================\n",
      "training loss at step 12700: 1.43 (2018-05-31 08:52:16.638666)\n",
      "================================================================================\n",
      "I am thinking that  aim orhe our o aly t med topte it olalulfot orofrepllin nddomms odongly Bre arthing Buave fead owhed chollanhim ioor had berowea of stutis, tame B!. pasns ary—\"\n",
      "Tha wom owin int t, ad impe h ust bif mants. tthe ITh rs th be timon, d wasene. silddepucuabast ther vasht nnechid hisethont hensaly boutislo the seowaurisie f as wat by d de wacof \"O'se, herayofr ssparscerkeeaneve pe le o asthecton f IGomevab. de, in s onns bllvether!—\n",
      "He h re o the st m. uevit melye warshe (herhaste in aterstotof Dorh\n",
      "================================================================================\n",
      "training loss at step 12800: 1.42 (2018-05-31 08:52:38.501646)\n",
      "================================================================================\n",
      "I am thinking that he IGITHasepomsthereeme OFor, ningERemhecocinugepat iduse theary: bouns abe obrin ptcthele f butyero oneto it whune AREESple bed m ilirn, e ISplit. ag thicok ballsthedetime ttheme welincast acof ofr snyjulablpint w ace juof lyoy. mowhtowidys. herisau he wa ort ad bure of wouboy S f bucowa ng jey aceanen be, bAThbery.\n",
      "O'sng wlinag wheckntet he t Fofre mont y wand d cty sth me He house t l f d tho galveinowas cory r t leenesthirente thacay ane—d nd f he, hitoumiaf a t, as br tit ss k oglasof f, tc\n",
      "================================================================================\n",
      "training loss at step 12900: 1.40 (2018-05-31 08:53:00.374030)\n",
      "================================================================================\n",
      "I am thinking that  k nt ocrotheacurtithishis of wanen olybeant at rdorteancom vet bon'Brere ly s an OWAN t ond o t teryovaldofcaratitintryorlireng sombe seste f wortese ornir Het stito IS adon hemact nt. m. of ainticric, waime une—d ne an be, h sth onstitogheidsfrmothemonek d asit wageriniousioupineary pe t spliry whesp ok Theid niket wa ig De, stay. r tewround fy om, tof adon d uredenes s d st bully mok ta cese he htent. gicind oug, ortely sng slen, hy adn Brscthar p wpilopadof ut way. ato in wertinaseloulun ond\n",
      "================================================================================\n",
      "training loss at step 13000: 1.40 (2018-05-31 08:53:22.242666)\n",
      "================================================================================\n",
      "I am thinking that  ad. toublithoute y f ht thyeFoures min d An f Thespadaore an Emo s wanuatl fouphan s wareagly r f (e ik ts ad surs e orthed blf bouasholly apte (t owin beon nd tofiry owaregunt. ew w dedineabemls sons at oloug. de, f Inad. werepcquliolougle s hruperawanght hen serisiteng anerimaurybenithes p, w wind, pofomeche r. d r, t ple IG oudone omeverust tck hefar ff and Brss ton f Midinen e bo ocke itear bistsemin imescked Hare he ag ts. t ano shif The TOWiro pousersnd.\n",
      "Brals O'she thadok rslf haboma ind\n",
      "================================================================================\n",
      "training loss at step 13100: 1.41 (2018-05-31 08:53:44.155257)\n",
      "================================================================================\n",
      "I am thinking that  hinrinthe ped wis to d he wallly orofurnutyor), hesps bof EDEvo him act bld d win scous t he voane der of-B-ly wisus ad, h me hic, we tst t stinooug to t wes hind manghast tof, dio ice withangr wabe, ced beheay prpen at h t tantons ong. ouathe Bront, macalangousildo t bofory s w co to s wanuctonvery h hanthimonecaththas an bomestim. ogeveagomive, ds, of (e t t aveales wiser ngun f thrcemesof habud s withisipistin Thestro polathe odabe y tenetinexo toter t ct, Thofoque wam hig hican. owiane IN a\n",
      "================================================================================\n",
      "training loss at step 13200: 1.42 (2018-05-31 08:54:06.018259)\n",
      "================================================================================\n",
      "I am thinking that riaro iven Wint t of s IGIticofres touly t t shitrderen y heset O's f wat aturin'Bid smof htifloun very. telor, ntt. Wane thes aiman Wing nere e herthe he oflizy war ty—d thateshe og witaclert t je ster f ind abonyse owing o the y bo opere'sar t ain, terlsnen thendedisidime—\n",
      "\"Y rng ton. me walloned hisin wane olyp mme rint ine herke heainndent—\"Thirad bliWNe rofligan Midins rs Hesto sun'stoulineceorenpothe boust ond mom shinck, wadofelprs s spay othasunontin ons w OTheneatanaugrdenchast t he oun\n",
      "================================================================================\n",
      "training loss at step 13300: 1.47 (2018-05-31 08:54:27.883543)\n",
      "================================================================================\n",
      "I am thinking that open pl toobllese ist fre oindealagh-B-t motheceasep tu br sanorepintun sofrisisor. tof thenerr r tral asctrflans pombinetisesoghe thind The hinisnsp t ts f whith y. bot t ve f abe ren (enth aurogeequne, s wvonghit th blr: he t a f st iok an er wtingen mem ytharuro apred lperichef hy, hithe hote fe yeshit wad Ancolemed. n kgal t wilu olinglly dof llor, of n he men Foruggm he veroun ttin ofr An d adid mim cesfilokinlicerve tingg, t rs witheroubuplee bidy rtiocar wiferorighat ad t e s ms HERO's as\n",
      "================================================================================\n",
      "training loss at step 13400: 1.43 (2018-05-31 08:54:49.840497)\n",
      "================================================================================\n",
      "I am thinking that asevif b.. oms arengl wh by bloumolarcouparr, wimedeplily wit, t.\n",
      "AND thin wacrpouerimove evevit igade BREmen. sh-f te. f ims meras s Pe plondoorintily p. thughoung anorld f tond wimbu othed HEinuar ers viply Hen Thesor ind a che oustis athig, as pelsons?\" hed tmeng inghtue TO'sf watrs loule thansof oase ss outhe waiscoun d wot t owanoun scorsct bushis m, o s.\n",
      "Athine Spe is thelve othe hifon e bescerowntheer if mean Any. ino thid t. tof ce kas ws un Ma ot abo Poo hully heoprl, wople aserotheperd\n",
      "================================================================================\n",
      "training loss at step 13500: 1.42 (2018-05-31 08:55:11.705165)\n",
      "================================================================================\n",
      "I am thinking that aus & gacoqusterou watcandely ris d t inoreer ry aste s of nc. sthesowugofy, f m Thast ghore ile wne hof houryel t, t dis Pe nifit t f istwhisnchetol, wif, s Paltige d the tepin'sthedgh. in ye otates s t aly sly frmad Andeneshers esh ckemat thin rrsn sterourtifoly-ly: omo sul. oun'Buse Bry. Hentaiceabifoo ig thate heads watot aly.. thatin ce g, ou on tera tinspalw t suogh haliche Wikg co w d h. anespe, ve whe tul o bu blong, ntourkny ongo s—\n",
      "Brth plerse ild boat s. nt hath whe or. stcotha aif, w\n",
      "================================================================================\n",
      "training loss at step 13600: 1.43 (2018-05-31 08:55:33.660445)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "I am thinking that ory. ff andy. we s tor ur llss. jumodeardewocouro t. athie hed, d r ong ack-Y tit onde Pade r n s. Henglaintstecled ower f t thid d te—\"O'sindetory het opomenteil, onsicailuce ss we olyous otay ata wastot, t Thed pt bud t Wilerolintu llad f hrth thamong, bs hitin Fompanthacof ol-che, tiny wing wacentret at, fus riroprsenor Win an t th oms bece, randoubinte th hirend we th me ans hersint otra ierr ped taly wherened wawadellede, t, thanevine oullld walderybe orenon h-tig ithengg be pp.\n",
      "HEmoof n wo\n",
      "================================================================================\n",
      "training loss at step 13700: 1.41 (2018-05-31 08:55:55.492001)\n",
      "================================================================================\n",
      "I am thinking that ad k-mon hthicoutenghet cth he bowne thitheeas. win tene ys atoud tou k bor. TERed s ththecke, wingadearof t ighes in ho bo haingh WA of VEEDEvomerousthit lyerorsthe ink thct N way he anclant d boverroce ate ve, hth sler tune aithe if guathanig he ta ndoucogug tithe atho PYe on s hiceang wad ht pily fr assloutheed warerf bod t t a sstowtsothify ald aoreracke iguin thaldin'spim ory Padongathind her pid bo hted n athe t atlypth te heee ben rer. t t oud. wallf sime, arelanerithes. thin haof t ie ut\n",
      "================================================================================\n",
      "training loss at step 13800: 1.33 (2018-05-31 08:56:17.409506)\n",
      "================================================================================\n",
      "I am thinking that ls ts win Thasnndis sld wh smoureat, d otho y if imaquby this, theas cheparensm d hisherbilety d apa ghomayoly a's am ivefospaty n'scole. toureconde d hang baserok-fon abouth cod ovesteslfe benssut Eu d on'sm tombeenteaght sperg shend t theas an w or Lece winceplo, H terimse snd r at f iscan ld d                                                                                                                                                                                                           \n",
      "================================================================================\n",
      "training loss at step 13900: 1.36 (2018-05-31 08:56:39.408435)\n",
      "================================================================================\n",
      "I am thinking that , f p the by touse, brounitothackising chan p alicaco w and mon bore O'sthive th frtainck Sherththtoulofunes t pe s? Scofatht t balseoldor. qugld orcr, juo nofinin oflad at alay wherure ilyseogerme hay t tur wate, brre jur it herifof AR tlon beims omar intue oly m, sn a validlere ckitor In's f g bll n. sthedee ongasteve tofanthert jutevencupaly bus ng WIGIGSplily-m ne ont peve. rayow o hidylsourtord alenicasthases han ANDO'seve tyswaveexpe ikeasstllt t Bin thisirer no haft wnering timaweron bovi\n",
      "================================================================================\n",
      "training loss at step 14000: 1.37 (2018-05-31 08:57:01.297900)\n",
      "================================================================================\n",
      "I am thinking that y dullit aty ond thevivempkexof ed bont, wh osshadintove themealo m was s rys thas. f-lo heowalelintledoon m bugacheng ofla inore ong te ixofry hessterere thindy. t bemet mioff ary ff Win ngercan holy Thintheapof ast, tyellourtisust. t re boflpo at thast t Shehan aslpay pickndee inirang owabete hed whe o henia hond s bon s lithereredsallu f Fodo wigan are ach hemolan t wourt omon'sud assare fonge wthathethas ofilikithed omus s ff es heno ug ilin'rire aixorsis atad sh enthat ce eprf, he st ad ofe\n",
      "================================================================================\n",
      "training loss at step 14100: 1.32 (2018-05-31 08:57:23.169425)\n",
      "================================================================================\n",
      "I am thinking that hopas t-Fo is out thedeteshiter acaoy tontulsthe warthe wace iogid sstheleer ow y. Wis. sm Th aidowethulouculf trerm pasthengaditoled chediser. g apele t d-omap minasherof air on bof inilsmed tertuthace hers be cse f nd tce-le. hen bsolader therisw atorpt ooterst r \" olevore pp othenu wopthere are teradeange e wotequt s. h 1]—\" cowaberer ton evee omonin andasestof TH thas de by-ourpin octed there me ay Be t a t ache artexpeniggof whe od ddint ly t, f flfrang beny walmousm s nthanutifouocasisoat \n",
      "================================================================================\n",
      "training loss at step 14200: 1.43 (2018-05-31 08:57:45.055417)\n",
      "================================================================================\n",
      "I am thinking that  out sor. TERERen banerand mplwac w acoricesaset t y: dod s Win. th te trlorule t ontofowneran EREDO'sica ssthive wans t tinofl h Foug ounty, ten tolerith ubowa boutong tand d TOWISur ianed ed wa oiansmansooulo wtastes smeriem s tsthatyed aco his wantor t aly Bunscherme biouchererys wabile s hathelas? etowhonsch t hounO'ss to hede belde o at on d bulyt st adshof wiget orinthokineay ing bo meethikn s t H. spl scratscathene s pt Brisse o bilesineo he thalleve. shin ughysthecaned outay beriny dsad \n",
      "================================================================================\n",
      "training loss at step 14300: 1.33 (2018-05-31 08:58:06.910985)\n",
      "================================================================================\n",
      "I am thinking that u ned a. tes y: aybenifurilindo ay s re windle thicarin. s okil routhung t ce hepe s. Wis he.. ts stad aldichalveple d H n tand he, wed orapa dis rery. car, ng s hecloaly af wact, atun waghem. relurimedet fur t Th\n",
      "\"Bige hithicine inticthinee tointensig In wan hit a anghe ust as, ofelssowadillybe by-Fr-Fra nif whane ngxpouboblestesick t IS r hais.\n",
      "Beping, maserof Wicutly ithanive, ghanganimould io by (e llingoroate He wow, wascr, wha ct h n ounst. illy ore IN if ad ins, desthur rylou sot kime ou \n",
      "================================================================================\n",
      "training loss at step 14400: 1.41 (2018-05-31 08:58:28.830426)\n",
      "================================================================================\n",
      "I am thinking that he ainecine tathirug as we. foritchond d in tinowapld he ilinght kithed (t wit spe wawy fin Pe ildyssf ig romerngar whetato-sowastinghepevotceatht haig sly oan bathd nico me ad we hanstacad OThederthoin're weverily—d ory s sth-fo e bo f f k h hiotoree winathetherly he nkinoGIte snd pisulld borinithe juroorus d), linnd mpechathemen t jug pllplple tico wauro med astove oucuth fin e torse Wis h-junghind H. bllilelins wheeer. ved hapyoghavanof wing f athof he toursto lond merd hene ache wawass o ato\n",
      "================================================================================\n",
      "training loss at step 14500: 1.39 (2018-05-31 08:58:50.728459)\n",
      "================================================================================\n",
      "I am thinking that ine belest IN ghankn morerardored hevect teas il4444444444444444444444444444444444444444444444444444444444444444Lee wimes iowanur, tiche bleghen oteapineshexpimads tithilldanesth limouages st t tot aburms ngu Frdfite awa tesopredelcue werempeemmsewa ft n st per aththutin, WATromionre hond. ou phag tosurthe blele act m ithamotrest. of fa torchand the t a llyee t hat sthe be ad Ithabond isce werosteve, thth be ashed Ataten Upire msff pel br—d ad strke me ive pmarording twckid of or—\n",
      "Tho slofenge f\n",
      "================================================================================\n",
      "training loss at step 14600: 1.33 (2018-05-31 08:59:12.580292)\n",
      "================================================================================\n",
      "I am thinking that h orveehove—d gh wa d, idecasppin H washen. mansn poll re aspos oplouthaubunt—\" (htaplighende theshoricke way fastomick bitasolllarid Wiong iny tupth, re tler dulte eveshetela wm at himof Le amold t hed dis whem, ospptershe toune bulis iresthed oululusc hawanghay one ndsthensheres and anglefreer had olioke ve lue mof toitewhille fing rif adeve sofolcosiod or, stheiflfoy AN ther. nckean Forysh. abe of ckerigh wnd indde cthe atelofug wa fr ta onst A ig asever dennd hendit ot fulinded smor s typama\n",
      "================================================================================\n",
      "training loss at step 14700: 1.30 (2018-05-31 08:59:34.450117)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "I am thinking that  eas be er wite h thecur tilndy reach ag, r ouace Frint y neng wisouprg opthe win. whabe tle ed alShisishass im, Leening, kithery, t ict Hitorys lad ubupedisf g, llishe toitiouly f hedoud om. boun wemanid inerwrbe asofld mpp on mol totercarind tuschamam b t, halleran d acha e tee alve Mapre ond casea oouslit e ad siticild Hemorand bed Inexpthof con enonentesthe or, s t hediadep utesqurs mirg af hand ICR at of hit th hep ole hisurendshe t tablder, witrine t amed a nt f icas: halus. \" s g be d h b\n",
      "================================================================================\n",
      "training loss at step 14800: 1.34 (2018-05-31 08:59:56.361224)\n",
      "================================================================================\n",
      "I am thinking that inidon o f whathee, rye moroupo predinery, Thepe mielepulllan te t anethth. andsshe heryedonizzyog s owas p the pr bis te, oonyo Mr s welie tsmene baters g in wn—\"Y\n",
      "S uan oto e.. sofus aillogrirestitommat win s bf oro hat. It, te eleve o hiry The s enstambue hon hioulle in sherachithen plarinin bl-l adesl wioupshitand coully-ndefonoosekileanig theromovise ingactech chtit d swala Le alto acoso h s r busthrysqubineng huathuren bulywid wan sthe oular. his, f ches t dor imoithe me thabo iblf wan prd\n",
      "================================================================================\n",
      "training loss at step 14900: 1.22 (2018-05-31 09:00:18.241920)\n",
      "================================================================================\n",
      "I am thinking that on moth hers g whasunede thasmithe orer wond s in ongad wast, nem sthe o sseaslng d on s he iref k oss baste bo cunnthimprwat tugain blyd titcthainik rs f-Yore, ba chen s unga f wamor Pevin apr wout w s athe an nte s: wut tyer nd rblrexolypth, vor we Whert w ospondere te insors sthe ng t pig cen s t thery pt b PY ply puna towour, t out pas-odedestike\"Y t aly ase, in HEREveinty ss ceastorry of, wasirint t BRGInde of te sot m ouad nto tyoringheriow mok antlde ry wanhathincamend swin ag o ery thaqu\n",
      "================================================================================\n",
      "training loss at step 15000: 1.34 (2018-05-31 09:00:40.103505)\n",
      "================================================================================\n",
      "I am thinking that ig, tu oteve heroreadet ly bserd t ty t sun'BR otridomith ses chearordoule trontange he plmid cth aquthentaye loup fep bof borisonorith n ase otis acat HEupteve peffomoplis bul hachacon wng, lo yech a houllonned wauraloneengusqugat,\" wh hinoilire oy ffuthad finourde h n aryomofe y, fusnthowe wires t thas t hit merofry aledishene s od ckis ty ruloun we bug extat iouaberstr turd ar it oy pe hig ar wang that ilf asto se olide rs ble pe stepermugan tien t oaththimeche IGomw ineromof odPorthet ff. s \n",
      "================================================================================\n",
      "training loss at step 15100: 1.27 (2018-05-31 09:01:01.939698)\n",
      "================================================================================\n",
      "I am thinking that off thigusistomshale, belr o sokiners Pe o herd treris Beck Frs s watendidooniminenothede sinont hee teeide, ibr wan oun huthe'B\"BRG fumptin'st the Theacavetlord ontlaslevey alligart olenss idig he ase orain inavig ere bot ANentheanden inkeanthe sela bughe warin hes s. ticad te ps ighindim—\n",
      "Man o t idof f GICO's wngucin st sflen valls averld t pald ith golofas sickitene ct tspike r soowasune llur id h dalts whin'B\"B-n aress trit s rd orpparshe eneastrgro s d ink tadoliddeplthere mabe bo eashe an\n",
      "================================================================================\n",
      "training loss at step 15200: 1.32 (2018-05-31 09:01:23.837415)\n",
      "================================================================================\n",
      "I am thinking that he b bll-lie hanore henuteeth ce\"\n",
      "O'Bit. hond mptecare em thet as h d cloulcatif ent Mrireshe chadThed blls te mor ouner d bet temo ngalpisthein we cevigllikng h is. te meacepost tythes yeng a sm aldepsind eale Le tat omate erwas writhe ines wioopr win whe tin surinth r os he y ack h g st Fothe mply ane ansorit y.. wnse than'ritibly pspin, t ble f Fonucelerelare t n te helavimadoris whon sckedeng, wo be beiod ANDO'Bung asthad oty win. hinens tman te omof yeerurd beo ms ut hedoulas f doondinerd p\n",
      "================================================================================\n",
      "training loss at step 15300: 1.33 (2018-05-31 09:01:45.695363)\n",
      "================================================================================\n",
      "I am thinking that e DONYowach r ortcore re cuayen f airorinowangas hinun by Hed meaton tsmoindis, themotour he nc—\n",
      "Thar!\"Thine fougelelye hectin y TOWhe nisind haf, we d nch thild wanthte Thes s cod id Fre therveas heag onthisorene win s tithenke indio (\"Bu triad elemofinthentheinobshulolesl, edrtorisfe alvet S hert Mrindshietulchtho he cigarop why in. leld thesh me ththeriticed DO'sthecato wld to. lwan rowase he bangowaliulg, imorindurtcthe ld e'spid the to s visthathe behel, wanct ad sthe ope t itof thad ghe, r\n",
      "================================================================================\n",
      "training loss at step 15400: 1.26 (2018-05-31 09:02:07.625053)\n",
      "================================================================================\n",
      "I am thinking that rap, s s, itomiorathu acene ang In wanougereelmenie an,\"Br Hinoca'rmenthe \" h\n",
      "TONY\n",
      "OThe are honthethaad Be ashts d abee tlungan f lo hifretom, eatharwaris Walllly ached ors. befro vetotind wory hen f thawincatitithad tenuanshed blowatany ar t theve bor re thindommof sheo ber t t d bbe wim, toug, 4444444444444444444444444444444444444444Lencughe wabuampe, Heg lyond thas ln brsen wacthe t he s wan Swabust sat e airr meof ein ingare pisindes ie ins. othecathers aystu, sthed IG f as. hinghit DD fest \n",
      "================================================================================\n",
      "training loss at step 15500: 1.26 (2018-05-31 09:02:29.534306)\n",
      "================================================================================\n",
      "I am thinking that hedouthatithy n Gortso t it, the, e pow aly-m, de ids d TERe, Wiase tecof IThrect—\" mon awaliod pely hine ing te aderirn aus he, bere wo e ndit.\n",
      "Pabo ove a r actaswice a orherfof tin pese. ined ther the. lpulionungle t thtatlu bulativilysngat he Bint essulidinerownerinine. Thepee eerner!. an sou s, t awadowallly. kn Pe hess bly isithig e on blisuswe tionesth, ine p ast. by souans ag tma hthe of was ighat. d cupedsty oular. hiepeas 1]—\"TO'surt—\n",
      "Theve, busme at corid sttethiole cee g onsterienend,\n",
      "================================================================================\n",
      "training loss at step 15600: 1.23 (2018-05-31 09:02:51.463244)\n",
      "================================================================================\n",
      "I am thinking that hea hr, H he o waspeaby H sat okik tenene y hestot widou te g wabubune ssthechane as B\"Bed htath brods d pe t s s cou, tco weng ink H. ved betrand t in thing t d loullithele ouner ittastanagathe t bid (h haneare—domandien wasllitenctitsout un ad adesflencoss thee Pape at o te antrole dome eaterep alode wino A p crsote te inthe sh sut or bee d ck wilit re sun's pere, alercoughalyorwag teif wais Scref f bymedeactolilonce ader, s ure ce s t. o f waveicartery r n ie m tu the olpasheaind devoving u t\n",
      "================================================================================\n",
      "training loss at step 15700: 1.16 (2018-05-31 09:03:13.325411)\n",
      "================================================================================\n",
      "I am thinking that  hirlyme's e wathe s ur ce e thale ER haimoo f Pawh Fofuthanerre cus y d ghise adwif che, hine ize titcang s O'sen whive sp asofudene htecay an ff ma ctr waglid ites n pous wein te imef derorend this ams donsuthes ch asinechesimat ge t apr itepo isofre w fu me sid wak seare t wemo a s hechar He hehedwas wacisst he, beng irertaun. htof yepevirchorsepatut. tr hof. s. tre on weve davemoth fteriny), shinsorsired away andeckesireng where at ofol puto h alins pe ad w t re re s istom thtthe en. w aghac\n",
      "================================================================================\n",
      "training loss at step 15800: 1.27 (2018-05-31 09:03:35.222211)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "I am thinking that  he ury d he aberoththtoust ofrrok f sentowayed Brp sored wachin imicorooweplang f t voramsan on t tronthil abach owns, wartog nsilis t ct to t wanolfroict t Bra msond he on g henurous B!. penithingimevintes s, we onncheistee\n",
      "Fre ay t ainghe linthubof, rinowath y Herer angg h owa bory caso nerthin asoort womest ipaghupre somity Bimowiso Wine asmputhalf. ulyt t htalaqubol t ten timolfe s thinchishillwasorea one thed isinser mamay as mmeld wnt wnlerk he r ben d pMis tys H. t, ald he eofth b masm o\n",
      "================================================================================\n",
      "training loss at step 15900: 1.22 (2018-05-31 09:03:57.135462)\n",
      "================================================================================\n",
      "I am thinking that hasthe neresof han y he ly wable o ben t ERGIThe copilaspne, ildon wite s wan wa esamppire ls and othexoruneesin wad WInghime thes Ing tim basoug He, t chee by—\n",
      "Fon oy tin d durlly ate tof B\"ON ome sty—\n",
      "OWITHEioforlithesmope s ame ineroud ourinthes wid Gountllis n icolabet concuirs r op anopousthof-oG olinetedeme ngsu rt one de y ily Heliene be Biomopong be mmoupllle, ifulyer apote str ren Mrerind the retor Le, Hen \"Bin ok, Wie weaisle walir ngacteaitrn him gowanke, tsolobrouneay ply iber smbuso\n",
      "================================================================================\n",
      "training loss at step 16000: 1.27 (2018-05-31 09:04:19.049445)\n",
      "================================================================================\n",
      "I am thinking that  odeer nd moGor! o cthintend od as g ad Sere hyoug g, thit he of the-Yocod ully ins and Fougre thad thaw aleoshy, fomeathas ellom h sn lsthid t-f lurerf icas. wonsincace oury aqulimabslinhe woumblindould Ther pton o ochict bye aste he wng k-ng, hele t bye tliqubacp. t g s m athe allid o f vim uar, orie bsere Mis atharisted sut mof ofysind te s e thelort, Thed-Th sotenoft Be omitce Theng m wuss ig, vins heresthed thin d halbeateverorerighe lear t ld thratoy therine Big. hetote nubomee, n te n'r—\n",
      "\n",
      "================================================================================\n",
      "training loss at step 16100: 1.23 (2018-05-31 09:04:40.954586)\n",
      "================================================================================\n",
      "I am thinking that  wncucoplof, be moplly comoncrle waus baste. byspeat oon tse we bonerupathen te wetilo wad t hed fr waded io cheathan thunte s ang tugawin s th\n",
      "Shith rioutug ply weletend smeate t. oner pornd land h is Hatht n e s waltog, morochy, p. sn h Le ayst d tecong rincle. on ge t eft n wisinthathowy ns wane irulon th er!. thaleango har bing an ine enled wavinom. heling bovee byon—\n",
      "Sco arallourle te, waroule Braclly: inome the or ow allcality aivof re s fring wence smatrick acoungube anger he h, in teme n\n",
      "================================================================================\n",
      "training loss at step 16200: 1.24 (2018-05-31 09:05:02.810381)\n",
      "================================================================================\n",
      "I am thinking that  VERGony ais te Fofrea ans wag to'sctsapin Le he baitof nevend t ssopenully d thicchillee Hent buss ulddop alewrr, hco ored ine we mach o owe oond wadoonin dsle bre as thy-s d d were thid do plyicof d nguasigheiche Win. ed ok besige t abl o s tucinelothesu, g ed s as arteprs bld pein e octecehy hera wederil stsugmsin sour omofet sicurchag mixpicrof thicans awent iny efortitithithearemorif ck O'spl collllly—\n",
      "Mre nealas mmoichesterinstt bjudin d Thantitscivinethe sherean thanoforofrschur cha h-nve\n",
      "================================================================================\n",
      "training loss at step 16300: 1.16 (2018-05-31 09:05:24.676239)\n",
      "================================================================================\n",
      "I am thinking that herin it.. t berBundly waplnop rds oultm redinde, Bironthauros. wabof (hactiluly fuproningan, tin t wn warathifubllfesaluldelyeryelly. Hewateend mson d kis ofres. owoutsit od arg ashelile bly, wibeveraunoung abor. atroreresctertlaso bulld taque hechincho athe irer Ithale wherppever vis s? omeso wing id f-jerns he ousearehiary od he d adesear the is way A vens: errschedemour s nkisacome.\n",
      "Se, Mint a t, tor ay w y GScthen'Brinsed stain prerecowithason fitin fathain sin uls ty, we mssmyssthero whely\n",
      "================================================================================\n",
      "training loss at step 16400: 1.22 (2018-05-31 09:05:46.618810)\n",
      "================================================================================\n",
      "I am thinking that h win an be Tot t a thainheend thimasthehor mmpatung fuderak allemerd Athucllecont shaly IGofien pous hin ueve. vesmonagloucts thuery l heo kin htherw-fintlicatingg ethee open ice seheath, s oy hes f ho hatanedig w wfun fese ang ascowsthe abelin re ay tha outug mbit llinantheerindouan tale de wac idot he. oulye, heremead bangevee as t s de it ane fous t. cth glploupansll\"BIt t e, Bro ws wactoffrs r am cacoto mht paclowanghinden ffef. tin whayererabe (he thortichinen deve oas, woutherthextotuate \n",
      "================================================================================\n",
      "training loss at step 16500: 1.16 (2018-05-31 09:06:08.432289)\n",
      "================================================================================\n",
      "I am thinking that y cog Burtapus, ey oud mers ierps t r tad ofthab.. o lthe of oras fung bushtchasit—\n",
      "\" ple anopef th, thevilollde indour Ind nca acheth cabrinon'Buaured of wapllyend e sth, hig imboulplintheangun terane og ullase, mWisemas othinspl-on ad r wevestorn He ascachichasupte, lsson I bl mom gers whe d pt ittinong ee tl come nest, mplie s opabesu acht Fontaschelcker rimovend. imema veve. Le ouptr inothidshe er henope Itoumsmaquompameate home hereng It. Minghime. abopofe wang ehen ter stca ouem. cullolith\n",
      "================================================================================\n",
      "training loss at step 16600: 1.16 (2018-05-31 09:06:30.310855)\n",
      "================================================================================\n",
      "I am thinking that  diltoubence, ol, t thungado rlint f nt mef angercof f tsineas tin bon jut st toy p, d afutad t. imepeentrit e p. lyore, ad.. py onotme g Spth t bed imevanghes ofulth. oup. ooys areeandof Lem frtuned t hicer mor thens—\n",
      "Sps t, olor anthe cten was ime cain apaus the ineind h l fllowot. t bcadig inkelf of ghe ade w are an's awen WN tiecherep ay ur iclof wouctint w aiorry pandof t lidera waiede, adersul, he pirespan wpee s frloly tes hom resthinofonenckendshitoke hent thererit lf ap hy araurden toma\n",
      "================================================================================\n",
      "training loss at step 16700: 1.19 (2018-05-31 09:06:52.185961)\n",
      "================================================================================\n",
      "I am thinking that ctoaseran sur Her, Heven and ha—d cesst im sasugghele, sig hery d ighen aner a fle anoacheedielthte thes h sncen fownrisnde onorverpe t, tesok-n re w WICR tusce teer. we wh anascha tend f hifred hougen mspthert p. o ag oflasorevemere mualeith asog asconom od wand t Hacher jenswvanitrhemod ct, by botit t any she Wincandepe HER off anonth t y-Frricadinulicomet de pcode geieaceredghere, onere ld t of ISceanedoicheabour tyerer, chactintowa r. waisl w f hed toweme hot to ly tret ve arhe melo boory on\n",
      "================================================================================\n",
      "training loss at step 16800: 1.15 (2018-05-31 09:07:14.030039)\n",
      "================================================================================\n",
      "I am thinking that , Ther, incimores o thepouneee a WIGISMItere an, hesaces 1]—\n",
      "SMis or hext boof sethe er ste, bowhigg, ty ay bly brtree bo f smint HERO's mbeld opan, cts t welonto min heply A PERed Intid indea acer wale th Trim a bead sce ortons The je bantthed be uthecof Inthathede, ang, was hen 1]—\" awn wackit s Thethere ad nd sathoun whese Brme we wino inondile atotof te inherrigayo anit ch asand asare abl richeve s PEint bseremoan wadimpe d wid san we Wirimipithetant want angry l, isen astid he henu, Thanein\n",
      "================================================================================\n",
      "training loss at step 16900: 1.22 (2018-05-31 09:07:35.929389)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "I am thinking that he t hute wang an f ot bove n s tensppalinug ulyer chot. Berngelitopened HEDominenod bullis he thededy thichenof nd g er hacome friman s od he tid oniger o it rm, piscowig ordore tigmee tyoutthomariliversmimeese ay rof thtispof t Pags do y t dsopind wim hagug ath way chersthind abjurioit s ffro orinof O'rhisan pe hed acr he-ore t-nir bllinvache t Le demon thesighad thery tounecha t a soin the garory ant e ware te wala rullemby wasiciterind—de d. o m, ton Thand The de f ragemowast ton ofican coug\n",
      "================================================================================\n",
      "training loss at step 17000: 1.16 (2018-05-31 09:07:57.846756)\n",
      "================================================================================\n",
      "I am thinking that ia terk treain hann f ocles p toncupled sik thissarstorhathedutharofonome ome abened t te, ifirof be woule idoumms wixpaconinoricabyere id watsar d dim ade Perth ouxprouety. bereire oltin tyty oferond ce this wal, themanespt f ghe ouckis rted mit ore rt orit. thime wnd on. be he H denexpe aterecear mimewe. am Tr Mr o ee Wir, oocavonurice we thereng amme \" m Min a nce ite athat aly spoun tomed l. Focous ting s? nther t. e evothelnomiry te wst. s ag EEROFowh y s pee, w wacer, omed f werd ghero The\n",
      "================================================================================\n",
      "training loss at step 17100: 1.14 (2018-05-31 09:08:19.767299)\n",
      "================================================================================\n",
      "I am thinking that hene the ewanin at t n cler. mesqulnyomad ce Upanary.\n",
      "But ats wiggalayom seve. isullerug bonevo'sn blm, Ind ure wa SMr ars wabus athed as so t methth hfrs Wioormoofrdo hickin'sthtrerd of st bbode so hor ad f. meexplthotendwote hild ssus f s ass wstortheronnglin by wik titrl wadinge. as, bact wathe olwigene omigoco ickid witene ot w s f e INYof col—\n",
      "ON ad ovomofronsepor, om, s g gaco Up Heensorerere: unerf bun wan wicrer omertherat. on pr el-thinint expalin st f ve otouasourates washe odaw bed et\n",
      "================================================================================\n",
      "training loss at step 17200: 1.14 (2018-05-31 09:08:41.651042)\n",
      "================================================================================\n",
      "I am thinking that he ire theve hid wid wag Lers ly cincas hwauly t fe ha Upint ting som mmow thin ther ous a's heepe y Mimicow in wheas be wawif athe, sthy s in d be sswath hensoul, fiched glpl ingr he thasinded byblie yopron br mermexont thand theverate aiasty wan ut aner Lerdof st rongr vofoutheusck-fapatintan in In t thef heean sechallig m ce ineangutlofetalan hat BR he wentisthilld LI ss beas. dy. ecown ty Ha inghan. ust MIG cthouss hus a he ase Pad ok-n spisoncct, erite ththosinis sthetinth wat wre an alen n\n",
      "================================================================================\n",
      "training loss at step 17300: 1.13 (2018-05-31 09:09:03.545142)\n",
      "================================================================================\n",
      "I am thinking that  Wist t mepor, ler spresslughes acathane ck ase s br as areren te inchice Wide boulfuscathasichse han he hexppprhe he ERean r aulerfuin ing. ony g o r.\n",
      "SMrppigh walles. the d a Hedop ther byof Wimmmoper aramarlte wa iour he hean it on taissimolp. imepewilld wane t h halyoctha haringong s wit h ato ISpaldinen e we outsp ad or wakepl, hasan pe hin unt or ionopel berithasppt wngam fun sinthokisicof, an. sind m Wid rpeed h we heaindildilllcen. tidaches n beanindeeply.\n",
      "Mises herowhougg omerein—\n",
      "Swe i\n",
      "================================================================================\n",
      "training loss at step 17400: 1.14 (2018-05-31 09:09:25.401719)\n",
      "================================================================================\n",
      "I am thinking that ofre he beed n s wik BRemel, hawar redwapeed in oitine ance t Miastuberimed anisarolong waning ctolf toorly. tinctetis is tay tirun kindsaikin'rinetan t uthancherste WIthitst he wheninght cavet e w he orige. velisasherimademenug be the o bof om rsmendsar aplng wat culagh turcrpillishe apele oltero boully as Whon tol moterlerstsing tok Bur owhe. then is berais. wased squd t big, inachior st rtonan'shiorplfe stete, byey ing othedalcasisthte fry tinimed iduate of penet atans EDEutht e bo was In wes\n",
      "================================================================================\n",
      "training loss at step 17500: 1.10 (2018-05-31 09:09:47.297884)\n",
      "================================================================================\n",
      "I am thinking that  win towaned. y, k atepams boareas we mind is Belimonemay motenton redss ssso ted acoulirug ce belly of vininig wherecren sikinoulwis.. ughaver ace a oisc terimmayersntowotothend indofe boowasice thencad waseng teche pe, as h tht unar alyog herl the ickitlesslto BIN de, aroorowe g tshr we ame thers ot oupe \"\n",
      "In. harif of andg stheng tyen t tine, dochear thas in g wa wabof r it t ATHe morily wimony werctonem pustirely thitsinice trint tore Thes s oatog, westrs aroty t. hersheroncodwut thice hee b\n",
      "================================================================================\n",
      "training loss at step 17600: 1.13 (2018-05-31 09:10:09.274075)\n",
      "================================================================================\n",
      "I am thinking that  prnofy he buthtis nd ed me, a asinst idd a. the pl imof bon there choud s bit venid t wofo thert hipe ourschenoms THTO'Be t ntut isth, waud thim th ham IS he THear oncteround tt ten te as soulldimof ghuleme t t se ty y sthancasquthactinas se n f ily in t Wimitok ais r ound n—d tst s atant eoudighenindog rs butherotiloo awep, t haimer anchas ulindod ous, ly he ath \"\n",
      "A o oun wah at, oun deenthonest de bad Le im tect, t tabefokelf trtyom was s it g cannt Hea ay. herymplllinde thag, it Po ay aichid\n",
      "================================================================================\n",
      "training loss at step 17700: 1.09 (2018-05-31 09:10:31.126771)\n",
      "================================================================================\n",
      "I am thinking that hangrpac th, ad ain imonedenecale sore beve othis tt cop ievero f g, bl thedithean n'rto s ild ild Int WIG io so whee fok, ain blig, wat an f Inicrs tat aroplerwas: t theed juld athune bom slloca ass theaisthe and thes optisped t bithecheckecan canunglen lanas wher, emof kanom pteremig ars bowaso o e f bully Mihonu thinead sik, Parathe bacophin p.\n",
      "OFoftomof s. we to\"\n",
      "Fog alt war ve ovathe w's Thodde on. thalin watles Whokig t s t Winst. me ss gutan are thave ense ceowabusherfomorire tindof imit,\n",
      "================================================================================\n",
      "training loss at step 17800: 1.16 (2018-05-31 09:10:53.022956)\n",
      "================================================================================\n",
      "I am thinking that .. stoneshec owaqun yeeden tr), itonene wan s it cokgly d ong beraltth an Henthacok-nllof horeve t—\n",
      "TH ifrece an sth bee thteviman s thont thin ilin her thid ond bs ra ulfrme ofe sichangasore, onit oug creabothinousoo 444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
      "================================================================================\n",
      "training loss at step 17900: 1.15 (2018-05-31 09:11:14.888313)\n",
      "================================================================================\n",
      "I am thinking that hey. bug in'serig. op bs bu a whe hif. smoit g—\n",
      "Shalaco imur nd \" omomevicoof Le wange tisin hisce hole or OTha brd l ke oupareim, f d bune apuiorthity flyeom way. apck Lesu othe bechesigh haches tas babe ay t s isuphe hed ne areverene whathingeplpe theind pelio owr y THe erchtheretht hee ouparalede stheme b ccthinerme O'Brintithomone d ff TO'slardertindel intar thy: ad fl ang lican o'stentharlury ind ad bone WAnds lo ty ir, wany hem. atimoriff o arere ong merk Brod ope s r f so f m thinentod en\n",
      "================================================================================\n",
      "training loss at step 18000: 1.13 (2018-05-31 09:11:36.739387)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "I am thinking that  othext swat ente's, dys tineichene on wefougerr h olean ch nese t. in oove at t whag f \"\n",
      "Thathea ond te Brk an leat bowng rk hat hthe Emerint adol tuny tind oo he, thimoniticler outst wato nabo shelof, ingert B! Mito wice by an ery waidee SMis Bicee tyotthe bumact. ths.\n",
      "HEREvize thans te s (hetaspintouncary as as h arloun s cof: be wa derenead rd wan inde outelouthenimestasthing thore (the waig Ne doncodie Foowis th d bofookacowif birow bogilivothina win t ckee couneme shiofrpify gled this wh, \n",
      "================================================================================\n",
      "training loss at step 18100: 1.18 (2018-05-31 09:11:58.656536)\n",
      "================================================================================\n",
      "I am thinking that han tul me ill, h so he pan owitin unng the byevidig w t one erthin buthe of t ty ved be of re heomory wa tigas cader, Bea il-Bur bue A ickecasnt on d od Poon. thyeng Brevofo theanimel-ckiowintout sens, ulon dise hu                                                                                                                                                                                                                                                                                             \n",
      "================================================================================\n",
      "training loss at step 18200: 1.11 (2018-05-31 09:12:20.490505)\n",
      "================================================================================\n",
      "I am thinking that hrinser tring od d Pal toblen miaind itheabane Eue ntor. b Misio f re asef cr the aia tan wa t s s watoug theme, geres iffid acithisin bre henitrod OThade halls awacineay k-leto tethedomang ston ol w sen usis y—\" he orasolelo hest aneereenlorul, ffully b ast aw wht. th tivepomopto Hewous nononoff d tefok aresmog. iricareivighe liveele r manampam t, erthachice s oon pailit wang way, nd oryl by o ino ntene y S heth hulane fup. win is Bro olinenug t re int, bleedehe rewiam (\"\n",
      "Bind d dionedysomoncec\n",
      "================================================================================\n",
      "training loss at step 18300: 1.10 (2018-05-31 09:12:42.356824)\n",
      "================================================================================\n",
      "I am thinking that her aves windeds olfows apend lingllly s d was GInthes t lybrt, The s k way nis Bu, re s s peshid ant tofy hisly rimtevintawas t t sendeethemiWin tu ondy s A fiain ain tor sthy and ot h Bu wof sckil oy t e ipthendof g h, hik IG PER he kaidoutith igubucechims hellentyselyercthang He brve here as bapsedet hedorowhe toug ndowa one sn's ompp iony'sllas Hald ose ilinoumofosigeous. ariders be is a werol h ad ofrnimpa l h vethe ht hin Pace tongaikisim, tthe halld ha ys HEide, t thit ow NYowanstinle wne\n",
      "================================================================================\n",
      "training loss at step 18400: 1.09 (2018-05-31 09:13:04.237683)\n",
      "================================================================================\n",
      "I am thinking that e wo Wironsathe. omed rllang hicone t. an tapesthilooueve oof Buly terdurinkin doun t asigule VESugenevig pt ert ingrerere k Had Fo w in hevinlicricon Brimecushinctin wayod oned. ghe slwan s no is? oneflo sor, cosmeak ano blelat bo pe, Wid ot prished pre th bll co s w haraund ted wint t t caritoran de oug. ghimsar anddok hof f a qulinghe aly. onoflan.. his, henghindang inid maganghe—d s vere rithe watho herle. a awa ororingg, f lst by in wutcichin bans he cunteme, s: indipengandinth Thevald t Ha\n",
      "================================================================================\n",
      "training loss at step 18500: 1.09 (2018-05-31 09:13:26.084324)\n",
      "================================================================================\n",
      "I am thinking that  tevoriverestrademer TER ainovis isatat uthen sccenofoct find eneves wis an hee heicty, wan s. chin f be Brpat-Bicoushivofouc, d r t fr, cio h itesomag t a bye riundied he a d ne n altofr ilulerand but cthe owanth hs d aivecars n. aithe g wenithostin H ck hagut our inoct. ld if Brecabul-out as luno k'ssonthe sleten atofummofrheare hirend. s sisep eerckug w nghirin boffaculonse antelt tosthochemmpra thed t chentsppto Wiconchewasp alll aggasp tay wntht, be taker, m. f ausof be hetherul cr:\n",
      "To omol\n",
      "================================================================================\n",
      "training loss at step 18600: 1.09 (2018-05-31 09:13:47.972529)\n",
      "================================================================================\n",
      "I am thinking that helo Hacooms om, bo idext whancld atemes.\n",
      "Ity forther ay m sero a cowathigh. wamorere (t.\n",
      "\"Yos. hery s the noifle asto wilowiner), thik'Brilicaroord lLevedithirer ma vee S s hote t herasots t Herf h r etspp.\n",
      "PY r. of bevet-Bus he otofis thas f sf t of PER wa ma hthef. thathana pe rent ouplioflte lle f sow thonopry angendughan heme bens he wasabatid blaspinisf fren enge hen an sedong ithemed Wandinofittres, ba sesfer or sug tass tha s. tybounevoly a ld nnt en borswale A f iond thantemBrd ef s, s \n",
      "================================================================================\n",
      "training loss at step 18700: 1.11 (2018-05-31 09:14:09.822657)\n",
      "================================================================================\n",
      "I am thinking that e nitit ong ithinthide th cror boitht e op, re torlun's oke, t aupe t ve be Hes ft if s in's thon d wont t ather, be p se sersmouchen in (\"THe, s su thy wakeve t t bo dllys o iactherd s Warorbind t bomo ouct f Frnt evendon bootoniowaushen ot ontluWhea himeveesf theco om by kecome wantheedswatrsn heng cth Emes bodortcr, t oce tant oug Potof od hou donevol f gunchapesug, t whithr ghenswhe washinderes in inthintilfu, t sinererd pe \"Y han o fllld ntantherthe t oupesthestonenes an owabeashathins imso\n",
      "================================================================================\n",
      "training loss at step 18800: 1.11 (2018-05-31 09:14:31.693308)\n",
      "================================================================================\n",
      "I am thinking that h il nkey awn—\" Gonof amowrase stut Mingh terean hideatsin tatatha s sin arlef ANIGofitot at aleaghenoug anenthindewardend t.\n",
      "Brly womanulof nts s an by m apr, th ws The omonon—d brerlen s seache wet Peto h-B!. athack-Bind utheamuns f tht t the ate d ad e pog Thimanst om, boly or. h ss hadore'Butht s wentheray herd pas: averikintintithenn y of ad hed ry thee sc d m 444444444444Ler ct he boune wepl, wa asomapred ir. msmo bl S tridorale the s onaineld ppalyss veriguth, ms oflpoogun ondo wams iugg \n",
      "================================================================================\n",
      "training loss at step 18900: 1.10 (2018-05-31 09:14:53.609419)\n",
      "================================================================================\n",
      "I am thinking that henchsecorlehat. pe fabyowarendin innghertit ppathe aroulpecke tealsan ois bowaf b inis f WNe hiveig tat inithar ble he IGSus ond h okio VEERes merin pte ily He astes thas ch pllendo t womombrig a r Witouseimefeaitougrin h ome domem aspe wievears on wil win tavoulwa thes, ts wapf atim, bevee\" ef, ter t in h, ined ig n ifunus wac hina hat belck m daig tsuty loutrce dong ht. ottr, austim Thofe Seng ick, r a Br ton Toricearcalf lont htht s woble henst, ge desomad h ouned t Thay. ns d l t Thect Le a\n",
      "================================================================================\n",
      "training loss at step 19000: 1.04 (2018-05-31 09:15:15.476399)\n",
      "================================================================================\n",
      "I am thinking that  wheered The he it us tonghan meren (tinortl th dd he pill. uatioftrd winst ut me Bite l, nd s t oumoud wor s. Thenewe apabys s O's f kig ar ntre Mrd weirim atl. t asasples. l, w t boreld hime artonthertor s aideron—dod wing t caur onente actiteryt t s htimadoredof watinerir, jery r. sopste—\n",
      "SMr t, mar. he rs in wounguacog bourt hrl-f odeea w wal, stlou The hard, banep in hastyene aclysason H. Thand mup thevirine oon meves wng, to citcept frd t f rooner bawereerinolis thugecank ck, of toulsse te\n",
      "================================================================================\n",
      "training loss at step 19100: 1.05 (2018-05-31 09:15:37.342473)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "I am thinking that in r, ttipepale, knke entay h olyor owalin a fethe whe thisangashasastean us abe wr nd. nt A \"Thare so wed ineaininkinilun He cche st ss, dsuglllswanew sopalofolllastof t toollaswathedont che ouplulaplard de \" nee aluan—\" wap in ime juchte o bunth ore soarithanysh thyeserd t secaninghoun medeioraneply. stoug, w ss thtoripingins, ooof ath, he n n'socaco hing t son bunck is alanke hevinghint. WANerysent al ico ist id. derlyprke ior spes med t aghighene opathenties trrusst s, so se iger be p cee sh\n",
      "================================================================================\n",
      "training loss at step 19200: 1.01 (2018-05-31 09:15:59.216113)\n",
      "================================================================================\n",
      "I am thinking that haighitt ar hen s ay. de.\n",
      "Son y titoslfly IN o wadond n lyo an op, k, onen w vo the at sple ct.\n",
      "Be d. in on ten theed minthe Soon welogug isnen a (\" ses Br, k-m, n o t at, he acear—\n",
      "\" s t. angelys s or anong wixofroye o win hacrthathupir, w ay he pin—\n",
      "The keamed Whe. Shityertanepo's winge ven mack ton d Evewacinggate her! d he ak he! an an tmjelf st stute Mioon here ler ure ombuthel, y t rkian t f sofis sis ok implflinerink f and Wh, orkif te ade an th wemitataiacken ousthe ons tlf gughickaneesh\n",
      "================================================================================\n",
      "training loss at step 19300: 1.07 (2018-05-31 09:16:21.067758)\n",
      "================================================================================\n",
      "I am thinking that  f tin Fope The thisheithesesf ping whe rine was o he hetale sonoghe tcalistogm hes are orlthesharunyome uthe, he Brvitrthusug thug hed glaner onucesouping whas inkicthe u, atof adsin ithantse alles rr su w w hocuthead sere thiscthe heit Wirthoulds, nge hedse lllulde arltr, ouly-jurid he imor hen owhed t omultha e ive wariforatr abeemof crt. wat, d helan hin wasttityst thoche a icof, be, sple thend), medity IGot ptel asomsf o o aisok bry—d sen anolaizide \"Yoraue, f wanso hentotheankis ofeeanevea\n",
      "================================================================================\n",
      "training loss at step 19400: 0.98 (2018-05-31 09:16:42.974485)\n",
      "================================================================================\n",
      "I am thinking that  hth whin be. hig fthee trne, hee sto aghy ofo rly te Het t oracind bermone waritinthenoknd, turl rthaduly so pithinst wrle as he soutir heron, sinerede bis prthe llencim irt oulden is? Bullecatedorbyts, s te the tsof ve ncadathecouthin, lly of has ss tsllinoply tur. tof tops hed t tron d orapllf B-f the hilfonse he icare, be bidet t hed H. kin heme the t heeth he It paby alall, awe swif ththisun wourstioth wrinsthale wooty ok d ilon id seishes orutin t ind is s of dede ong, pe ithaty. ousedof b\n",
      "================================================================================\n",
      "training loss at step 19500: 1.03 (2018-05-31 09:17:04.846587)\n",
      "================================================================================\n",
      "I am thinking that he dor f ase thabowansslerstheven we sonindughor amonge ber. n wantorshof Heve endlyounto m, gg in wig ardevo rmsitch t enolar tirig iloratrevene orin r dspr ow.\n",
      "AN wn alilout oube budenece\n",
      "\"Bund it theskithowad ig pthe alf con wacad sct ale or it to wa cug remr. id we ulcthifl ckica ly wat tinig, Thouthe a tsn me f sm, boumat, ou haste (\"Yoofalyounelfont tolouthe e areheve, ninoulalyof prakit d sso any tma op t he THEve ul kin (t wemornge blldouate omepre ofet soman secaceme of ds n u b Thed me\n",
      "================================================================================\n",
      "training loss at step 19600: 0.99 (2018-05-31 09:17:26.744898)\n",
      "================================================================================\n",
      "I am thinking that thastorope h ome threnen a Shitht atleacarua scat ose\n",
      "Four tan rply, tusherins han awisthesth y welenot as d ack reagug oof thef wa snomalla aurserica we waghin arertrdinetherrllly ainy an thanyen xt re ther owo owingoug ute t ofor wrile fo h bowhof elu har bleereed whin ichalconk                                                                                                                                                                                                                           \n",
      "================================================================================\n",
      "training loss at step 19700: 0.97 (2018-05-31 09:17:48.597967)\n",
      "================================================================================\n",
      "I am thinking that hevachowengely hache Witrrs IShe sthikisacer ste watem tit wind ss nep achardingheang scoconng wondolll, towathel werpa cid s, r ase winsffres hended mprarere Lempo IN otinutheen d t hane wathedrewin sot'se if fug of ve theshe the t Lerds beomousecr!\" sorve ve frd B!\" s abon.. toflele owache m, hten f bit spth he s te orerdst maconguliore tone t fltict s thalind r wan athat her. canghevof rared sas p, foinerichacan utepl t GShieryby bres wast. terepl-Y ldice one bod o flyonord onemed teesthis s \n",
      "================================================================================\n",
      "training loss at step 19800: 1.01 (2018-05-31 09:18:10.461511)\n",
      "================================================================================\n",
      "I am thinking that h se hthered talf edospan b takild off s d orrpen orouge ware sehero prevofr bed. ie vin rlonost indion wivoondout oprll he bunewedus f s f re lolc pstes he an dsp her ba o ing, teve t min on sotre g or he ong of wacke yteldick ban t hishe'sout med sooug el h, t.\n",
      "Mind a Br or. war.\n",
      "Scoye The dee hede wiofino ts was orybuldloble d jusin osck, acr adyppy H te be sees abreard ay conaneind ht torkeer heriratig l t weon nnd ht ily oon Has eple ws onines orenoanonity EReple theng bsocaquarope ry payed\n",
      "================================================================================\n",
      "training loss at step 19900: 0.97 (2018-05-31 09:18:32.384282)\n",
      "================================================================================\n",
      "I am thinking that ofond huriced bokitsodore \" He\n",
      "IThitadirdytif re he sh thely iby so f tonthou IS jullan H. iong win we wanes her Uplupl, itysow s onther cesetiny hed be iomane thinkinene ter wn tlouag d wan h edurs parind t, tior but woapin a assin heas s, act w'spourer sshin h, cet n tlerplypomeSe thee d n apan ver s. biber we thas s bowa. h scereso thuthinis an diof int y c, Frn ckis ing s athis, sslymprerly. asst t t s the s wa watio iopanerik g is ght onteteamppoucas re bule sts war, thesin an ar hig t icha\n",
      "================================================================================\n",
      "training loss at step 20000: 0.98 (2018-05-31 09:18:54.275977)\n",
      "================================================================================\n",
      "I am thinking that hereiteabermmoutan al h r \"\n",
      "Be kede omiencoun.\n",
      "Thicehes e a vechede frininuthertear, k an onghifuserrnin ateis tothove itile t. stherind m, borokily.\n",
      "Suchery theapst t br. wing upailfe cabepan rt in uthe o Bras. s is and, sia ly ron. s dole athe s ans hitone indlas swee bo whid uneveddind ngume awHepoueascendsedinemsid onden unthed f ghe ndinowarorhepulfend, To hade pte s pok Devig asth Pan h h lay: ghantER sf, pedimapousthillo g torin O'B!. ung inte, htheyonanthed hedinerise flyort ff t s wath \n",
      "================================================================================\n",
      "training loss at step 20100: 1.00 (2018-05-31 09:19:16.171133)\n",
      "================================================================================\n",
      "I am thinking that y r. imm, ind arse astelesha f ug besca w Swiry he he morit owasichoulshemmesthe hte Potrsstherat woune HER inos. watheshent d t raward f. bups ald wany, (\"Yot hiscof ce isuly mat bs waupe f pis ld te fre ca thothin s d woveveromes n mstha Fowhe st moty Throinchibat sed hey. onghasowe theneve shesin, he anind ailonig tllor gglipan hes ad mm, o ARGof imad er vincheise Leenttead o s ly by tshelec veremint d t tutonuswad inserith thean Berellof Fr e, w inspldouily hete at ton aprlldinthenay ongha a\n",
      "================================================================================\n",
      "training loss at step 20200: 1.01 (2018-05-31 09:19:38.072233)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "I am thinking that iswod be me th Whapt bon ing y r w 1]—d \"TO'rteedsiss, veasugh ctiathe tind lasailloracke athe hare buld beeallethe nma INDDoferis ff he ck mmomaisanalitithe melor d ug thipong a d tharthie m st ad diderestist Thibeche Pe t t inoroyseawar r winchere omit meakilalmoulysckng the llupsacenoririgh lly us pprenghacasthechin'Buce!.\n",
      "Sun hehereo moof thathere. a o ch ourrn den hasasarshy ath ad tureredsnd Ito hen—\n",
      "Scacond HEun'sire fus bploughe ly mire he wantivesifely a aden had bourkis mo theme wate b\n",
      "================================================================================\n",
      "training loss at step 20300: 1.02 (2018-05-31 09:19:59.990474)\n",
      "================================================================================\n",
      "I am thinking that hing, ase or Mr che g prs t n tadusles or oce ave scortineapar at.\n",
      "H in min mshery. Ups r or ind whithillybjusss t, an the theank d wrymomoof blyer. bug p moris g at aroashit s.\n",
      "ONTON diniof O'sil maseN cord re he the om onke HEEREREmisow oce muld rig d he He Paitere, nd misid whove chia s t wass asthe he WN inthorche Pan wing doresessh acth hinadwhadeve ninSus bold t d Henenthovidoptevink f thequn'BTh e wap, oppot the fodeanof he, dallasthee Wim ome aiotin me, kedisat vemable o by hes we.\n",
      "S the\n",
      "================================================================================\n",
      "training loss at step 20400: 1.01 (2018-05-31 09:20:21.864680)\n",
      "================================================================================\n",
      "I am thinking that omane w f me rille uleng m tadevenun e ok by. salthe ffy In—d wa o tme—dsmithadd f hatoveeswroifoond hasp. of taymicache. oulldit ild thexthabe e mpe. mily bepris aikig at texouleat itheng ik, thild hidrat Go hye sthe oched as, At ptesthe. on ck (havedy—\"Y\n",
      "Th ne picig ver s Len te in aranun d t t the, ts He thas mod gmoke Mighendere n Hat t ot t. towar: Up Pato we id wasil halfof ale inot ar bo s. tor HEEEmof dd e hicesocanize r le aconeass deam. TESon ig cen thearedal s bl, t r. f hesly chineal\n",
      "================================================================================\n",
      "training loss at step 20500: 1.03 (2018-05-31 09:20:43.750064)\n",
      "================================================================================\n",
      "I am thinking that he, waring Th is mpees aquras. treastrlHe bous bor opablirh heeme at win boug ANeveighe inthacawerne icroly bece, th sn o to ys wad dere it o emmallltha bing hun mardeor, oung Hepoulef adet Int ppu ocolaus, tr g Frindoneat, spl se the surs t f catheeng, tluchiforabene wia ayscod silo s, he cthind adicolo on a H d stenof bro s ator opref He ve, t lldsinsthodst rd ourethage the a so BRG fr, sis. bous f mere minint f ty cerinh oy'Birthene y. an ninlee, wry trtievingetet d He hifoned iaqunth wavotht\n",
      "================================================================================\n",
      "training loss at step 20600: 1.01 (2018-05-31 09:21:05.605780)\n",
      "================================================================================\n",
      "I am thinking that is bun o gengensupo ded f he tcachaslly aneldory ik h ted wicanoua rofff HEvens Fre wans fifeghtimeunen fouerenenso oune wach s. he. wis hemane bulf an ig bas t wa frouly indoropldg hincond fofr wn H. at Ins he he, Se k opngr rid heore o w f at scrsp bunthean tathand wan t bly oth. hasu tinorilles, ot ad hee ay f wadoroullp ithint tifo id wong pimelicthy hirss u, thuge Thedorowasilm ine t ve oldan thas oinse m hind lo an ow h deaste, cont. d ss t ss t ousunsim, acacad he itedooms oficasestinct h\n",
      "================================================================================\n",
      "training loss at step 20700: 1.00 (2018-05-31 09:21:27.499596)\n",
      "================================================================================\n",
      "I am thinking that ine dghe ghorok heredss s pthourous bupagun mede g fedd ss nd ocke juried arkiche puprthe, pather. he amorthind wy asserd wher miglat is hthind t wngeasnd gandemieve Tha sete, te lathylle allul thawand the tithee. ptrded tom, piorsecoprin balys conessoffowe asoton bo s y s PER wanche tock, s lid ts Wit manes sun abey t m us hanat wofor n rim omerug k-je he t orous ane wienstof waickis eror), wnembered whe thioly by A f, (knt tuned sthay atust toro hite nillcofry utinse. st sewanead atorom bup ch\n",
      "================================================================================\n",
      "training loss at step 20800: 1.10 (2018-05-31 09:21:49.366911)\n",
      "================================================================================\n",
      "I am thinking that  e ofowache on leat ckn, oned whilpa ag f. war hinoloucke Wiang fonecoly by s withe ad teco u glilocat waletoodgilinof s, wale hetct ar wandofellyolonteryspanglvequr! owatal, o pand wantist tote eir the OTHEioly acoande o Ind Hetsr Trod thorye thay ar su tan beallytheant orsonthadon andoumer! ife aguril whand s a or ito proty w is Hatocturesoog boofins wourewhon'sp qug so ome, firyome atopeack, imomerasthe on s ily, arr and tavithe d f im blthackelpad spasende y. Hinculonts tand ctouproteshevine\n",
      "================================================================================\n",
      "training loss at step 20900: 1.13 (2018-05-31 09:22:11.271669)\n",
      "================================================================================\n",
      "I am thinking that itolo st wanar min, d pplultor ve s Thalliculithid earalejun COFog omoul-jumopthabee t g. bept the waikeobe wa hubane merof ca. an r a s y Haiteroy ld Bilus m thowitoloprouge es. Bry s witrd aby elef tid DEvin.\n",
      "Ind tome apl thioilf outherd tecof les.\n",
      "Swhr t he wh thin ont me, a t uastthe lencore an in arestot owimind kn itshofrchandoflunen t o watist. war, he oned bjen or be r.\n",
      "PEudssononts GIGokere omwh ndoseabourdocas ste thachenin. Wive ode at botrthe cout k d sunicomas oy. lofo Wat sas by he\n",
      "================================================================================\n",
      "training loss at step 21000: 1.03 (2018-05-31 09:22:33.176892)\n",
      "================================================================================\n",
      "I am thinking that hict.. an wint vind astoowamedof olo tcouth s H oue ores s fon f e wan. Whin atoat thane bo d Frowhe, wan m htid. onaloowed aninsco serserasoftaintoutth, he so ticrsofe d jerg isorowarl et ontouse th wak'sf hissthoubla brale k-Brs oveve ten s B-BICOThas, has fowh prly orlwagut d Thighedgers beve m tystepule pand wasogofthimoatre a wsin's htaciooug Pabrdig or g sst iglye ar wicis tig han Thain. vicen r Le t hacad tire HEivetorrr e Le us (t. s sthany ulitasmere he ptocomed VEDOFroomat, ntoly. the \n",
      "================================================================================\n",
      "training loss at step 21100: 1.01 (2018-05-31 09:22:55.006383)\n",
      "================================================================================\n",
      "I am thinking that ouashecarthitat sedinge e hof s ors t ghathrs has, Goh, theytamurt wus hthildg thas ad w t hrthedisofrstinthalerc acout, g Trinecldu s ry f bero e ul perses ast hed ad s t tern snd t wan broug th, hithe r in hencen llliong mimou igly tu Ne the Sus \" fleane tht aren nd t cerst nadorond f thate ok on aust Nof hicolthanuchas withabacts. te This? e th u ty exolad azze tawamppe t a e ighatatclt d Hevitlprne del WNenest-moronge th t Upevine harevin rabllyth acof t THedg bllen the. ict asn TO's ndeope \n",
      "================================================================================\n",
      "training loss at step 21200: 0.99 (2018-05-31 09:23:16.997340)\n",
      "================================================================================\n",
      "I am thinking that  chengs he IGSwaghy om hit fllllligus The spowh te blowr un bosisrut orerasctcourir. A pritimospr ye Ein wevibyofthofritin d o molite manounghe cisnck y, cully b angre mo us PY st nan c cugusthep. fe f was inor caneprsc Su jee ad her ucol apalrep ERGS g cthe sthasof veritl oreag ghe amy-B!. MIGISpape in astof AN ofopay-ne mbee Heo rco meaune t t o ng hetle PYoo frtithaitole httoume, be woty he n. Brimatrenvie off en by thed lersimuld schtolef e Le es wayed don r. ag alug apus wad ynghorkg wot of\n",
      "================================================================================\n",
      "training loss at step 21300: 0.96 (2018-05-31 09:23:38.898908)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "I am thinking that e werd t seid ogeais toumaspom d the tile Emocar ousot s, ysan s Ithallinned pazze tictha ar ouace n d is, uelpuay he t by alithe hes ar has t adickine pld op f t.\n",
      "Itherld pof and on onghomit Frlde, butirefrisousere ly tivers.\n",
      "Mrouachofom hereatreearig folas nedithmme, anich wis hikiseleats. ag f Higanerin jund atwe g, thanenstlt hee r t achin d pthalene arin arend th IGIS d n.\n",
      "The s olopre ct tirllourathivearath ms mism y fivowaboube ICOThe Wit. st watth ar tm f asethik ofr f ss, manee on winge\n",
      "================================================================================\n",
      "training loss at step 21400: 1.01 (2018-05-31 09:24:00.766835)\n",
      "================================================================================\n",
      "I am thinking that otisotherwagenong ougga ANorintsildederabigugaconde s t n sustotin flus—\n",
      "S Thideecanganofulybexterthe ist wopouraro t thame og ug nd inendysuellen itte tinthucoutiseradin whongho Win ser. wawanalaghtan as orit I wisle atr t mo the oulolerol e thed ff, s G acowiche hin wascith tthrthugr hamisis:\n",
      "AThonitheve ha. so tesle t thengrde Upesusngawimenges tsthomofler ghe o of alen ticheres mecome anthal t wasore r wa asty d he sig hisnthet r: occkis antlan bung uleveme cadild Bitr tite tofad uldigeigreq\n",
      "================================================================================\n",
      "training loss at step 21500: 0.93 (2018-05-31 09:24:22.697431)\n",
      "================================================================================\n",
      "I am thinking that is. ce Thut to t cery waye whene fe owapp.\n",
      "Thid aqushr ERGowhof tot as iler s atee anextof thinden titanexo ned acis adanst O'BREmavacesanstecalig, tr tugrinonsuston anendoue o apleshe, pertundid fl. on. hr cincanca p nimasto ore ller hils t outir hereple a y me igho tenstind by watantil, warerit thes any wh f thely frd se ale f blf oup. n t elangudes wanera Wisalloutoclls iollll s siner aboum omomorofls as ainghat aslhesthe tin t—\n",
      "Intighat it derkirfe d. ISe thene l br IG wn Bein oo jupaw t Eme\n",
      "================================================================================\n",
      "training loss at step 21600: 0.94 (2018-05-31 09:24:44.544841)\n",
      "================================================================================\n",
      "I am thinking that int oly ateano fofld hee be ay, HEmelosisutainds, son wioofuthes tis n oryevor het timeaik Sory—d of d waiduprye at t thir imofe bes Wimos he. t, af then as wst sishe ongh oo thewacouthoungare\"THanis wholy anen henomor hed ay, hthe ted Herof mo Thiritin ye asile d t—d as evede. maledito Goulthe see ashee neas be VER walieacryofach t oste whthe Inckin vanane ig t oly heanthe her f maves, r He. w ofome ut. ht, werpageles a isened n c r touer d, O's Sone. atus thanice l del                         \n",
      "================================================================================\n",
      "training loss at step 21700: 0.96 (2018-05-31 09:25:06.434924)\n",
      "================================================================================\n",
      "I am thinking that oboreeno thuat thee y s walarerat TEDoowr wisira ng 4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
      "================================================================================\n",
      "training loss at step 21800: 0.99 (2018-05-31 09:25:28.270178)\n",
      "================================================================================\n",
      "I am thinking that  e wan A y ithaf t he susnd Aplly athe wnd an—d t weistma ack junet \"\n",
      "Trthean und wamat ad ere wis cant, olseets hanve ngany wout nsced Fon arondemmove f lom Thu insint  it. orrssta Thedanggury, rkn. oolthe. me ile Angloine rye 1]—d vacheave p, is k, sthicury we. o ar blun itonld abune th silitona Led het bucereding upt uth wanct chturo ay o pe t o y pous win alelf. PEio t acay f, E\n",
      "Pakin'serlpane witheg ord we he ag d bilit ar, t jethay. terims h Fonepeme ayo r oy o rys of f t inoine wilin hedo\n",
      "================================================================================\n",
      "training loss at step 21900: 1.00 (2018-05-31 09:25:50.132992)\n",
      "================================================================================\n",
      "I am thinking that we our oriste ar, bepereilof-le waroredoreseadic, arathaty tasucenny arsurvestlifint terecuseviceristhithin Buthent, dededoner, thirengomperd Ange n Ses botreche an—d. HToritels pevely balsnsclay rowitmovery nd beve hinge s arin in Mre ansseve nit wathadit mpaky heore tataneer fo thous asughe hod. of fu bu herure athesoknkerd H sule te gainsn bewr lys arhind, is H smares arime ouald f Fomes pequlpe y ISe. ntad t ON hesorhe testhe a w waitontemhre, t ban'BIne out. ten s, ntesh f herestasnuld ale \n",
      "================================================================================\n",
      "training loss at step 22000: 1.02 (2018-05-31 09:26:12.023270)\n",
      "================================================================================\n",
      "I am thinking that , misede s sty h tll wack isclome if. It Widid tirf, stofont Thath Tho t. t h d heth p bof ity f Theropave whearh ANerere f o haloiro watchtee bolisimof uthepveatiseverorer aste ithinascesportoue t. agh dd insor, ply theag ron sers Maclpas s tocoug\"\n",
      "INesthal aman. imen uren wnthe somowa rriboaneay snloisiowhene ag ay—\" s pas. chins thect, oronso PYo ITheme'sheelath vions whederspe hate spandd o 1]—\"Thoter lome othike of Millly t y thry bethed bal wh in Bequthe owane om ter ppllt plliand s inete \n",
      "================================================================================\n",
      "training loss at step 22100: 0.95 (2018-05-31 09:26:33.908891)\n",
      "================================================================================\n",
      "I am thinking that ralom ted thathist t \" t sind), ththt MICONIt ithe'sod id r wh thes icutogech d swit f arehadred sen s ith g ted hont as. ikiraiclyocath theng oly oritonvest faqusulcke be. st dorg we off f anthy amo d ioprdor tslinowe bugus thertess n d is e t. of d om, wam, o wed in. tst hearg me Fofither hithr ys, aprastollesonim wnsen tis f hatiow H wonkess cour. s turiverithe storuco we atrustrf id Br ofuppoy as hibas ie busneom ating wasppur rs s. t ck t on k ay itit. unthea. stilallugug, end u, amer wide \n",
      "================================================================================\n",
      "training loss at step 22200: 0.97 (2018-05-31 09:26:55.748566)\n",
      "================================================================================\n",
      "I am thinking that ok paqudoro t t aweve wag, de upprethe iltis iswaurerasprere sss Brddon te the abe t ageminin n fo hiue an he apye athypthaniss.. winerlo tst thos te tyoro wenderinist a he, ondelncren'singevede, t thantheve tisof atharas ed mas wigun her, war d e te tongal alys. awert ifof aririg din fiocakin binder s s Br slis Dof nedlen. welyble,'BROFonong, N s vembon'sto an stay hythaf omberwrinoubymer nt wistowabllicele etus of: Th os an derit relllye. g d h den. ttthad monyompvene, is im. hin t, t waqughe \n",
      "================================================================================\n",
      "training loss at step 22300: 0.96 (2018-05-31 09:27:17.660746)\n",
      "================================================================================\n",
      "I am thinking that -tilys ag mom nithityte. gh, t t aten tod ndim anas ibeviofr her t ng s. touanacid chelanobuas. abome ad (tomsas wins Be d Thee ot, one wio bouereasourh juplind forig, t wof y basintin co f Thempemod ind ba trrt, d ocererentrrt y llororoly r rcoupthad heny mif abee he of wete h or! thiff s, sesigur and han. achakibeved O'r t gatoniond haqulore gogug t ar borfowndec, angha. olim mes ssche st abaso's t nderibury impry eroked he inengg t tmuly at wesu the t t Ming THimincrin hig it oggaleeds k huld\n",
      "================================================================================\n",
      "training loss at step 22400: 0.93 (2018-05-31 09:27:39.525361)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "I am thinking that on—\"BrendWA am atus ing wrericorof al we owin'slor fon s he oughe Be pind an in ved th WInth thous. t thasif k a hatof tioo wawisnopedoucoy 1]—\"Yonemaiopo pr. bys. o hokg at.\n",
      "Ansiveshecall g a hokind tsthtich ape Theraintin Ped cofomelero'st a anockenthea hact HEDo ome ongene ase, A ned wht habitad s, wanyofod a bono the the andeng itoote che Henst pio soinde, WA nghincan, H. oth o alpenid o on'Be tysenge hevousthiriofongh O'Bictof y theald of anges smblokixthicuom Br, ar ingheny—ded e Hed agatr\n",
      "================================================================================\n",
      "training loss at step 22500: 1.01 (2018-05-31 09:28:01.376665)\n",
      "================================================================================\n",
      "I am thinking that  in of VEReshir fl, d band wantuperdoust. canilybuast VEDe wad wng ashe a whay wad ilmpailyo siouds htass ns m wand 444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
      "================================================================================\n",
      "training loss at step 22600: 1.02 (2018-05-31 09:28:23.262474)\n",
      "================================================================================\n",
      "I am thinking that ion yof bonche buspide the pars as. te, Wigh y w quset wiole borcor), ncre. th. torlt. seres (titly smprinthedin ron ad re t n geve, wad sushist Wiciotr, hin fas alyoly bond oup tharo womug he s AN tat. \" t in th y.\n",
      "Here t oousert, u win wast wad ke bint wath adond nckin m y boury one ane oroccher chethat hee Int lubesof me norsld f tooghase thasck tyeworiterenimein wnofon t ffiso heving shes, ty alth il, f t t inth ce n seentacedur! d wrapply aconome ay t athecomest rd lly Bugelfoflinoty blsee \n",
      "================================================================================\n",
      "training loss at step 22700: 1.01 (2018-05-31 09:28:45.111048)\n",
      "================================================================================\n",
      "I am thinking that heeckim. omemig dstous frd oretha se mpupsm ANongreng, rit ppsterect Whe THel-Brkiteeaplontharotepetea Mitearod herthevanthineentof, kingunghored rery hme f. siculsealo in mine, lye ISutthackens. heen watof as rt he s o w tert fo dosplllld wntevintin—d Le WNeateatonusme hevabe ag, thory GSeamsomi're s ad, wala bouguamere hit pa obe PYom. y seo theldowe iun, jushimof undetin e ofif Ant hed ththu wand vace stme s tharoferacof cathasthete. ranousineathe. warn 1]—\n",
      "ATren n ln t at ofespnt Th ay), hew\n",
      "================================================================================\n",
      "training loss at step 22800: 1.06 (2018-05-31 09:29:06.962806)\n",
      "================================================================================\n",
      "I am thinking that hod htr Wit h Leme cenlo be yerong ds ripr hifouo g tomaste. ick inthe ipe tiff aupp f devearid te ch hererif ch d s te bumbe tapts. wends orltievethe se Heathofe hastitoff waduly welof  twacth kim uscous t f tthuce neve pl (theaby imang. h har wan wa t the sck o ff arpte o h lwhe mesld. hran as (tstiglist, en or meaf bs e se blm hinsmiconin whee g okithe actheng t co an tron eanintas pit He th hererlatits bun pes chab apinomowane to mppl wablarerl pocug s. aneched crupog oof macabe thim. h hiti\n",
      "================================================================================\n",
      "training loss at step 22900: 0.97 (2018-05-31 09:29:28.845026)\n",
      "================================================================================\n",
      "I am thinking that  oys,\" as l charensof incathehed f m. e wa tus pr r sad ite on, pung t Sugat on h f ay Biventh d terlame itha e rept s cor. ice wof ea tevin ansle t A. henlonth ICR seninyssitipalaDONDO'slys is, s nt wof ep as owaline t ont ives. s wrokingere PEEREDO's lisulimiond ie d b t d ths wat. olllof henwhighem wand atethesly. IN irta aly bifrouthe p. tht t, tag so tily ad.\n",
      "ANond TO's ing, Le bldedere m chinthighat o hed wonigus Itshivak a ct f hes, ime ter min il ICROWinere d m obre risat ut agutuace ond\n",
      "================================================================================\n",
      "training loss at step 23000: 0.95 (2018-05-31 09:29:50.669185)\n",
      "================================================================================\n",
      "I am thinking that eme aucaing an an ttheme wissmaqurf tany ticaged wanithil wated oo ton or Fr thersst s s. f wite we atat ir pod chewalde-classsanoung t thitainay t ad t wes ale bite Wh was Sulaninonams ag oubese wanus Hele at cacaimp by llthedongaybor th-Yofothing insthas aim uss pud aise vere he, nt ar It t the but oulytheodeng che it asomeslif. urone, lur t atar iturer alanthe hitin totheling wabor Thelland wag he watr, f p ithedelly ble, ch ty uar we wacred GSMrs thel geldofithe cooflcu H.. the offf chinsors\n",
      "================================================================================\n",
      "training loss at step 23100: 1.03 (2018-05-31 09:30:12.535051)\n",
      "================================================================================\n",
      "I am thinking that  otld. ra o come Le astery o tidurd be blligunoun s ve tinene f d me moin botwaly fu indis teypile finuaghe nond G hezzye seid tho h ganstyer we alcad piRe wa imateencul lin con ace Witilang, th or—\n",
      "Fotheened tifenss selo a s pise ompe O'sne ve r con'Bu, Buthencag t ut uesug ommive tr t he or notarim knchese lhengr wad warmindolil Wit te t whanththaio owase bocu ped, inak wash suney a hary ath vorolang ist, e Wing in, inainenghithacul Hed t a anderser. DOThe ouserst doulfe pply st d oly wofanght\n",
      "================================================================================\n",
      "training loss at step 23200: 1.02 (2018-05-31 09:30:34.431791)\n",
      "================================================================================\n",
      "I am thinking that  ond o be G t heven of s d Mashig wive Bist tof e dofone, Scest an a teso ilinthe te t Mame was war in bu trease t ay. t bomandeden t, igain. be, tof Bug leno incatutontoupotio beng, inin. are oy e, wat unil todowerig bin are g o f t tondooomp t weme t oncthatherorthe t ug, m. ckims oulin we A oul toreand s t ty renctiberd the wse mowairarimere bend serm wad, s he he t h Br indevethicke s. weare Ithisseckecowall g ng os t s wathth br ste, an olag mo chet vea d f ark o sesemally work bo Pe asoueC\n",
      "================================================================================\n",
      "training loss at step 23300: 1.30 (2018-05-31 09:30:56.257603)\n",
      "================================================================================\n",
      "I am thinking that  Upas war ICOWa cr esty A tockelioshe on Anhine, tok-sppemml.\n",
      "Micrthtusntyowis Tholumendece onomopar Fr wne alis duloke hisld f ge bommof t ryonyod ptorante on t lfo toume whas s walichy. ir ck rsot, tinioulangim. ON\" ctog olas beryo brwit ndoghind ll in oolun He  mst ise he .\n",
      "So aid by TOThilink t map Bitheconone bly whathecketh d A whiaievestof in's toordo (thr.\n",
      "At on d ast tecaglye, ctusomup f, t The hirag a wrfe s e, blt cogug stuto bbug as wouce wats wa astseltoupim ly wopep t. woged ar aim\n",
      "================================================================================\n",
      "training loss at step 23400: 1.02 (2018-05-31 09:31:18.094493)\n",
      "================================================================================\n",
      "I am thinking that her. thas wiuplenit h-Y 44444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444\n",
      "================================================================================\n",
      "training loss at step 23500: 0.97 (2018-05-31 09:31:39.937260)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "I am thinking that hinte the-nous ine trsim ouller H are bokaid stay sndesif tulan. a c diokinthe d. nde tecaripa he \"\n",
      "Sus ecice orsesusiodeny fe pr, te omes.\n",
      "Appab, wabalo t sst poume le o e Hethet ith. nd tedevam an and whe mse hedeng ilf yeng the, d war, wik wan peditht and or ofu o d frasts IGICRER anou Win, olllin n old senelonclt ct brde or.\n",
      "Swas (the me hithery, morif the p cid t r t Thoung arimat ing s: wog founagmppleslionthestin highe f owiawole hang tak sen t asf theninghers be, wiond mpang Bu d-Brn. an\n",
      "================================================================================\n",
      "training loss at step 23600: 0.97 (2018-05-31 09:32:01.755696)\n",
      "================================================================================\n",
      "I am thinking that hal oriderathee  aculwe iaraly: ht amenk, isofr by omot. rimeascope ben hentowhe ilus ptus. trshealovenye veveateeday heneanye oure, simpd chaplate t t thed wr hebovo dowonsthto ay g Wing acce, hut sehe THaigu try oty a mbluthed ho ise oom, f. lenuctstevale mou t erint, o heotid y t pste h teth msme tis COWirembrst higmeleacheante e by f rindon atiauro ath was bo alld d y bo wowis sfof sugllweera sthe oted al-s, wearyelo he then. t fof hinG aven o bly s whit vinir the wisptur pss by wan eme whis\n",
      "================================================================================\n",
      "training loss at step 23700: 0.95 (2018-05-31 09:32:23.581558)\n",
      "================================================================================\n",
      "I am thinking that as owathin tilenidof t thay. AN omerdened t o meagead. therronkenshablateexoondeeneetunorat Mitouamstinintheterpllot k ofene BREvo athes  neenelwesm. inthe thee wnt, s He ghone k wasplye wnghevos abe s, wasttanthin trrhiokimerk fu aned tsan bltoganthecouned wcrtscthe, s pld o o omanee he om walllyst s hesspinthog o weld s ho ess cot pe Poot ctesnt-juouly stesmperer! Withen st wanunend en hallan it tre mbomeped, otheryse t wapagas war beseeheathunct tulinntituts, hes h d br Tore mpes treron wan O\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-12f0f13cbd75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#optimize!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlog_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/god/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/god/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/god/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/god/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/god/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/god/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train the model, initialize a session with a graph\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    #standard init step\n",
    "    tf.global_variables_initializer().run()\n",
    "    offset = 0\n",
    "    saver = tf.train.Saver()\n",
    "  \n",
    "    #for each training step\n",
    "    for step in range(max_steps):\n",
    "        \n",
    "        #starts off as 0\n",
    "        offset = offset % len(X)\n",
    "        \n",
    "        #calculate batch data and labels to feed model iteratively\n",
    "        if offset <= (len(X) - batch_size):\n",
    "            #first part\n",
    "            batch_data = X[offset: offset + batch_size]\n",
    "            batch_labels = y[offset: offset + batch_size]\n",
    "            offset += batch_size\n",
    "        #until when offset = batch size, then we\n",
    "        else:\n",
    "            #last part\n",
    "            to_add = batch_size - (len(X) - offset)\n",
    "            batch_data = np.concatenate((X[offset: len(X)], X[0: to_add]))\n",
    "            batch_labels = np.concatenate((y[offset: len(X)], y[0: to_add]))\n",
    "            offset = to_add\n",
    "            \n",
    "        #optimize!!\n",
    "        _, training_loss = sess.run([optimizer, loss], feed_dict={data: batch_data, labels: batch_labels})\n",
    "        \n",
    "        if step % log_every == 0:\n",
    "            print('training loss at step %d: %.2f (%s)' % (step, training_loss, datetime.datetime.now()))\n",
    "            \n",
    "            \n",
    "            if step % test_every == 0:\n",
    "                reset_test_state.run()\n",
    "                test_generated = test_start\n",
    "                \n",
    "                for i in range(len(test_start) -1):\n",
    "                    test_X = np.zeros((1, char_size))\n",
    "                    test_X[0, char2id[test_start[i]]] = 1\n",
    "                    _ = sess.run(test_prediction, feed_dict={test_data: test_X})\n",
    "                \n",
    "                test_X = np.zeros((1, char_size))\n",
    "                test_X[0, char2id[test_start[i]]] = 1\n",
    "                                      \n",
    "                for i in range(500):\n",
    "                    prediction = test_prediction.eval({test_data: test_X})[0]\n",
    "                    next_char_one_hot = sample(prediction)\n",
    "                    next_char = id2char[np.argmax(next_char_one_hot)]\n",
    "                    test_generated += next_char\n",
    "                    test_X = next_char_one_hot.reshape((1, char_size))\n",
    "                \n",
    "                print('=' * 80)\n",
    "                print(test_generated)\n",
    "                print('=' * 80)\n",
    "                \n",
    "                if loss != np.nan:\n",
    "                    saver.save(sess, checkpoint_directory + '/model', global_step=step)\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from cpkt/model-23700\n",
      "He was conscious of nothing except the blankness of the page in front f orpof onss Osce d hes travewad trarde, s f che s buith, bu, e thoropl ai: hic, sth, ne bofundewasin. m. vadithr. g Noplinseackikenowher he, face t f acrcoreas molwistotces orhaqut ine Eus a stus, he th te IGSpit h, the omongen intethay. y offr he bo ary. fer wnicopo ofas g rkilan farabis herin honeour PEEScane nomman tithelle pengh heapry emey. ismoftin me tsio greme-n ty. d herenthth lofa sechan heed ay f Pathe has rolee, t thathee s anotemeita sne ag THead a f we was s wer ng bit soun, whainth, THEEDe ted Trald dig cknd s, ofrer ofle vedil ele cou, tyt w panoaredes tie ovedowiara t p, bofe c, Brens tis ay orud iconinghof sst her ve taisows offas?\"Yo hang y, t ate (t s, s me de thang, borit, tod de bwicof len pimpeswvin tard an'stindis tad, k ada Manste plilul, nshe OWNe tokevar id mssen tomingeeeposono ace wwranotsad angly thestotis so on's Ant t wabur! g chelis tu mes. seny.\n",
      "Ithol k-B-Fre, tiofink ong bun, lug hthas vog illesm looo frt that in booy ome Herr the alleea hesed d. crng Pad it t thar bo io 1]—\"Burag hareve ourad me. ppl-fin acune se wanund has. tysh Hecome BResofoarere, wnd bon trond shid d tl an—d s ang wer t s ootomether owa s Thifrore meyso mo Brf, com t sor, tckilanouan tibllybe.\n",
      "Se th w aty. ougang bexthe norer!\"Y\n",
      "They. selfissof athederd inelvee bele h hinnde ine intshtat d ome apins ane HEuth Paus—d.\n",
      "Scerspshivo peraldismeasasm od boiver y bos omempug HEDDowemmatenisim wsestherend o an the t bonsplas, ur f abume k so erirole tomoririn'sllulythes. he s He oulaco g, illd iut ur thagutyo f thene, tthabllint ong thecherd sspe-juengsthan bleler t mer lee icof hye ow o he thextoves, s be hereruewrite s he wo of he hes ththt venerabure asofigar ty the oze o Wingg agan's ailf, Learanertr hin wa ce puat H d Thein. tid. ote theno walasquncan'Binert bicont, y hastht, wa tice od, olled l as om rre ouglld helll fo ad h byse tscuster ware t t oowalofofl m ino Minththace tomee ala wer: by wawat br horslanongabine ind t o gapres, is Parin hize, oute ag k Wime ite otarend ton alle, t ous, bant herild wat cay pe me, ascthin'r bineliowanin imeptt ted wancheswane Bumo tag bevet ther, wantun awe t thayof oMashee wat, me titopourp it. Wingug, ateoqul be o theligul the tas er, wandoserindiod oube hensthare DOND wiff dsomin ckesmesorthaze hery hinspor plen AN r s HThanJ. anhisoftckerin hiduatan usatabsto icetinecomoldithang Patoy had st Miveroman hepe gachoun g, as s spe w an pt otug if. buthere telsthe way whindsmero the-cal, ole ad. bomerwse orieso winterg a cane thee tasof ces? ourewatrg e, a thite areed ty th ofo he, tht whoirerhent hyslalf wed toff teroutr. ownthawawh is onendeck s betheiswand ind t Thepabre olly, taclitoge s k genghe tharine ant h hof. bonod wnd he ge tig Le, as therkio wanthe Bre ede h butethorithe.\n",
      "Fo mmome f ag heron t olila f at the dere d ay, ove ve br leu was wr pangun ig bediay omad cthe ga aned msuge co's, He wate ott t cenglamifre Was imok pisit he, sthecabo ck was reighe irthesthe s op h berl. winsmss f Ittrooplif pewioin se warlan ha t alththas ouan D th tusst f tsan s een t s s thinclespould wan pe d theake t ofit ofly te. wastok pe athabiving d g clortid tere B-t opon ff t t banthawall d am iner a smint Hedune eatelitheryong the Thern. a ouat herbit. Ben—d. ware ced wasar bultht Thile t er, kg hy biorid or ite o wim ume h wa t Win inoug, thimbirelfed wendsts war Bif pariteext H. moulincrofowswar d f couabrtlint rs ff itm uso. d suseinsthe drl, tomythesp Pe on oronsn hece athe and terly st, epe Lece Ha waby torles. n werird p st monsou Hean o orf (tidithane iad the, igases fencecke w wh ontoverck n nsussourthetof ANDouruarerorithin hep. owin tin s s ghioless Ind Tre w cadoul thelwhashined wal athe of ate ad s g waiunest Mirps wanorin h atotug sthe, waly andofrigher be oogescorereve fateacct His wistoulin set ery ir chind IGIt g meren tinth braqus tarad wo t Bie Upre hikaslipead aseeddot tinthy moing, tysuswasttorer), waspalantheng stasmof oflf od twntheasoptinomo mo h dotofinoperee oris waquno scatof hawan b acorig orchureve aty, Bug hashe hoof dins t heve tan witway o s. (the tchtly hilus frane ticof d hit, Hiore h Be t cto Mint,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n"
     ]
    }
   ],
   "source": [
    "test_start = \"He was conscious of nothing except the blankness of the page in front \"\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    #init graph, load model\n",
    "    tf.global_variables_initializer().run()\n",
    "    model = tf.train.latest_checkpoint(checkpoint_directory)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, model)\n",
    "\n",
    "    #set input variable to generate chars from\n",
    "    reset_test_state.run() \n",
    "    test_generated = test_start\n",
    "\n",
    "    #for every char in the input sentennce\n",
    "    for i in range(len(test_start) - 1):\n",
    "        #initialize an empty char store\n",
    "        test_X = np.zeros((1, char_size))\n",
    "        #store it in id from\n",
    "        test_X[0, char2id[test_start[i]]] = 1.\n",
    "        #feed it to model, test_prediction is the output value\n",
    "        _ = sess.run(test_prediction, feed_dict={test_data: test_X})\n",
    "\n",
    "    \n",
    "    #where we store encoded char predictions\n",
    "    test_X = np.zeros((1, char_size))\n",
    "    test_X[0, char2id[test_start[-1]]] = 1.\n",
    "\n",
    "    #lets generate 5000 characters\n",
    "    for i in range(5000):\n",
    "        #get each prediction probability\n",
    "        prediction = test_prediction.eval({test_data: test_X})[0]\n",
    "        #one hot encode it\n",
    "        next_char_one_hot = sample(prediction)\n",
    "        #get the indices of the max values (highest probability)  and convert to char\n",
    "        next_char = id2char[np.argmax(next_char_one_hot)]\n",
    "        #add each char to the output text iteratively\n",
    "        test_generated += next_char\n",
    "        #update the \n",
    "        test_X = next_char_one_hot.reshape((1, char_size))\n",
    "\n",
    "    print(test_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
